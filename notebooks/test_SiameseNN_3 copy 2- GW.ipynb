{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 16:44:41.761039: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-08 16:44:41.846278: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-08 16:44:41.846336: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-08 16:44:41.850133: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-08 16:44:41.867494: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-08 16:44:42.946659: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-08 16:44:44.470800: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 16:44:44.538653: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 16:44:44.538833: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 16:44:44.540471: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 16:44:44.540708: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 16:44:44.540812: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 16:44:44.619390: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 16:44:44.619547: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 16:44:44.619656: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-08 16:44:44.619738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting memory growth to True for GPU:  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "Physical GPUs:  1 Logical GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "import tensorflow as tf\n",
    "# dont display much info of tensorflow\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any level you prefer\n",
    "\n",
    "# limit gpu memory usage only as much as needed\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "        print(\"Setting memory growth to True for GPU: \", gpu)\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(\"Physical GPUs: \", len(gpus), \"Logical GPUs: \", len(logical_gpus))\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "from tensorflow.keras import layers, models, Input, Model\n",
    "from tensorflow.keras.layers import Lambda, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Activation, GlobalAveragePooling2D, Concatenate, Add, AveragePooling2D\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manta shape:  (9587, 320, 320)\n",
      "xiris shape:  (9587, 320, 320)\n",
      "y shape:  (9587, 2)\n",
      "y shape:  (9587,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "manta_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_manta.npy\"\n",
    "xiris_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_xiris.npy\"\n",
    "y_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_y.npy\"\n",
    "feats_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_feats.npy\"\n",
    "\n",
    "# load numpy arrays and display shapes\n",
    "manta = np.load(manta_path)\n",
    "xiris = np.load(xiris_path)\n",
    "y = np.load(y_path)\n",
    "print(\"manta shape: \", manta.shape)\n",
    "print(\"xiris shape: \", xiris.shape)\n",
    "print(\"y shape: \", y.shape) # laser power and velocity\n",
    "\n",
    "#feats = np.load(feats_path)\n",
    "#print(\"feats shape: \", feats.shape)\n",
    "y = y[:, 0] # only use laser power\n",
    "print(\"y shape: \", y.shape)\n",
    "\n",
    "# normalize y\n",
    "y = y / np.max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values in y:  [0.18181818 0.45454545 0.72727273 1.        ]\n",
      "y encoded:  [0. 0. 0. ... 3. 3. 3.]\n",
      "y encoded type:  <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "# unique values in y\n",
    "y_unique = np.unique(y)\n",
    "print(\"unique values in y: \", y_unique)\n",
    "\n",
    "# encode y as integers based on unique values\n",
    "y_encoded = np.zeros(y.shape)\n",
    "for i in range(len(y_unique)):\n",
    "    y_encoded[y == y_unique[i]] = i\n",
    "print(\"y encoded: \", y_encoded)\n",
    "# change to int\n",
    "y_encoded = y_encoded.astype(int)\n",
    "\n",
    "# print typr of y_encoded\n",
    "print(\"y encoded type: \", type(y_encoded[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pairs for image 0/9587, Completed 0%\n",
      "Creating pairs for image 1000/9587, Completed 10%\n",
      "Creating pairs for image 2000/9587, Completed 20%\n",
      "Creating pairs for image 3000/9587, Completed 31%\n",
      "Creating pairs for image 4000/9587, Completed 41%\n",
      "Creating pairs for image 5000/9587, Completed 52%\n",
      "Creating pairs for image 6000/9587, Completed 62%\n",
      "Creating pairs for image 7000/9587, Completed 73%\n",
      "Creating pairs for image 8000/9587, Completed 83%\n",
      "Creating pairs for image 9000/9587, Completed 93%\n",
      "pairs shape:  (19174, 2, 320, 320)\n",
      "labels shape:  (19174, 2)\n",
      "X_train shape: (15339, 2, 320, 320)  y_train shape: (15339, 1) \n",
      "X_test shape: (3835, 2, 320, 320)  y_test shape: (3835, 1) \n",
      "max of y_train:  1\n",
      "min of y_train:  0\n",
      "max of y_test:  1\n",
      "min of y_test:  0\n"
     ]
    }
   ],
   "source": [
    "# crate pairs\n",
    "def create_pairs(manta, xiris, y_encoded):\n",
    "    # set seed\n",
    "    np.random.seed(42)\n",
    "        \n",
    "    pairs = []\n",
    "    labels = []\n",
    "    binary_labels = []\n",
    "    \n",
    "    # Getting the indices of each class\n",
    "    numclasses = len(np.unique(y_encoded))\n",
    "    idx = [np.where(y_encoded==i)[0] for i in range(numclasses)]\n",
    "\n",
    "    for idxA in range(len(y_encoded)):\n",
    "        # grab the current image and label belonging to the current iteration\n",
    "        currentImage = manta[idxA]\n",
    "        label1 = y_encoded[idxA]\n",
    "\n",
    "        # randomly pick an image that belongs to the same class label\n",
    "        idxB = np.random.choice(idx[label1])\n",
    "        posImage = xiris[idxB]\n",
    "\n",
    "        # prepare a positive pair and update the images and labels lists, respectively\n",
    "        pairs.append([currentImage, posImage])\n",
    "        labels.append([label1, label1])\n",
    "        binary_labels.append([0])\n",
    "\n",
    "        # grab the indices for each of the class labels not equal to the current label\n",
    "        negIdx = np.where(y_encoded != label1)[0]\n",
    "        \n",
    "        # randomly pick an image corresponding to a label not equal to the current label\n",
    "        idxC = np.random.choice(negIdx)\n",
    "        label2 = y_encoded[idxC]\n",
    "        negImage = xiris[idxC]\n",
    "        \n",
    "        # prepare a negative pair of images and update our lists\n",
    "        pairs.append([currentImage, negImage])\n",
    "        labels.append([label1, label2])\n",
    "        binary_labels.append([1])\n",
    "\n",
    "        if idxA % 1000 == 0:\n",
    "            print(f\"Creating pairs for image {idxA}/{len(y_encoded)}, Completed {int(idxA/len(y_encoded)*100)}%\")\n",
    "    \n",
    "    return np.array(pairs), np.array(labels), np.array(binary_labels)      \n",
    "                                                                                             \n",
    "# create pairs\n",
    "pairs, labels, binary_labels = create_pairs(manta, xiris, y_encoded)\n",
    "print(\"pairs shape: \", pairs.shape)\n",
    "print(\"labels shape: \", labels.shape)\n",
    "\n",
    "# split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pairs, binary_labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "print(f\"X_train shape: {X_train.shape} \",f\"y_train shape: {y_train.shape} \")\n",
    "print(f\"X_test shape: {X_test.shape} \",f\"y_test shape: {y_test.shape} \")\n",
    "\n",
    "# max and min of y_train and y_test\n",
    "print(\"max of y_train: \", np.max(y_train))\n",
    "print(\"min of y_train: \", np.min(y_train))\n",
    "\n",
    "print(\"max of y_test: \", np.max(y_test))\n",
    "print(\"min of y_test: \", np.min(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(pairs, labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "del X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(pairs, labels, to_show=6, num_col=3, predictions=None, test=False):\n",
    "    \"\"\"Creates a plot of pairs and labels, and prediction if it's test dataset.\n",
    "\n",
    "    Arguments:\n",
    "        pairs: Numpy Array, of pairs to visualize, having shape\n",
    "               (Number of pairs, 2, 28, 28).\n",
    "        to_show: Int, number of examples to visualize (default is 6)\n",
    "                `to_show` must be an integral multiple of `num_col`.\n",
    "                 Otherwise it will be trimmed if it is greater than num_col,\n",
    "                 and incremented if if it is less then num_col.\n",
    "        num_col: Int, number of images in one row - (default is 3)\n",
    "                 For test and train respectively, it should not exceed 3 and 7.\n",
    "        predictions: Numpy Array of predictions with shape (to_show, 1) -\n",
    "                     (default is None)\n",
    "                     Must be passed when test=True.\n",
    "        test: Boolean telling whether the dataset being visualized is\n",
    "              train dataset or test dataset - (default False).\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    num_row = to_show // num_col if to_show // num_col != 0 else 1\n",
    "\n",
    "    # `to_show` must be an integral multiple of `num_col`\n",
    "    #  we found num_row and we have num_col\n",
    "    #  to increment or decrement to_show\n",
    "    #  to make it integral multiple of `num_col`\n",
    "    #  simply set it equal to num_row * num_col\n",
    "    to_show = num_row * num_col\n",
    "\n",
    "    # Plot the images\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(5, 5))\n",
    "    for i in range(to_show):\n",
    "        # If the number of rows is 1, the axes array is one-dimensional\n",
    "        if num_row == 1:\n",
    "            ax = axes[i % num_col]\n",
    "        else:\n",
    "            ax = axes[i // num_col, i % num_col]\n",
    "\n",
    "        ax.imshow(tf.keras.layers.concatenate([pairs[i][0], pairs[i][1]], axis=1), cmap=\"gray\")\n",
    "        ax.set_axis_off()\n",
    "        if test:\n",
    "            ax.set_title(\"True: {} | Pred: {:.5f}\".format(labels[i], predictions[i][0]))\n",
    "        else:\n",
    "            ax.set_title(\"Label: {}\".format(labels[i]))\n",
    "    if test:\n",
    "        plt.tight_layout(rect=(0, 0, 1.9, 1.9), w_pad=0.0)\n",
    "    else:\n",
    "        plt.tight_layout(rect=(0, 0, 1.5, 1.5))\n",
    "    plt.show()\n",
    "\n",
    "# visualize pairs\n",
    "#visualize(X_train2, y_train2, to_show=4, num_col=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss_with_margin(margin=1):\n",
    "    \"\"\"Provides 'contrastive_loss' an enclosing scope with variable 'margin'.\n",
    "\n",
    "    Arguments:\n",
    "        margin: Integer, defines the baseline for distance for which pairs\n",
    "                should be classified as dissimilar. - (default is 1).\n",
    "\n",
    "    Returns:\n",
    "        'contrastive_loss' function with data ('margin') attached.\n",
    "    \"\"\"\n",
    "\n",
    "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
    "    #                         true_value * square( max(margin-prediction, 0) ))\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        \"\"\"Calculates the contrastive loss.\n",
    "\n",
    "        Arguments:\n",
    "            y_true: List of labels, each label is of type float32.\n",
    "            y_pred: List of predictions of same length as of y_true,\n",
    "                    each label is of type float32.\n",
    "\n",
    "        Returns:\n",
    "            A tensor containing contrastive loss as floating point value.\n",
    "        \"\"\"\n",
    "\n",
    "        # Ensure that y_true is of type float32\n",
    "        y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
    "        return tf.reduce_mean((1 - y_true) * square_pred + (y_true) * margin_square)\n",
    "\n",
    "    return contrastive_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder(input_shape=(320, 320, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# add projection head\n",
    "def add_projection_head(input_shape, encoder, embedding_dim):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    outputs = Dense(embedding_dim, activation='relu')(features)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def contrastive_loss_2(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "    \n",
    "    x =  tf.cast(y_true[:,0], dtype=tf.float32)\n",
    "    #print(\"x: \", x)\n",
    "    y =  tf.cast(y_true[:,1], dtype=tf.float32)\n",
    "    #print(\"y: \", y)\n",
    "    z = tf.abs(tf.subtract(x, y))\n",
    "    #print(\"z: \", z)\n",
    "    # using tf less to construct binary labels\n",
    "    y_b = tf.cast(tf.less(z, 1), tf.float32)\n",
    "\n",
    "    margin = 0.5\n",
    "    square_pred = tf.square(y_pred)\n",
    "    margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
    "    return tf.reduce_mean((1 - y_b) * square_pred + (y_b) * margin_square)\n",
    "\n",
    "# get first 4 values of y_train2\n",
    "#y_true2 = y_train2[:4, :]\n",
    "\n",
    "# test contrastive_loss_2\n",
    "y_true = np.array([[0, 0], [2, 1], [0, 3], [3, 3]])\n",
    "y_pred = np.array([0.09, 0.85, 0.95, 0.92])\n",
    "\n",
    "#print(contrastive_loss_2(y_true2, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # from https://github.com/keras-team/keras/blob/v3.0.2/keras/metrics/accuracy_metrics.py#L18 \\nfrom keras import backend\\nfrom keras import ops\\nfrom keras.losses.loss import squeeze_to_same_rank\\n\\ndef binary_accuracy(y_true, y_pred, threshold=0.5):\\n    y_true = ops.convert_to_tensor(y_true)\\n    y_pred = ops.convert_to_tensor(y_pred)\\n    y_true, y_pred = squeeze_to_same_rank(y_true, y_pred)\\n    threshold = ops.cast(threshold, y_pred.dtype)\\n    y_pred = ops.cast(y_pred > threshold, y_true.dtype)\\n    return ops.mean(\\n        ops.cast(ops.equal(y_true, y_pred), dtype=backend.floatx()),\\n        axis=-1,\\n    )\\n '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # from https://github.com/keras-team/keras/blob/v3.0.2/keras/metrics/accuracy_metrics.py#L18 \n",
    "from keras import backend\n",
    "from keras import ops\n",
    "from keras.losses.loss import squeeze_to_same_rank\n",
    "\n",
    "def binary_accuracy(y_true, y_pred, threshold=0.5):\n",
    "    y_true = ops.convert_to_tensor(y_true)\n",
    "    y_pred = ops.convert_to_tensor(y_pred)\n",
    "    y_true, y_pred = squeeze_to_same_rank(y_true, y_pred)\n",
    "    threshold = ops.cast(threshold, y_pred.dtype)\n",
    "    y_pred = ops.cast(y_pred > threshold, y_true.dtype)\n",
    "    return ops.mean(\n",
    "        ops.cast(ops.equal(y_true, y_pred), dtype=backend.floatx()),\n",
    "        axis=-1,\n",
    "    )\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy_with_threshold(y_true, y_pred, threshold=0.5): # WORKS!!!\n",
    "    # Ensure the predicted values are between 0 and 1\n",
    "    y_pred = tf.clip_by_value(y_pred, 0, 1)\n",
    "\n",
    "    # Convert the predicted values to binary (0 or 1) using the specified threshold\n",
    "    y_pred_binary = tf.cast(tf.greater_equal(y_pred, threshold), tf.float32)\n",
    "\n",
    "    # Calculate the binary accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_true, y_pred_binary), tf.float32))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-08 16:45:27.973019: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def binary_accuracy_with_threshold_2(y_true, y_pred, threshold=0.4):\n",
    "    # Ensure that y_true is of type float32\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "    \n",
    "    # Ensure the predicted values are between 0 and 1\n",
    "    y_1 = tf.cast(y_true[:,0], tf.float32)\n",
    "    y_2 = tf.cast(y_true[:,1], tf.float32)\n",
    "    \n",
    "    # y_true_b is 0 if y_1 and y_2 are equal, 1 otherwise\n",
    "    # give a margin of 0.25\n",
    "    #y_true_b = tf.cast(tf.less(tf.abs(tf.subtract(y_1, y_2)), 0.25), tf.float32)\n",
    "    y_true_b = tf.cast(tf.not_equal(y_1, y_2), tf.float32)\n",
    "\n",
    "    # Ensure the predicted values are between 0 and 1\n",
    "    y_pred = tf.clip_by_value(y_pred, 0, 1)\n",
    "    # Convert the predicted values to binary (0 or 1) using the specified threshold\n",
    "    y_pred_binary = tf.cast(tf.greater_equal(y_pred, threshold), tf.float32)\n",
    "\n",
    "    # Calculate the binary accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_true_b, y_pred_binary), tf.float32))\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# test accuracy_2\n",
    "y_true = np.array([[0, 0], [2, 1], [0, 3], [3, 3]])\n",
    "y_pred = np.array([0.1, 0.85, 0.95, 0.3])\n",
    "\n",
    "print(binary_accuracy_with_threshold_2(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_1:  tf.Tensor([0. 2. 0. 3.], shape=(4,), dtype=float32)\n",
      "y_2:  tf.Tensor([0. 1. 3. 3.], shape=(4,), dtype=float32)\n",
      "y_true_b:  tf.Tensor([0. 1. 1. 0.], shape=(4,), dtype=float32)\n",
      "tf.Tensor(0.25375003, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def contrastive_loss_with_margin_2(y_true, y_pred):\n",
    "\n",
    "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
    "    #                         true_value * square( max(margin-prediction, 0) ))\n",
    "    #def contrastive_loss(y_true, y_pred):\n",
    "    margin=1\n",
    "    # Ensure that y_true is of type float32\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "    \n",
    "    # Ensure the predicted values are between 0 and 1\n",
    "    y_1 = y_true[:,0]\n",
    "    y_2 = y_true[:,1]\n",
    "    \n",
    "    print(\"y_1: \", y_1)\n",
    "    print(\"y_2: \", y_2)\n",
    "    \n",
    "    # y_true_b is 0 if y_1 and y_2 are equal, 1 otherwise\n",
    "    y_true_b = tf.cast(tf.not_equal(y_true[:,0], y_true[:,1]), tf.float32)\n",
    "\n",
    "    \n",
    "    # print y_true_b\n",
    "    print(\"y_true_b: \", y_true_b)\n",
    "\n",
    "    square_pred = tf.square(y_pred)\n",
    "    margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
    "    return tf.reduce_mean((1 - y_true_b) * square_pred + (y_true_b) * margin_square)\n",
    "\n",
    "    #return contrastive_loss\n",
    "\n",
    "y_true = np.array([[0, 0], [2, 1], [0, 3], [3, 3]])\n",
    "y_pred = np.array([0.1, 0.95, 0.95, 1])\n",
    "\n",
    "\n",
    "# test contrastive_loss_with_margin_2\n",
    "print(contrastive_loss_with_margin_2(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true:  tf.Tensor([0. 1. 1. 0.], shape=(4,), dtype=float32)\n",
      "y_pred:  tf.Tensor([0.1  0.95 0.95 1.  ], shape=(4,), dtype=float32)\n",
      "tf.Tensor(0.25375003, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "        \"\"\"Calculates the contrastive loss.\n",
    "\n",
    "        Arguments:\n",
    "            y_true: List of labels, each label is of type float32.\n",
    "            y_pred: List of predictions of same length as of y_true,\n",
    "                    each label is of type float32.\n",
    "\n",
    "        Returns:\n",
    "            A tensor containing contrastive loss as floating point value.\n",
    "        \"\"\"\n",
    "        margin=1\n",
    "        # cast y_true to float32 and y_pred to float32\n",
    "        y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "\n",
    "        # print y_true and y_pred\n",
    "        print(\"y_true: \", y_true)\n",
    "        print(\"y_pred: \", y_pred)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
    "        return tf.reduce_mean((1 - y_true) * square_pred + (y_true) * margin_square)\n",
    "\n",
    "y_true_b = np.array([0, 1, 1, 0])\n",
    "y_pred = np.array([0.1, 0.95, 0.95, 1])\n",
    "\n",
    "# test contrastive_loss\n",
    "print(contrastive_loss(y_true_b, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (320, 320, 1)\n",
    "embedding_dim= 128\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "encoder = create_encoder(input_shape)\n",
    "encoder_with_projection_head = add_projection_head(input_shape, encoder, embedding_dim)\n",
    "\n",
    "manta = Input(shape=input_shape)\n",
    "xiris = Input(shape=input_shape)\n",
    "manta_encoded = encoder_with_projection_head(manta)\n",
    "xiris_encoded = encoder_with_projection_head(xiris)\n",
    "distance = tf.abs(manta_encoded - xiris_encoded)\n",
    "output = tf.keras.layers.Dense(1, activation=\"linear\")(distance)\n",
    "siamese_net = tf.keras.Model(inputs=[manta, xiris], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/vm/laser/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_349637/3342900744.py\", line 17, in contrastive_loss  *\n        y_2 = y_true[:, 1]\n\n    ValueError: slice index 1 of dimension 1 out of bounds. for '{{node contrastive_loss/strided_slice_1}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2](contrastive_loss/Cast, contrastive_loss/strided_slice_1/stack, contrastive_loss/strided_slice_1/stack_1, contrastive_loss/strided_slice_1/stack_2)' with input shapes: [?,1], [2], [2], [2] and with computed input tensors: input[1] = <0 1>, input[2] = <0 2>, input[3] = <1 1>.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 103\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n\u001b[1;32m     98\u001b[0m siamese_net\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     99\u001b[0m     loss\u001b[38;5;241m=\u001b[39mcontrastive_loss,\n\u001b[1;32m    100\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate),\n\u001b[1;32m    101\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[binary_accuracy_with_threshold]\n\u001b[1;32m    102\u001b[0m )\n\u001b[0;32m--> 103\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43msiamese_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mX_train2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# [X_train[:, 0], X_train[:, 1]]\u001b[39;49;00m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43my_train2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43my_train2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\n\u001b[1;32m    109\u001b[0m \u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filefr_v9nei.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file44m2ll4s.py:24\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__contrastive_loss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     22\u001b[0m y_true \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mld(y_true),), \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mfloat32), fscope)\n\u001b[1;32m     23\u001b[0m y_1 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(y_true)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 24\u001b[0m y_2 \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m y_true_b \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mnot_equal, (ag__\u001b[38;5;241m.\u001b[39mld(y_1), ag__\u001b[38;5;241m.\u001b[39mld(y_2)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope), ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mfloat32), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     26\u001b[0m square_pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39msquare, (ag__\u001b[38;5;241m.\u001b[39mld(y_pred),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/vm/laser/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_349637/3342900744.py\", line 17, in contrastive_loss  *\n        y_2 = y_true[:, 1]\n\n    ValueError: slice index 1 of dimension 1 out of bounds. for '{{node contrastive_loss/strided_slice_1}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2](contrastive_loss/Cast, contrastive_loss/strided_slice_1/stack, contrastive_loss/strided_slice_1/stack_1, contrastive_loss/strided_slice_1/stack_2)' with input shapes: [?,1], [2], [2], [2] and with computed input tensors: input[1] = <0 1>, input[2] = <0 2>, input[3] = <1 1>.\n"
     ]
    }
   ],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    \"\"\"Calculates the contrastive loss.\n",
    "\n",
    "    Arguments:\n",
    "        y_true: Tensor of shape (n, 2), where n is the number of samples.\n",
    "               Each row corresponds to a pair of labels.\n",
    "        y_pred: List of predictions of same length as of y_true,\n",
    "                each label is of type float32.\n",
    "\n",
    "    Returns:\n",
    "        A tensor containing contrastive loss as a floating point value.\n",
    "    \"\"\"\n",
    "    margin = 1\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "\n",
    "    y_1 = y_true[:, 0]\n",
    "    y_2 = y_true[:, 1]\n",
    "\n",
    "    y_true_b = tf.cast(tf.not_equal(y_1, y_2), tf.float32)\n",
    "\n",
    "    square_pred = tf.square(y_pred)\n",
    "    margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
    "    return tf.reduce_mean((1 - y_true_b) * square_pred + (y_true_b) * margin_square)\n",
    "\n",
    "\n",
    "def binary_accuracy_with_threshold(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"Calculates binary accuracy with a threshold for siamese networks.\n",
    "\n",
    "    Arguments:\n",
    "        y_true: Tensor of shape (n, 2), where n is the number of samples.\n",
    "               Each row corresponds to a pair of labels.\n",
    "        y_pred: List of predictions of same length as of y_true,\n",
    "                each label is of type float32.\n",
    "        threshold: Threshold value for predictions.\n",
    "\n",
    "    Returns:\n",
    "        A tensor containing binary accuracy as a floating point value.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    y_1 = y_true[:, 0]\n",
    "    y_2 = y_true[:, 1]\n",
    "\n",
    "    y_pred_binary = tf.cast(y_pred > threshold, tf.float32)\n",
    "    correct_predictions = tf.cast(tf.equal(y_pred_binary, tf.math.not_equal(y_1, y_2)), tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(correct_predictions)\n",
    "\n",
    "def binary_accuracy_with_threshold(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"Calculates binary accuracy with a threshold for siamese networks.\n",
    "\n",
    "    Arguments:\n",
    "        y_true: Tensor of shape (n, 2), where n is the number of samples.\n",
    "               Each row corresponds to a pair of labels.\n",
    "        y_pred: List of predictions of same length as of y_true,\n",
    "                each label is of type float32.\n",
    "        threshold: Threshold value for predictions.\n",
    "\n",
    "    Returns:\n",
    "        A tensor containing binary accuracy as a floating point value.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    y_1 = y_true[:, 0]\n",
    "    y_2 = y_true[:, 1]\n",
    "\n",
    "    y_pred_binary = tf.cast(y_pred > threshold, tf.float32)\n",
    "    not_equal_float32 = tf.cast(tf.math.not_equal(y_1, y_2), tf.float32)\n",
    "    correct_predictions = tf.cast(tf.equal(y_pred_binary, not_equal_float32), tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(correct_predictions)\n",
    "\n",
    "def binary_accuracy_with_threshold(y_true, y_pred, threshold=0.4):\n",
    "    \"\"\"Calculates binary accuracy with a threshold for siamese networks.\"\"\"  \n",
    "    # Ensure the predicted values are between 0 and 1\n",
    "    y_1 = tf.cast(y_true[:,0], tf.float32)\n",
    "    y_2 = tf.cast(y_true[:,1], tf.float32)\n",
    "    \n",
    "    print(\"y_1: \", y_1)\n",
    "    print(\"y_2: \", y_2)\n",
    "    \n",
    "    # y_true_b is 0 if y_1 and y_2 are equal, 1 otherwise\n",
    "    # give a margin of 0.25\n",
    "    #y_true_b = tf.cast(tf.less(tf.abs(tf.subtract(y_1, y_2)), 0.25), tf.float32)\n",
    "    y_true_b = tf.cast(tf.not_equal(y_1, y_2), tf.float32)\n",
    "    \n",
    "    print(\"y_true_b: \", y_true_b)\n",
    "\n",
    "    # Ensure the predicted values are between 0 and 1\n",
    "    y_pred = tf.clip_by_value(y_pred, 0, 1)\n",
    "    # Convert the predicted values to binary (0 or 1) using the specified threshold\n",
    "    y_pred_binary = tf.cast(tf.greater_equal(y_pred, threshold), tf.float32)\n",
    "\n",
    "    # Calculate the binary accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_true_b, y_pred_binary), tf.float32))\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "siamese_net.compile(\n",
    "    loss=contrastive_loss,\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    metrics=[binary_accuracy_with_threshold]\n",
    ")\n",
    "history = siamese_net.fit(\n",
    "    x=[X_train2[:, 0], X_train2[:, 1]], # [X_train[:, 0], X_train[:, 1]]\n",
    "    y=[y_train2[:,0],  y_train2[:,1]], \n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)        [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " model_4 (Functional)        (None, 128)                  2492499   ['input_7[0][0]',             \n",
      "                                                          2          'input_8[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLa  (None, 128)                  0         ['model_4[0][0]',             \n",
      " mbda)                                                               'model_4[1][0]']             \n",
      "                                                                                                  \n",
      " tf.math.abs_1 (TFOpLambda)  (None, 128)                  0         ['tf.math.subtract_1[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    129       ['tf.math.abs_1[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24925121 (95.08 MB)\n",
      "Trainable params: 24925121 (95.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/vm/laser/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_349637/1246668639.py\", line 13, in contrastive_loss_with_margin_2  *\n        y_2 = y_true[:,1]\n\n    ValueError: slice index 1 of dimension 1 out of bounds. for '{{node contrastive_loss_with_margin_2/strided_slice_1}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2](contrastive_loss_with_margin_2/Cast, contrastive_loss_with_margin_2/strided_slice_1/stack, contrastive_loss_with_margin_2/strided_slice_1/stack_1, contrastive_loss_with_margin_2/strided_slice_1/stack_2)' with input shapes: [?,1], [2], [2], [2] and with computed input tensors: input[1] = <0 1>, input[2] = <0 2>, input[3] = <1 1>.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 25\u001b[0m\n\u001b[1;32m     20\u001b[0m siamese_net\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mcontrastive_loss_with_margin_2,\u001b[38;5;66;03m#contrastive_loss_with_margin(margin=1), #contrastive_loss_2,  #contrastive_loss_with_margin2(margin=1.0)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m                     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate), \n\u001b[1;32m     22\u001b[0m                     metrics\u001b[38;5;241m=\u001b[39m[binary_accuracy_with_threshold_2] \u001b[38;5;66;03m#['binary_accuracy']#[tf.keras.metrics.binary_accuracy] # ['accuracy']  # [tf.keras.metrics.Accuracy()])#[accuracy_3]) # accuracy #'accuracy'\u001b[39;00m\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m siamese_net\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m---> 25\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43msiamese_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mX_train2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# [X_train[:, 0], X_train[:, 1]]\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43my_train2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43my_train2\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\n\u001b[1;32m     31\u001b[0m \u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filefr_v9nei.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filec__kubji.py:14\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__contrastive_loss_with_margin\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     12\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mld(y_pred),), \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mfloat32), fscope)\n\u001b[1;32m     13\u001b[0m y_1 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(y_true)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m y_2 \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_1: \u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mld(y_1))\n\u001b[1;32m     16\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mprint\u001b[39m)(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_2: \u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mld(y_2))\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/vm/laser/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_349637/1246668639.py\", line 13, in contrastive_loss_with_margin_2  *\n        y_2 = y_true[:,1]\n\n    ValueError: slice index 1 of dimension 1 out of bounds. for '{{node contrastive_loss_with_margin_2/strided_slice_1}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2](contrastive_loss_with_margin_2/Cast, contrastive_loss_with_margin_2/strided_slice_1/stack, contrastive_loss_with_margin_2/strided_slice_1/stack_1, contrastive_loss_with_margin_2/strided_slice_1/stack_2)' with input shapes: [?,1], [2], [2], [2] and with computed input tensors: input[1] = <0 1>, input[2] = <0 2>, input[3] = <1 1>.\n"
     ]
    }
   ],
   "source": [
    "input_shape = (320, 320, 1)\n",
    "embedding_dim= 128\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "encoder = create_encoder(input_shape)\n",
    "encoder_with_projection_head = add_projection_head(input_shape, encoder, embedding_dim)\n",
    "\n",
    "manta = Input(shape=input_shape)\n",
    "xiris = Input(shape=input_shape)\n",
    "manta_encoded = encoder_with_projection_head(manta)\n",
    "xiris_encoded = encoder_with_projection_head(xiris)\n",
    "# Assuming encoded_l and encoded_r are your two input tensors\n",
    "distance = tf.abs(manta_encoded - xiris_encoded)\n",
    "output = tf.keras.layers.Dense(1, activation=\"linear\")(distance)\n",
    "\n",
    "siamese_net = tf.keras.Model(inputs=[manta, xiris], outputs=output)\n",
    "\n",
    "siamese_net.compile(loss=contrastive_loss_with_margin_2,#contrastive_loss_with_margin(margin=1), #contrastive_loss_2,  #contrastive_loss_with_margin2(margin=1.0)\n",
    "                    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                    metrics=[binary_accuracy_with_threshold_2] #['binary_accuracy']#[tf.keras.metrics.binary_accuracy] # ['accuracy']  # [tf.keras.metrics.Accuracy()])#[accuracy_3]) # accuracy #'accuracy'\n",
    ")\n",
    "siamese_net.summary()\n",
    "history = siamese_net.fit(\n",
    "    x=[X_train2[:, 0], X_train2[:, 1]], # [X_train[:, 0], X_train[:, 1]]\n",
    "    y=[y_train2[:,0],  y_train2[:,1]], \n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' input_shape = (320, 320, 1)\\nembedding_dim= 128\\nbatch_size = 64\\nepochs = 2\\nlearning_rate = 0.001\\n\\nencoder = create_encoder(input_shape)\\nencoder_with_projection_head = add_projection_head(input_shape, encoder, embedding_dim)\\n\\nmanta = Input(shape=input_shape)\\nxiris = Input(shape=input_shape)\\nmanta_encoded = encoder_with_projection_head(manta)\\nxiris_encoded = encoder_with_projection_head(xiris)\\n# Assuming encoded_l and encoded_r are your two input tensors\\ndistance = tf.abs(manta_encoded - xiris_encoded)\\noutput = tf.keras.layers.Dense(1, activation=\"linear\")(distance)\\n\\nsiamese_net = tf.keras.Model(inputs=[manta, xiris], outputs=output)\\n\\nsiamese_net.compile(loss=contrastive_loss_with_margin(margin=1), #contrastive_loss_2,  #contrastive_loss_with_margin2(margin=1.0)\\n                    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \\n                    metrics=[binary_accuracy_with_threshold] #[\\'binary_accuracy\\']#[tf.keras.metrics.binary_accuracy] # [\\'accuracy\\']  # [tf.keras.metrics.Accuracy()])#[accuracy_3]) # accuracy #\\'accuracy\\'\\n)\\nsiamese_net.summary()\\nhistory = siamese_net.fit(\\n    [X_train[:, 0], X_train[:, 1]],\\n    # only the first two columns of y_train are needed\\n    y_train, #y_train2,     #y_train,\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    validation_split=0.2\\n) '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" input_shape = (320, 320, 1)\n",
    "embedding_dim= 128\n",
    "batch_size = 64\n",
    "epochs = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "encoder = create_encoder(input_shape)\n",
    "encoder_with_projection_head = add_projection_head(input_shape, encoder, embedding_dim)\n",
    "\n",
    "manta = Input(shape=input_shape)\n",
    "xiris = Input(shape=input_shape)\n",
    "manta_encoded = encoder_with_projection_head(manta)\n",
    "xiris_encoded = encoder_with_projection_head(xiris)\n",
    "# Assuming encoded_l and encoded_r are your two input tensors\n",
    "distance = tf.abs(manta_encoded - xiris_encoded)\n",
    "output = tf.keras.layers.Dense(1, activation=\"linear\")(distance)\n",
    "\n",
    "siamese_net = tf.keras.Model(inputs=[manta, xiris], outputs=output)\n",
    "\n",
    "siamese_net.compile(loss=contrastive_loss_with_margin(margin=1), #contrastive_loss_2,  #contrastive_loss_with_margin2(margin=1.0)\n",
    "                    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                    metrics=[binary_accuracy_with_threshold] #['binary_accuracy']#[tf.keras.metrics.binary_accuracy] # ['accuracy']  # [tf.keras.metrics.Accuracy()])#[accuracy_3]) # accuracy #'accuracy'\n",
    ")\n",
    "siamese_net.summary()\n",
    "history = siamese_net.fit(\n",
    "    [X_train[:, 0], X_train[:, 1]],\n",
    "    # only the first two columns of y_train are needed\n",
    "    y_train, #y_train2,     #y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2\n",
    ") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model siamese_net\n",
    "#del siamese_net"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
