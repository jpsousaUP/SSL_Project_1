{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 18:50:44.249241: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-12 18:50:44.325964: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-12 18:50:44.326006: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-12 18:50:44.328321: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-12 18:50:44.343099: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-12 18:50:45.197029: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_838678/3769053210.py:7: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n",
      "Setting memory growth to True for GPU:  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 18:50:46.670309: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:50:46.728969: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:50:46.729145: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:50:46.807317: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:50:46.807453: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:50:46.807550: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:50:46.807628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "2024-01-12 18:50:46.809493: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:50:46.809675: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:50:46.809762: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
    "import numpy as np\n",
    "\n",
    "# verify if GPU is available\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "# set memory growth to true\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Setting memory growth to True for GPU: \", physical_devices[0])\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# dont display much info of tensorflow\n",
    "tf.get_logger().setLevel('ERROR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manta shape:  (9587, 320, 320)\n",
      "xiris shape:  (9587, 320, 320)\n",
      "y shape:  (9587, 2)\n",
      "y shape:  (9587, 2)\n",
      "max of each column:  [2750   15]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "manta_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_manta.npy\"\n",
    "xiris_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_xiris.npy\"\n",
    "y_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_y.npy\"\n",
    "feats_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_feats.npy\"\n",
    "\n",
    "# load numpy arrays and display shapes\n",
    "manta = np.load(manta_path)\n",
    "xiris = np.load(xiris_path)\n",
    "y = np.load(y_path)\n",
    "print(\"manta shape: \", manta.shape)\n",
    "print(\"xiris shape: \", xiris.shape)\n",
    "print(\"y shape: \", y.shape) # laser power and velocity\n",
    "\n",
    "\"\"\" #feats = np.load(feats_path)\n",
    "#print(\"feats shape: \", feats.shape)\n",
    "y = y[:, 0] # only use laser power\n",
    "print(\"y shape: \", y.shape)\n",
    "\n",
    "# normalize y\n",
    "y = y / np.max(y) \"\"\"\n",
    "\n",
    "# use laser power and velocity as labels\n",
    "y = y[:, :2]\n",
    "print(\"y shape: \", y.shape)\n",
    "\n",
    "# print max of each column\n",
    "print(\"max of each column: \", np.max(y, axis=0))\n",
    "# normalize y by dividing laser power by max of each column\n",
    "y = y / np.max(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9587, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create a function to encode y\n",
    "def encode_one_column(y):\n",
    "    # create a new array of zeros with the same shape as y\n",
    "    encoded_y = np.zeros(y.shape)\n",
    "    # get the unique values in y\n",
    "    unique_values = np.unique(y)\n",
    "    # loop through the unique values\n",
    "    for i, value in enumerate(unique_values):\n",
    "        # find the indices where y equals the unique value\n",
    "        indices = np.where(y == value)\n",
    "        # set the indices in encoded_y to i\n",
    "        encoded_y[indices] = i\n",
    "    return encoded_y\n",
    "\n",
    "# create new array to store encoded y\n",
    "y_encoded = np.zeros(y.shape)\n",
    "# loop through each column in y and encode it\n",
    "for i in range(y.shape[1]):\n",
    "    y_encoded[:, i] = encode_one_column(y[:, i])\n",
    "    \n",
    "# convert to int\n",
    "y_encoded = y_encoded.astype(int)\n",
    "y_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  (19174, 320, 320)\n",
      "y shape:  (19174, 2)\n",
      "x_train shape:  (15339, 320, 320)\n",
      "y_train shape:  (15339, 2)\n",
      "x_test shape:  (3835, 320, 320)\n",
      "y_test shape:  (3835, 2)\n"
     ]
    }
   ],
   "source": [
    "# concatenate manta and xiris images with label y_encoded as rows\n",
    "# concatenate the two inputs (manta and xiris) along rows\n",
    "x = np.concatenate((manta, xiris), axis=0)\n",
    "y = np.concatenate((y_encoded, y_encoded), axis=0)\n",
    "print(\"x shape: \", x.shape)\n",
    "print(\"y shape: \", y.shape)\n",
    "\n",
    "# split data into train and test (manta as input and y as output) with shuffle as true\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "print(\"x_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"x_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del manta, xiris, y, y_encoded, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " model_2 (Functional)        (None, 194688)               4800      ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " contrastive_output_0 (Dens  (None, 128)                  2492019   ['model_2[0][0]']             \n",
      " e)                                                       2                                       \n",
      "                                                                                                  \n",
      " contrastive_output_1 (Dens  (None, 128)                  2492019   ['model_2[0][0]']             \n",
      " e)                                                       2                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 49845184 (190.14 MB)\n",
      "Trainable params: 49845184 (190.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/4\n",
      "192/192 - 11s - loss: 7.6583 - val_loss: 0.0000e+00 - 11s/epoch - 58ms/step\n",
      "Epoch 2/4\n",
      "192/192 - 7s - loss: 6.7920 - val_loss: 0.0000e+00 - 7s/epoch - 37ms/step\n",
      "Epoch 3/4\n",
      "192/192 - 7s - loss: 6.4246 - val_loss: 0.0000e+00 - 7s/epoch - 38ms/step\n",
      "Epoch 4/4\n",
      "192/192 - 7s - loss: 6.2843 - val_loss: 0.0000e+00 - 7s/epoch - 38ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def create_encoder(input_shape=(320, 320, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "def add_contrastive_and_regression_heads(input_shape, encoder, embedding_dim, num_tasks):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "\n",
    "    # Add dense layers for contrastive tasks\n",
    "    contrastive_outputs = [Dense(embedding_dim, activation='linear', name=f\"contrastive_output_{i}\")(features) for i in range(num_tasks)]\n",
    "\n",
    "    # Add dense layers for regression tasks\n",
    "    #regression_outputs = [Dense(1, activation='linear', name=f\"regression_output_{i}\")(features) for i in range(num_tasks)]\n",
    "\n",
    "    # Concatenate contrastive and regression outputs\n",
    "    all_outputs = contrastive_outputs #+ regression_outputs\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=all_outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (320, 320, 1)\n",
    "embedding_dim = 128\n",
    "num_tasks = 2\n",
    "\n",
    "encoder = create_encoder(input_shape=input_shape)\n",
    "SupCR = add_contrastive_and_regression_heads(input_shape=input_shape, encoder=encoder, embedding_dim=embedding_dim, num_tasks=num_tasks)\n",
    "SupCR.summary()\n",
    "\n",
    "class SupervidedContrastiveModel(Model):\n",
    "    def __init__(self, SupervisedContrastiveModel, temperature=0.05, optimizer=None):\n",
    "        super(SupervidedContrastiveModel, self).__init__()\n",
    "        self.SupervisedContrastiveModel = SupervisedContrastiveModel\n",
    "        self.temperature = temperature\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.contrastive_loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.SupervisedContrastiveModel(inputs)\n",
    "    \n",
    "    def Supervised_Contrastive_Loss(self, labels, feature_vectors):\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        # Unpack the data\n",
    "        X, y = data\n",
    "        \n",
    "        # Forward pass through the encoder and the SupervisedContrastiveModel\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.SupervisedContrastiveModel(X, training=True)\n",
    "\n",
    "            # Compute the contrastive loss\n",
    "            contrastive_loss = sum([self.Supervised_Contrastive_Loss(y[:, i], y_pred[i]) for i in range(num_tasks)])\n",
    "            \n",
    "            # Compute the mean squared error loss for regression tasks\n",
    "            #regression_loss = sum([tf.keras.losses.MeanSquaredError()(y[:, i], y_pred[num_tasks+i]) for i in range(num_tasks)])\n",
    "            \n",
    "            # Combine the losses\n",
    "            loss = contrastive_loss #+ regression_loss\n",
    "            \n",
    "        # Backpropagation\n",
    "        gradients = tape.gradient(loss, self.SupervisedContrastiveModel.trainable_weights)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.SupervisedContrastiveModel.trainable_weights))\n",
    "        \n",
    "        # Update loss tracker\n",
    "        self.contrastive_loss_tracker.update_state(loss)\n",
    "        \n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {\"loss\": self.contrastive_loss_tracker.result()}\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.contrastive_loss_tracker]\n",
    "\n",
    "# create model\n",
    "model = SupervidedContrastiveModel(SupCR, temperature=0.05, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "model.compile()\n",
    "\n",
    "# Assuming you have X_train and y_train defined\n",
    "batch_size = 64\n",
    "epochs = 4\n",
    "validation_split = 0.2\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    validation_split=validation_split,\n",
    "                    verbose=2)  # Added verbose argument for visibility during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "192/192 [==============================] - 12s 57ms/step - loss: 3.0744 - val_loss: 0.0000e+00\n",
      "Epoch 2/4\n",
      "120/192 [=================>............] - ETA: 2s - loss: 3.0617"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     64\u001b[0m validation_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m---> 65\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m                    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Added verbose argument for visibility during training\u001b[39;00m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ... (unchanged code)\n",
    "\n",
    "class SupervidedContrastiveModel(Model):\n",
    "    def __init__(self, SupervisedContrastiveModel, temperature=0.05, optimizer=None):\n",
    "        super(SupervidedContrastiveModel, self).__init__()\n",
    "        self.SupervisedContrastiveModel = SupervisedContrastiveModel\n",
    "        self.temperature = temperature\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.contrastive_loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.SupervisedContrastiveModel(inputs)\n",
    "    \n",
    "    def Supervised_Contrastive_Loss(self, labels, feature_vectors):\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        # Unpack the data\n",
    "        X, y = data\n",
    "        \n",
    "        # Forward pass through the encoder and the SupervisedContrastiveModel\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.SupervisedContrastiveModel(X, training=True)\n",
    "            \n",
    "            # Compute the contrastive loss\n",
    "            contrastive_loss = sum([self.Supervised_Contrastive_Loss(y[:, i], y_pred[i]) for i in range(num_tasks)])\n",
    "            \n",
    "            # Scale the contrastive loss\n",
    "            contrastive_loss /= num_tasks\n",
    "            \n",
    "            # Combine the losses\n",
    "            loss = contrastive_loss\n",
    "            \n",
    "        # Backpropagation\n",
    "        gradients = tape.gradient(loss, self.SupervisedContrastiveModel.trainable_weights)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.SupervisedContrastiveModel.trainable_weights))\n",
    "        \n",
    "        # Update loss tracker\n",
    "        self.contrastive_loss_tracker.update_state(contrastive_loss)\n",
    "        \n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {\"loss\": self.contrastive_loss_tracker.result()}\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.contrastive_loss_tracker]\n",
    "\n",
    "# create model\n",
    "model = SupervidedContrastiveModel(SupCR, temperature=0.05, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "model.compile()\n",
    "\n",
    "# Assuming you have X_train and y_train defined\n",
    "batch_size = 64\n",
    "epochs = 4\n",
    "validation_split = 0.2\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    validation_split=validation_split,\n",
    "                    verbose=1)  # Added verbose argument for visibility during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "y_pred :  Tensor(\"model_1/contrastive_output_0/BiasAdd:0\", shape=(None, 64), dtype=float32)\n",
      "y_pred :  Tensor(\"model_1/contrastive_output_0/BiasAdd:0\", shape=(None, 64), dtype=float32)\n",
      "192/192 [==============================] - 11s 51ms/step - loss: 6.3075 - val_loss: 0.0000e+00\n",
      "Epoch 2/4\n",
      "191/192 [============================>.] - ETA: 0s - loss: 6.2561"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 74\u001b[0m\n\u001b[1;32m     72\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     73\u001b[0m validation_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m---> 74\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m                    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/training.py:1856\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1842\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1843\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1855\u001b[0m     )\n\u001b[0;32m-> 1856\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1869\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1871\u001b[0m }\n\u001b[1;32m   1872\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/training.py:2296\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2292\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   2293\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2294\u001b[0m             ):\n\u001b[1;32m   2295\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2296\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2297\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2298\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2299\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2300\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2301\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2303\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2304\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/training.py:4108\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4108\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   4110\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def create_encoder(input_shape=(320, 320, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    # add dense layer\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "def add_contrastive_and_regression_heads(input_shape, encoder, embedding_dim, num_tasks):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "\n",
    "    # Add dense layers for contrastive tasks\n",
    "    contrastive_outputs = [Dense(embedding_dim, activation='linear', name=f\"contrastive_output_{i}\")(features) for i in range(num_tasks)]\n",
    "\n",
    "    # Add dense layers for regression tasks\n",
    "    regression_outputs = [Dense(1, activation='linear', name=f\"regression_output_{i}\")(features) for i in range(num_tasks)]\n",
    "\n",
    "    # Concatenate contrastive and regression outputs\n",
    "    all_outputs = contrastive_outputs + regression_outputs\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=all_outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (320, 320, 1)\n",
    "embedding_dim = 128\n",
    "num_tasks = 2\n",
    "\n",
    "encoder = create_encoder(input_shape=input_shape)\n",
    "SupCR = add_contrastive_and_regression_heads(input_shape=input_shape, encoder=encoder, embedding_dim=64, num_tasks=2)\n",
    "SupCR.summary()\n",
    "\n",
    "class SupervidedContrastiveModel(Model):\n",
    "    def __init__(self, SupervisedContrastiveModel, temperature=0.1):\n",
    "        super(SupervidedContrastiveModel, self).__init__()\n",
    "        self.SupervisedContrastiveModel = SupervisedContrastiveModel\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        self.contrastive_loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.SupervisedContrastiveModel(inputs)\n",
    "    \n",
    "    def Supervised_Contrastive_Loss(self, labels, feature_vectors):\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        # Unpack the data\n",
    "        X, y = data\n",
    "        \n",
    "        # Forward pass through the encoder and the SupervisedContrastiveModel\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.SupervisedContrastiveModel(X, training=True)\n",
    "            \n",
    "            # print the shape of y_pred\n",
    "            print(\"y_pred : \", y_pred[0])\n",
    "            \n",
    "            # Compute the contrastive loss\n",
    "            contrastive_loss = sum([self.Supervised_Contrastive_Loss(y[:, i], y_pred[i]) for i in range(num_tasks)])\n",
    "            \n",
    "            # Compute the mean squared error loss for regression tasks\n",
    "            regression_loss = sum([tf.keras.losses.MeanSquaredError()(y[:, i], y_pred[num_tasks+i]) for i in range(num_tasks)])\n",
    "            \n",
    "            # Combine the losses\n",
    "            loss = contrastive_loss + regression_loss\n",
    "            \n",
    "        # Backpropagation\n",
    "        gradients = tape.gradient(loss, self.SupervisedContrastiveModel.trainable_weights)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.SupervisedContrastiveModel.trainable_weights))\n",
    "        \n",
    "        # update loss tracker\n",
    "        self.contrastive_loss_tracker.update_state(loss)\n",
    "        # return a dict mapping metric names to current value\n",
    "        return {\"loss\": self.contrastive_loss_tracker.result()}\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We list our `Metric` objects here so that `reset_states()` can be\n",
    "        # called automatically at the start of each epoch\n",
    "        # or at the start of `evaluate()`.\n",
    "        # If you don't implement this property, you have to call\n",
    "        # `reset_states()` yourself at the time of your choosing.\n",
    "        return [self.contrastive_loss_tracker]\n",
    "\n",
    "# create model\n",
    "model = SupervidedContrastiveModel(SupCR, temperature=0.1)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "\n",
    "# train model\n",
    "batch_size = 64\n",
    "epochs = 4\n",
    "validation_split = 0.2\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs, \n",
    "                    validation_split=validation_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)        [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " model_6 (Functional)        (None, 128)                  2492499   ['input_8[0][0]']             \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " regression_output_0 (Dense  (None, 1)                    129       ['model_6[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " regression_output_1 (Dense  (None, 1)                    129       ['model_6[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " contrastive_output_0 (Dens  (None, 128)                  16512     ['model_6[0][0]']             \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " contrastive_output_1 (Dens  (None, 128)                  16512     ['model_6[0][0]']             \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " tf.stop_gradient_2 (TFOpLa  (None, 1)                    0         ['regression_output_0[0][0]'] \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.stop_gradient_3 (TFOpLa  (None, 1)                    0         ['regression_output_1[0][0]'] \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24958274 (95.21 MB)\n",
      "Trainable params: 24958274 (95.21 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "192/192 [==============================] - 14s 64ms/step - loss: 81.4891 - contrastive_output_0_loss: 3.4245 - contrastive_output_1_loss: 4.0480 - tf.stop_gradient_2_loss: 69.6621 - tf.stop_gradient_3_loss: 4.3545 - val_loss: 112.1626 - val_contrastive_output_0_loss: 3.0542 - val_contrastive_output_1_loss: 3.7156 - val_tf.stop_gradient_2_loss: 99.3020 - val_tf.stop_gradient_3_loss: 6.0908\n",
      "Epoch 2/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 46.1554 - contrastive_output_0_loss: 3.0030 - contrastive_output_1_loss: 3.5638 - tf.stop_gradient_2_loss: 34.6799 - tf.stop_gradient_3_loss: 4.9088 - val_loss: 36.2705 - val_contrastive_output_0_loss: 2.9282 - val_contrastive_output_1_loss: 3.4862 - val_tf.stop_gradient_2_loss: 23.4639 - val_tf.stop_gradient_3_loss: 6.3921\n",
      "Epoch 3/20\n",
      "192/192 [==============================] - 9s 48ms/step - loss: 29.6436 - contrastive_output_0_loss: 2.9329 - contrastive_output_1_loss: 3.4503 - tf.stop_gradient_2_loss: 16.8855 - tf.stop_gradient_3_loss: 6.3749 - val_loss: 19.9271 - val_contrastive_output_0_loss: 2.9073 - val_contrastive_output_1_loss: 3.3961 - val_tf.stop_gradient_2_loss: 9.4865 - val_tf.stop_gradient_3_loss: 4.1372\n",
      "Epoch 4/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 20.7201 - contrastive_output_0_loss: 2.9167 - contrastive_output_1_loss: 3.4004 - tf.stop_gradient_2_loss: 9.0529 - tf.stop_gradient_3_loss: 5.3501 - val_loss: 17.4869 - val_contrastive_output_0_loss: 2.8847 - val_contrastive_output_1_loss: 3.3645 - val_tf.stop_gradient_2_loss: 6.1456 - val_tf.stop_gradient_3_loss: 5.0921\n",
      "Epoch 5/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 17.0734 - contrastive_output_0_loss: 2.8989 - contrastive_output_1_loss: 3.3582 - tf.stop_gradient_2_loss: 5.6674 - tf.stop_gradient_3_loss: 5.1488 - val_loss: 13.5488 - val_contrastive_output_0_loss: 2.8878 - val_contrastive_output_1_loss: 3.3487 - val_tf.stop_gradient_2_loss: 4.0317 - val_tf.stop_gradient_3_loss: 3.2806\n",
      "Epoch 6/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 13.5628 - contrastive_output_0_loss: 2.8818 - contrastive_output_1_loss: 3.3126 - tf.stop_gradient_2_loss: 3.8948 - tf.stop_gradient_3_loss: 3.4736 - val_loss: 14.7420 - val_contrastive_output_0_loss: 2.8758 - val_contrastive_output_1_loss: 3.3170 - val_tf.stop_gradient_2_loss: 4.7945 - val_tf.stop_gradient_3_loss: 3.7548\n",
      "Epoch 7/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 13.6583 - contrastive_output_0_loss: 2.8794 - contrastive_output_1_loss: 3.2924 - tf.stop_gradient_2_loss: 3.7193 - tf.stop_gradient_3_loss: 3.7673 - val_loss: 13.6206 - val_contrastive_output_0_loss: 2.8651 - val_contrastive_output_1_loss: 3.2780 - val_tf.stop_gradient_2_loss: 3.4993 - val_tf.stop_gradient_3_loss: 3.9783\n",
      "Epoch 8/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 16.9382 - contrastive_output_0_loss: 2.8585 - contrastive_output_1_loss: 3.2724 - tf.stop_gradient_2_loss: 3.8570 - tf.stop_gradient_3_loss: 6.9503 - val_loss: 19.9221 - val_contrastive_output_0_loss: 2.8609 - val_contrastive_output_1_loss: 3.2828 - val_tf.stop_gradient_2_loss: 2.9692 - val_tf.stop_gradient_3_loss: 10.8092\n",
      "Epoch 9/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 21.2188 - contrastive_output_0_loss: 2.8556 - contrastive_output_1_loss: 3.2600 - tf.stop_gradient_2_loss: 4.5345 - tf.stop_gradient_3_loss: 10.5686 - val_loss: 24.4348 - val_contrastive_output_0_loss: 2.8521 - val_contrastive_output_1_loss: 3.2707 - val_tf.stop_gradient_2_loss: 6.0765 - val_tf.stop_gradient_3_loss: 12.2354\n",
      "Epoch 10/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 27.0467 - contrastive_output_0_loss: 2.8531 - contrastive_output_1_loss: 3.2572 - tf.stop_gradient_2_loss: 4.9435 - tf.stop_gradient_3_loss: 15.9929 - val_loss: 26.2974 - val_contrastive_output_0_loss: 2.8743 - val_contrastive_output_1_loss: 3.2763 - val_tf.stop_gradient_2_loss: 7.0719 - val_tf.stop_gradient_3_loss: 13.0750\n",
      "Epoch 11/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 27.1915 - contrastive_output_0_loss: 2.8473 - contrastive_output_1_loss: 3.2525 - tf.stop_gradient_2_loss: 5.6620 - tf.stop_gradient_3_loss: 15.4296 - val_loss: 30.9825 - val_contrastive_output_0_loss: 2.8374 - val_contrastive_output_1_loss: 3.2629 - val_tf.stop_gradient_2_loss: 5.7812 - val_tf.stop_gradient_3_loss: 19.1010\n",
      "Epoch 12/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 26.7800 - contrastive_output_0_loss: 2.8441 - contrastive_output_1_loss: 3.2415 - tf.stop_gradient_2_loss: 5.7339 - tf.stop_gradient_3_loss: 14.9606 - val_loss: 35.5430 - val_contrastive_output_0_loss: 2.8328 - val_contrastive_output_1_loss: 3.2714 - val_tf.stop_gradient_2_loss: 7.1974 - val_tf.stop_gradient_3_loss: 22.2414\n",
      "Epoch 13/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 34.0361 - contrastive_output_0_loss: 2.8338 - contrastive_output_1_loss: 3.2383 - tf.stop_gradient_2_loss: 7.1410 - tf.stop_gradient_3_loss: 20.8230 - val_loss: 37.5084 - val_contrastive_output_0_loss: 2.8302 - val_contrastive_output_1_loss: 3.2486 - val_tf.stop_gradient_2_loss: 7.9145 - val_tf.stop_gradient_3_loss: 23.5151\n",
      "Epoch 14/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 32.9822 - contrastive_output_0_loss: 2.8318 - contrastive_output_1_loss: 3.2308 - tf.stop_gradient_2_loss: 6.0363 - tf.stop_gradient_3_loss: 20.8834 - val_loss: 31.4128 - val_contrastive_output_0_loss: 2.8324 - val_contrastive_output_1_loss: 3.2514 - val_tf.stop_gradient_2_loss: 5.3545 - val_tf.stop_gradient_3_loss: 19.9745\n",
      "Epoch 15/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 29.1277 - contrastive_output_0_loss: 2.8286 - contrastive_output_1_loss: 3.2280 - tf.stop_gradient_2_loss: 5.1423 - tf.stop_gradient_3_loss: 17.9287 - val_loss: 36.4561 - val_contrastive_output_0_loss: 2.8456 - val_contrastive_output_1_loss: 3.2527 - val_tf.stop_gradient_2_loss: 7.2332 - val_tf.stop_gradient_3_loss: 23.1246\n",
      "Epoch 16/20\n",
      "192/192 [==============================] - 9s 47ms/step - loss: 30.0596 - contrastive_output_0_loss: 2.8305 - contrastive_output_1_loss: 3.2232 - tf.stop_gradient_2_loss: 5.7081 - tf.stop_gradient_3_loss: 18.2977 - val_loss: 34.7168 - val_contrastive_output_0_loss: 2.8321 - val_contrastive_output_1_loss: 3.2491 - val_tf.stop_gradient_2_loss: 5.2371 - val_tf.stop_gradient_3_loss: 23.3984\n",
      "Epoch 17/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 30.5734 - contrastive_output_0_loss: 2.8314 - contrastive_output_1_loss: 3.2243 - tf.stop_gradient_2_loss: 5.1797 - tf.stop_gradient_3_loss: 19.3379 - val_loss: 29.3766 - val_contrastive_output_0_loss: 2.8361 - val_contrastive_output_1_loss: 3.2521 - val_tf.stop_gradient_2_loss: 5.4098 - val_tf.stop_gradient_3_loss: 17.8786\n",
      "Epoch 18/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 27.2180 - contrastive_output_0_loss: 2.8293 - contrastive_output_1_loss: 3.2253 - tf.stop_gradient_2_loss: 6.0226 - tf.stop_gradient_3_loss: 15.1408 - val_loss: 29.4442 - val_contrastive_output_0_loss: 2.8252 - val_contrastive_output_1_loss: 3.2420 - val_tf.stop_gradient_2_loss: 4.9860 - val_tf.stop_gradient_3_loss: 18.3910\n",
      "Epoch 19/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 27.9052 - contrastive_output_0_loss: 2.8213 - contrastive_output_1_loss: 3.2191 - tf.stop_gradient_2_loss: 5.5638 - tf.stop_gradient_3_loss: 16.3011 - val_loss: 25.5442 - val_contrastive_output_0_loss: 2.8207 - val_contrastive_output_1_loss: 3.2528 - val_tf.stop_gradient_2_loss: 5.2500 - val_tf.stop_gradient_3_loss: 14.2208\n",
      "Epoch 20/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 27.3480 - contrastive_output_0_loss: 2.8273 - contrastive_output_1_loss: 3.2231 - tf.stop_gradient_2_loss: 5.1526 - tf.stop_gradient_3_loss: 16.1450 - val_loss: 26.0433 - val_contrastive_output_0_loss: 2.8286 - val_contrastive_output_1_loss: 3.2426 - val_tf.stop_gradient_2_loss: 5.7823 - val_tf.stop_gradient_3_loss: 14.1898\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "class RegressionLoss(tf.keras.losses.Loss):\n",
    "    def __call__(self, labels, predictions, sample_weight=None):\n",
    "        return tf.keras.losses.mean_squared_error(labels, predictions)\n",
    "\n",
    "def create_encoder(input_shape=(320, 320, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    # add dense layer\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "def add_contrastive_and_regression_heads(input_shape, encoder, embedding_dim, num_tasks):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "\n",
    "    # Add dense layers for contrastive tasks\n",
    "    contrastive_outputs = [Dense(embedding_dim, activation='linear', name=f\"contrastive_output_{i}\")(features) for i in range(num_tasks)]\n",
    "\n",
    "    # Add dense layers for regression tasks with gradient stop\n",
    "    regression_outputs = [Dense(1, activation='linear', name=f\"regression_output_{i}\")(features) for i in range(num_tasks)]\n",
    "    regression_outputs_with_stop = [tf.stop_gradient(output) for output in regression_outputs]\n",
    "\n",
    "    # Concatenate contrastive and regression outputs\n",
    "    all_outputs = contrastive_outputs + regression_outputs_with_stop\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=all_outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (320, 320, 1)\n",
    "embedding_dim = 128\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "validation_split = 0.2\n",
    "learning_rate = 0.001\n",
    "num_tasks = 2   # P, V\n",
    "temperature = 0.05\n",
    "\n",
    "# Build model\n",
    "encoder = create_encoder()\n",
    "model_with_contrastive_and_regression = add_contrastive_and_regression_heads(input_shape, encoder, embedding_dim, num_tasks)\n",
    "model_with_contrastive_and_regression.summary()\n",
    "\n",
    "# Compile model\n",
    "model_with_contrastive_and_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                                              loss=[SupervisedContrastiveLoss(temperature=temperature) for _ in range(num_tasks)] + ['mse'] * num_tasks,\n",
    ")\n",
    "# Fit model\n",
    "history = model_with_contrastive_and_regression.fit(\n",
    "    x=X_train, \n",
    "    y=[y_train[:, 0], y_train[:, 1], y_train[:, 0], y_train[:, 1]], \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs, \n",
    "    validation_split=validation_split,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " model_4 (Functional)        (None, 194688)               4800      ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " contrastive_output_0 (Dens  (None, 128)                  2492019   ['model_4[0][0]']             \n",
      " e)                                                       2                                       \n",
      "                                                                                                  \n",
      " contrastive_output_1 (Dens  (None, 128)                  2492019   ['model_4[0][0]']             \n",
      " e)                                                       2                                       \n",
      "                                                                                                  \n",
      " regression_output_0 (Dense  (None, 1)                    194689    ['model_4[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " regression_output_1 (Dense  (None, 1)                    194689    ['model_4[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 50234562 (191.63 MB)\n",
      "Trainable params: 50234562 (191.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "192/192 [==============================] - ETA: 0s - loss: 8.5261 - contrastive_output_0_loss: 3.5769 - contrastive_output_1_loss: 4.0782 - regression_output_0_loss: 0.3352 - regression_output_1_loss: 0.5358"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 71\u001b[0m\n\u001b[1;32m     67\u001b[0m model_with_contrastive_and_regression\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate),\n\u001b[1;32m     68\u001b[0m                                               loss\u001b[38;5;241m=\u001b[39m[SupervisedContrastiveLoss(temperature\u001b[38;5;241m=\u001b[39mtemperature) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_tasks)] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m num_tasks,\n\u001b[1;32m     69\u001b[0m )\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_with_contrastive_and_regression\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m)\u001b[49m; \n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/training.py:1856\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1842\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1843\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1855\u001b[0m     )\n\u001b[0;32m-> 1856\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1869\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1871\u001b[0m }\n\u001b[1;32m   1872\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/training.py:2296\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2292\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   2293\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2294\u001b[0m             ):\n\u001b[1;32m   2295\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2296\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2297\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2298\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2299\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2300\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2301\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2303\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2304\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/training.py:4108\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4108\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   4110\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:918\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[1;32m    913\u001b[0m   filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    914\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(\n\u001b[1;32m    915\u001b[0m           bound_args\n\u001b[1;32m    916\u001b[0m       )\n\u001b[1;32m    917\u001b[0m   )\n\u001b[0;32m--> 918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds):\n\u001b[1;32m    924\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class SupervisedContrastiveLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "def create_encoder(input_shape=(320, 320, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    # add dense layer\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "def add_contrastive_and_regression_heads(input_shape, encoder, embedding_dim, num_tasks):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "\n",
    "    # Add dense layers for contrastive tasks\n",
    "    contrastive_outputs = [Dense(embedding_dim, activation='linear', name=f\"contrastive_output_{i}\")(features) for i in range(num_tasks)]\n",
    "\n",
    "    # Add dense layers for regression tasks\n",
    "    regression_outputs = [Dense(1, activation='linear', name=f\"regression_output_{i}\")(features) for i in range(num_tasks)]\n",
    "\n",
    "    # Concatenate contrastive and regression outputs\n",
    "    all_outputs = contrastive_outputs + regression_outputs\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=all_outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (320, 320, 1)\n",
    "embedding_dim = 128\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "validation_split = 0.2\n",
    "learning_rate = 0.001\n",
    "num_tasks = 2   # P, V\n",
    "temperature = 0.05\n",
    "\n",
    "# Build model\n",
    "encoder = create_encoder()\n",
    "model_with_contrastive_and_regression = add_contrastive_and_regression_heads(input_shape, encoder, embedding_dim, num_tasks)\n",
    "model_with_contrastive_and_regression.summary()\n",
    "\n",
    "# Compile model\n",
    "model_with_contrastive_and_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                                              loss=[SupervisedContrastiveLoss(temperature=temperature) for _ in range(num_tasks)] + ['mse'] * num_tasks,\n",
    ")\n",
    "# Fit model\n",
    "history = model_with_contrastive_and_regression.fit(\n",
    "    x=X_train, \n",
    "    y=[y_train[:, 0], y_train[:, 1], y_train[:, 0], y_train[:, 1]], \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs, \n",
    "    validation_split=validation_split,\n",
    "); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 320, 320, 1)]     0         \n",
      "                                                                 \n",
      " model_22 (Functional)       (None, 194688)            4800      \n",
      "                                                                 \n",
      " contrastive_output_0 (Dens  (None, 128)               24920192  \n",
      " e)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24924992 (95.08 MB)\n",
      "Trainable params: 24924992 (95.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 17:55:30.885192: W external/local_tsl/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.68GiB (rounded to 5026201600)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-01-11 17:55:30.885318: I external/local_tsl/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2024-01-11 17:55:30.885359: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 248, Chunks in use: 248. 62.0KiB allocated for chunks. 62.0KiB in use in bin. 6.9KiB client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885381: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 65, Chunks in use: 64. 40.0KiB allocated for chunks. 39.2KiB in use in bin. 33.8KiB client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885399: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 4, Chunks in use: 4. 4.8KiB allocated for chunks. 4.8KiB in use in bin. 2.7KiB client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885415: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885431: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885445: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885465: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 28, Chunks in use: 26. 532.5KiB allocated for chunks. 490.0KiB in use in bin. 468.0KiB client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885484: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 6, Chunks in use: 6. 205.2KiB allocated for chunks. 205.2KiB in use in bin. 108.0KiB client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885503: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 9, Chunks in use: 9. 880.8KiB allocated for chunks. 880.8KiB in use in bin. 850.8KiB client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885522: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 1, Chunks in use: 1. 191.8KiB allocated for chunks. 191.8KiB in use in bin. 95.9KiB client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885541: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 2, Chunks in use: 2. 671.5KiB allocated for chunks. 671.5KiB in use in bin. 671.1KiB client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885555: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885570: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885614: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885629: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885643: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885660: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 1, Chunks in use: 0. 24.13MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885675: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885697: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 27, Chunks in use: 27. 2.54GiB allocated for chunks. 2.54GiB in use in bin. 2.51GiB client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885718: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 3, Chunks in use: 2. 569.87MiB allocated for chunks. 379.75MiB in use in bin. 190.12MiB client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885737: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 11, Chunks in use: 9. 42.65GiB allocated for chunks. 38.64GiB in use in bin. 38.62GiB client-requested in use in bin.\n",
      "2024-01-11 17:55:30.885754: I external/local_tsl/tsl/framework/bfc_allocator.cc:1062] Bin for 4.68GiB was 256.00MiB, Chunk State: \n",
      "2024-01-11 17:55:30.885795: I external/local_tsl/tsl/framework/bfc_allocator.cc:1068]   Size: 1.13GiB | Requested Size: 4B | in_use: 0 | bin_num: 20, prev:   Size: 95.06MiB | Requested Size: 95.06MiB | in_use: 1 | bin_num: -1, next:   Size: 95.06MiB | Requested Size: 95.06MiB | in_use: 1 | bin_num: -1\n",
      "2024-01-11 17:55:30.885815: I external/local_tsl/tsl/framework/bfc_allocator.cc:1068]   Size: 2.88GiB | Requested Size: 4B | in_use: 0 | bin_num: 20, prev:   Size: 4.68GiB | Requested Size: 4.68GiB | in_use: 1 | bin_num: -1\n",
      "2024-01-11 17:55:30.885827: I external/local_tsl/tsl/framework/bfc_allocator.cc:1075] Next region of size 49149640704\n",
      "2024-01-11 17:55:30.885842: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c000000 of size 1280 next 1\n",
      "2024-01-11 17:55:30.885855: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c000500 of size 256 next 2\n",
      "2024-01-11 17:55:30.885868: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c000600 of size 256 next 3\n",
      "2024-01-11 17:55:30.885879: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c000700 of size 256 next 5\n",
      "2024-01-11 17:55:30.885891: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c000800 of size 256 next 6\n",
      "2024-01-11 17:55:30.885902: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c000900 of size 256 next 4\n",
      "2024-01-11 17:55:30.885912: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c000a00 of size 256 next 7\n",
      "2024-01-11 17:55:30.885924: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c000b00 of size 256 next 12\n",
      "2024-01-11 17:55:30.885934: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c000c00 of size 256 next 10\n",
      "2024-01-11 17:55:30.885945: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c000d00 of size 256 next 11\n",
      "2024-01-11 17:55:30.885956: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c000e00 of size 256 next 15\n",
      "2024-01-11 17:55:30.885967: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c000f00 of size 256 next 8\n",
      "2024-01-11 17:55:30.885979: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c001000 of size 768 next 9\n",
      "2024-01-11 17:55:30.885991: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c001300 of size 512 next 17\n",
      "2024-01-11 17:55:30.886003: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c001500 of size 512 next 20\n",
      "2024-01-11 17:55:30.886014: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c001700 of size 256 next 16\n",
      "2024-01-11 17:55:30.886025: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c001800 of size 256 next 23\n",
      "2024-01-11 17:55:30.886035: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c001900 of size 256 next 22\n",
      "2024-01-11 17:55:30.886047: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c001a00 of size 256 next 24\n",
      "2024-01-11 17:55:30.886060: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c001b00 of size 256 next 29\n",
      "2024-01-11 17:55:30.886071: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c001c00 of size 256 next 25\n",
      "2024-01-11 17:55:30.886082: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c001d00 of size 512 next 26\n",
      "2024-01-11 17:55:30.886094: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c001f00 of size 512 next 27\n",
      "2024-01-11 17:55:30.886104: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c002100 of size 256 next 28\n",
      "2024-01-11 17:55:30.886115: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c002200 of size 256 next 35\n",
      "2024-01-11 17:55:30.886126: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c002300 of size 256 next 36\n",
      "2024-01-11 17:55:30.886137: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c002400 of size 256 next 37\n",
      "2024-01-11 17:55:30.886148: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c002500 of size 256 next 38\n",
      "2024-01-11 17:55:30.886159: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c002600 of size 256 next 39\n",
      "2024-01-11 17:55:30.886170: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c002700 of size 256 next 40\n",
      "2024-01-11 17:55:30.886181: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c002800 of size 256 next 41\n",
      "2024-01-11 17:55:30.886192: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c002900 of size 256 next 42\n",
      "2024-01-11 17:55:30.886203: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c002a00 of size 256 next 43\n",
      "2024-01-11 17:55:30.886213: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c002b00 of size 256 next 44\n",
      "2024-01-11 17:55:30.886224: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c002c00 of size 256 next 45\n",
      "2024-01-11 17:55:30.886235: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c002d00 of size 768 next 46\n",
      "2024-01-11 17:55:30.886246: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c003000 of size 768 next 47\n",
      "2024-01-11 17:55:30.886257: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c003300 of size 256 next 48\n",
      "2024-01-11 17:55:30.886269: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c003400 of size 256 next 49\n",
      "2024-01-11 17:55:30.886280: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c003500 of size 28160 next 14\n",
      "2024-01-11 17:55:30.886292: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c00a300 of size 18432 next 13\n",
      "2024-01-11 17:55:30.886304: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c00eb00 of size 18432 next 33\n",
      "2024-01-11 17:55:30.886315: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c013300 of size 256 next 110\n",
      "2024-01-11 17:55:30.886326: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c013400 of size 256 next 132\n",
      "2024-01-11 17:55:30.886337: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c013500 of size 768 next 96\n",
      "2024-01-11 17:55:30.886348: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c013800 of size 256 next 123\n",
      "2024-01-11 17:55:30.886359: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c013900 of size 256 next 115\n",
      "2024-01-11 17:55:30.886370: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c013a00 of size 256 next 131\n",
      "2024-01-11 17:55:30.886381: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c013b00 of size 256 next 146\n",
      "2024-01-11 17:55:30.886391: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c013c00 of size 256 next 88\n",
      "2024-01-11 17:55:30.886405: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c013d00 of size 256 next 143\n",
      "2024-01-11 17:55:30.886416: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c013e00 of size 256 next 145\n",
      "2024-01-11 17:55:30.886427: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c013f00 of size 256 next 149\n",
      "2024-01-11 17:55:30.886438: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c014000 of size 256 next 136\n",
      "2024-01-11 17:55:30.886449: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c014100 of size 256 next 141\n",
      "2024-01-11 17:55:30.886460: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c014200 of size 24832 next 139\n",
      "2024-01-11 17:55:30.886472: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c01a300 of size 256 next 144\n",
      "2024-01-11 17:55:30.886483: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c01a400 of size 256 next 130\n",
      "2024-01-11 17:55:30.886494: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c01a500 of size 256 next 152\n",
      "2024-01-11 17:55:30.886505: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c01a600 of size 1280 next 155\n",
      "2024-01-11 17:55:30.886516: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c01ab00 of size 768 next 147\n",
      "2024-01-11 17:55:30.886528: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c01ae00 of size 18688 next 142\n",
      "2024-01-11 17:55:30.886539: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c01f700 of size 256 next 135\n",
      "2024-01-11 17:55:30.886551: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c01f800 of size 768 next 148\n",
      "2024-01-11 17:55:30.886562: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c01fb00 of size 256 next 151\n",
      "2024-01-11 17:55:30.886573: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c01fc00 of size 256 next 157\n",
      "2024-01-11 17:55:30.886584: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c01fd00 of size 256 next 124\n",
      "2024-01-11 17:55:30.886595: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c01fe00 of size 256 next 107\n",
      "2024-01-11 17:55:30.886606: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c01ff00 of size 256 next 138\n",
      "2024-01-11 17:55:30.886616: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c020000 of size 256 next 158\n",
      "2024-01-11 17:55:30.886628: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c020100 of size 256 next 159\n",
      "2024-01-11 17:55:30.886638: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c020200 of size 256 next 160\n",
      "2024-01-11 17:55:30.886649: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c020300 of size 256 next 161\n",
      "2024-01-11 17:55:30.886660: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c020400 of size 256 next 162\n",
      "2024-01-11 17:55:30.886671: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c020500 of size 256 next 168\n",
      "2024-01-11 17:55:30.886682: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c020600 of size 256 next 174\n",
      "2024-01-11 17:55:30.886693: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c020700 of size 256 next 166\n",
      "2024-01-11 17:55:30.886704: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c020800 of size 256 next 164\n",
      "2024-01-11 17:55:30.886715: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c020900 of size 256 next 172\n",
      "2024-01-11 17:55:30.886726: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c020a00 of size 256 next 177\n",
      "2024-01-11 17:55:30.886737: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c020b00 of size 256 next 178\n",
      "2024-01-11 17:55:30.886750: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c020c00 of size 768 next 171\n",
      "2024-01-11 17:55:30.886762: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c020f00 of size 768 next 179\n",
      "2024-01-11 17:55:30.886773: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c021200 of size 768 next 165\n",
      "2024-01-11 17:55:30.886784: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c021500 of size 256 next 175\n",
      "2024-01-11 17:55:30.886795: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c021600 of size 256 next 180\n",
      "2024-01-11 17:55:30.886806: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c021700 of size 256 next 167\n",
      "2024-01-11 17:55:30.886816: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c021800 of size 256 next 181\n",
      "2024-01-11 17:55:30.886827: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c021900 of size 256 next 182\n",
      "2024-01-11 17:55:30.886838: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c021a00 of size 256 next 183\n",
      "2024-01-11 17:55:30.886849: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c021b00 of size 256 next 184\n",
      "2024-01-11 17:55:30.886860: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c021c00 of size 256 next 185\n",
      "2024-01-11 17:55:30.886871: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c021d00 of size 256 next 186\n",
      "2024-01-11 17:55:30.886882: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c021e00 of size 256 next 187\n",
      "2024-01-11 17:55:30.886893: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c021f00 of size 256 next 192\n",
      "2024-01-11 17:55:30.886904: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c022000 of size 256 next 205\n",
      "2024-01-11 17:55:30.886915: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c022100 of size 256 next 196\n",
      "2024-01-11 17:55:30.886925: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c022200 of size 256 next 190\n",
      "2024-01-11 17:55:30.886937: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c022300 of size 256 next 193\n",
      "2024-01-11 17:55:30.886947: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c022400 of size 256 next 194\n",
      "2024-01-11 17:55:30.886959: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c022500 of size 256 next 203\n",
      "2024-01-11 17:55:30.886969: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c022600 of size 256 next 210\n",
      "2024-01-11 17:55:30.886980: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c022700 of size 256 next 211\n",
      "2024-01-11 17:55:30.886991: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c022800 of size 256 next 213\n",
      "2024-01-11 17:55:30.887002: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c022900 of size 256 next 134\n",
      "2024-01-11 17:55:30.887013: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c022a00 of size 256 next 121\n",
      "2024-01-11 17:55:30.887024: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c022b00 of size 256 next 81\n",
      "2024-01-11 17:55:30.887035: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c022c00 of size 256 next 199\n",
      "2024-01-11 17:55:30.887046: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c022d00 of size 256 next 214\n",
      "2024-01-11 17:55:30.887057: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c022e00 of size 256 next 206\n",
      "2024-01-11 17:55:30.887068: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c022f00 of size 256 next 197\n",
      "2024-01-11 17:55:30.887079: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c023000 of size 256 next 201\n",
      "2024-01-11 17:55:30.887093: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c023100 of size 256 next 208\n",
      "2024-01-11 17:55:30.887104: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c023200 of size 256 next 212\n",
      "2024-01-11 17:55:30.887115: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c023300 of size 256 next 191\n",
      "2024-01-11 17:55:30.887126: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c023400 of size 256 next 204\n",
      "2024-01-11 17:55:30.887137: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c023500 of size 256 next 209\n",
      "2024-01-11 17:55:30.887148: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c023600 of size 512 next 215\n",
      "2024-01-11 17:55:30.887159: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c023800 of size 512 next 188\n",
      "2024-01-11 17:55:30.887170: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c023a00 of size 256 next 189\n",
      "2024-01-11 17:55:30.887181: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c023b00 of size 256 next 202\n",
      "2024-01-11 17:55:30.887193: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c023c00 of size 1024 next 153\n",
      "2024-01-11 17:55:30.887205: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c024000 of size 18432 next 137\n",
      "2024-01-11 17:55:30.887216: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c028800 of size 98304 next 156\n",
      "2024-01-11 17:55:30.887228: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c040800 of size 18432 next 154\n",
      "2024-01-11 17:55:30.887239: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c045000 of size 18432 next 176\n",
      "2024-01-11 17:55:30.887250: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c049800 of size 18432 next 173\n",
      "2024-01-11 17:55:30.887261: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c04e000 of size 18432 next 163\n",
      "2024-01-11 17:55:30.887273: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c052800 of size 115456 next 34\n",
      "2024-01-11 17:55:30.887284: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c06eb00 of size 18432 next 50\n",
      "2024-01-11 17:55:30.887295: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c073300 of size 256 next 51\n",
      "2024-01-11 17:55:30.887306: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c073400 of size 256 next 52\n",
      "2024-01-11 17:55:30.887318: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d0c073500 of size 198948352 next 19\n",
      "2024-01-11 17:55:30.887330: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d17e2eb00 of size 99680256 next 18\n",
      "2024-01-11 17:55:30.887342: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d1dd3eb00 of size 99680256 next 21\n",
      "2024-01-11 17:55:30.887354: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d23c4eb00 of size 343808 next 127\n",
      "2024-01-11 17:55:30.887366: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d23ca2a00 of size 98304 next 221\n",
      "2024-01-11 17:55:30.887377: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d23cbaa00 of size 18432 next 224\n",
      "2024-01-11 17:55:30.887389: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d23cbf200 of size 256 next 225\n",
      "2024-01-11 17:55:30.887399: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d23cbf300 of size 256 next 226\n",
      "2024-01-11 17:55:30.887411: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d23cbf400 of size 199243264 next 222\n",
      "2024-01-11 17:55:30.887422: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d2fac2a00 of size 99680256 next 200\n",
      "2024-01-11 17:55:30.887434: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d359d2a00 of size 99680256 next 198\n",
      "2024-01-11 17:55:30.887447: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d3b8e2a00 of size 99680256 next 227\n",
      "2024-01-11 17:55:30.887458: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d417f2a00 of size 512 next 228\n",
      "2024-01-11 17:55:30.887469: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d417f2c00 of size 512 next 229\n",
      "2024-01-11 17:55:30.887481: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d417f2e00 of size 99680256 next 230\n",
      "2024-01-11 17:55:30.887492: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d47702e00 of size 99680256 next 231\n",
      "2024-01-11 17:55:30.887503: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d612e00 of size 512 next 232\n",
      "2024-01-11 17:55:30.887514: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d613000 of size 512 next 233\n",
      "2024-01-11 17:55:30.887525: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d613200 of size 256 next 234\n",
      "2024-01-11 17:55:30.887536: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d613300 of size 256 next 235\n",
      "2024-01-11 17:55:30.887547: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d613400 of size 256 next 236\n",
      "2024-01-11 17:55:30.887558: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d613500 of size 256 next 237\n",
      "2024-01-11 17:55:30.887569: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d613600 of size 256 next 238\n",
      "2024-01-11 17:55:30.887580: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d613700 of size 256 next 239\n",
      "2024-01-11 17:55:30.887591: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d613800 of size 256 next 240\n",
      "2024-01-11 17:55:30.887602: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d613900 of size 18432 next 274\n",
      "2024-01-11 17:55:30.887613: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d618100 of size 18432 next 243\n",
      "2024-01-11 17:55:30.887624: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d61c900 of size 18432 next 271\n",
      "2024-01-11 17:55:30.887635: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d621100 of size 98304 next 251\n",
      "2024-01-11 17:55:30.887646: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d639100 of size 98304 next 133\n",
      "2024-01-11 17:55:30.887657: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d651100 of size 256 next 293\n",
      "2024-01-11 17:55:30.887668: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d651200 of size 256 next 294\n",
      "2024-01-11 17:55:30.887679: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d651300 of size 256 next 315\n",
      "2024-01-11 17:55:30.887690: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d651400 of size 512 next 324\n",
      "2024-01-11 17:55:30.887701: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d651600 of size 256 next 316\n",
      "2024-01-11 17:55:30.887712: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d651700 of size 256 next 311\n",
      "2024-01-11 17:55:30.887723: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d651800 of size 256 next 334\n",
      "2024-01-11 17:55:30.887734: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d651900 of size 256 next 326\n",
      "2024-01-11 17:55:30.887745: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d651a00 of size 768 next 317\n",
      "2024-01-11 17:55:30.887756: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d651d00 of size 256 next 298\n",
      "2024-01-11 17:55:30.887767: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d651e00 of size 256 next 305\n",
      "2024-01-11 17:55:30.887778: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d651f00 of size 768 next 319\n",
      "2024-01-11 17:55:30.887791: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d652200 of size 768 next 331\n",
      "2024-01-11 17:55:30.887802: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d652500 of size 256 next 308\n",
      "2024-01-11 17:55:30.887813: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d652600 of size 256 next 296\n",
      "2024-01-11 17:55:30.887825: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d652700 of size 34304 next 325\n",
      "2024-01-11 17:55:30.887836: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d65ad00 of size 18432 next 323\n",
      "2024-01-11 17:55:30.887847: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d65f500 of size 98304 next 332\n",
      "2024-01-11 17:55:30.887858: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d677500 of size 98304 next 303\n",
      "2024-01-11 17:55:30.887869: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d68f500 of size 18432 next 295\n",
      "2024-01-11 17:55:30.887881: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d693d00 of size 256 next 329\n",
      "2024-01-11 17:55:30.887892: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d693e00 of size 256 next 306\n",
      "2024-01-11 17:55:30.887903: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d693f00 of size 512 next 292\n",
      "2024-01-11 17:55:30.887913: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d694100 of size 512 next 307\n",
      "2024-01-11 17:55:30.887925: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d694300 of size 512 next 312\n",
      "2024-01-11 17:55:30.887936: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d694500 of size 512 next 291\n",
      "2024-01-11 17:55:30.887947: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d694700 of size 256 next 328\n",
      "2024-01-11 17:55:30.887958: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d694800 of size 256 next 321\n",
      "2024-01-11 17:55:30.887969: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d694900 of size 256 next 335\n",
      "2024-01-11 17:55:30.887980: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d694a00 of size 256 next 300\n",
      "2024-01-11 17:55:30.887991: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d694b00 of size 256 next 336\n",
      "2024-01-11 17:55:30.888002: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d694c00 of size 256 next 337\n",
      "2024-01-11 17:55:30.888013: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d694d00 of size 256 next 338\n",
      "2024-01-11 17:55:30.888024: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d694e00 of size 256 next 345\n",
      "2024-01-11 17:55:30.888035: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d694f00 of size 256 next 346\n",
      "2024-01-11 17:55:30.888045: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d695000 of size 256 next 341\n",
      "2024-01-11 17:55:30.888057: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d695100 of size 256 next 360\n",
      "2024-01-11 17:55:30.888068: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d695200 of size 256 next 372\n",
      "2024-01-11 17:55:30.888078: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d695300 of size 256 next 358\n",
      "2024-01-11 17:55:30.888089: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d695400 of size 256 next 363\n",
      "2024-01-11 17:55:30.888100: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d695500 of size 18432 next 371\n",
      "2024-01-11 17:55:30.888111: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d699d00 of size 256 next 368\n",
      "2024-01-11 17:55:30.888122: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d699e00 of size 256 next 359\n",
      "2024-01-11 17:55:30.888135: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d699f00 of size 512 next 373\n",
      "2024-01-11 17:55:30.888147: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69a100 of size 512 next 355\n",
      "2024-01-11 17:55:30.888158: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69a300 of size 256 next 377\n",
      "2024-01-11 17:55:30.888169: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69a400 of size 256 next 365\n",
      "2024-01-11 17:55:30.888179: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69a500 of size 256 next 350\n",
      "2024-01-11 17:55:30.888191: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69a600 of size 256 next 381\n",
      "2024-01-11 17:55:30.888202: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69a700 of size 256 next 343\n",
      "2024-01-11 17:55:30.888212: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69a800 of size 256 next 344\n",
      "2024-01-11 17:55:30.888223: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69a900 of size 256 next 376\n",
      "2024-01-11 17:55:30.888234: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69aa00 of size 256 next 395\n",
      "2024-01-11 17:55:30.888245: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69ab00 of size 256 next 388\n",
      "2024-01-11 17:55:30.888256: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69ac00 of size 256 next 339\n",
      "2024-01-11 17:55:30.888267: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69ad00 of size 256 next 394\n",
      "2024-01-11 17:55:30.888278: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69ae00 of size 256 next 392\n",
      "2024-01-11 17:55:30.888289: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69af00 of size 256 next 357\n",
      "2024-01-11 17:55:30.888300: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69b000 of size 512 next 384\n",
      "2024-01-11 17:55:30.888311: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69b200 of size 256 next 393\n",
      "2024-01-11 17:55:30.888323: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8d4d69b300 of size 768 next 402\n",
      "2024-01-11 17:55:30.888334: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d69b600 of size 768 next 389\n",
      "2024-01-11 17:55:30.888345: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8d4d69b900 of size 25088 next 378\n",
      "2024-01-11 17:55:30.888356: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6a1b00 of size 768 next 349\n",
      "2024-01-11 17:55:30.888367: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6a1e00 of size 512 next 370\n",
      "2024-01-11 17:55:30.888378: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6a2000 of size 768 next 356\n",
      "2024-01-11 17:55:30.888389: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6a2300 of size 768 next 379\n",
      "2024-01-11 17:55:30.888400: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6a2600 of size 256 next 366\n",
      "2024-01-11 17:55:30.888411: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6a2700 of size 256 next 364\n",
      "2024-01-11 17:55:30.888422: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6a2800 of size 34304 next 340\n",
      "2024-01-11 17:55:30.888433: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6aae00 of size 18432 next 351\n",
      "2024-01-11 17:55:30.888444: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6af600 of size 256 next 398\n",
      "2024-01-11 17:55:30.888455: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6af700 of size 256 next 403\n",
      "2024-01-11 17:55:30.888466: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6af800 of size 512 next 391\n",
      "2024-01-11 17:55:30.888479: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6afa00 of size 256 next 387\n",
      "2024-01-11 17:55:30.888490: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6afb00 of size 256 next 385\n",
      "2024-01-11 17:55:30.888501: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6afc00 of size 256 next 382\n",
      "2024-01-11 17:55:30.888512: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6afd00 of size 256 next 401\n",
      "2024-01-11 17:55:30.888523: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6afe00 of size 256 next 400\n",
      "2024-01-11 17:55:30.888534: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6aff00 of size 768 next 390\n",
      "2024-01-11 17:55:30.888545: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8d4d6b0200 of size 18432 next 367\n",
      "2024-01-11 17:55:30.888557: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6b4a00 of size 35584 next 361\n",
      "2024-01-11 17:55:30.888568: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6bd500 of size 256 next 342\n",
      "2024-01-11 17:55:30.888579: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6bd600 of size 256 next 369\n",
      "2024-01-11 17:55:30.888590: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6bd700 of size 256 next 374\n",
      "2024-01-11 17:55:30.888601: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6bd800 of size 256 next 354\n",
      "2024-01-11 17:55:30.888612: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6bd900 of size 256 next 362\n",
      "2024-01-11 17:55:30.888623: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6bda00 of size 256 next 348\n",
      "2024-01-11 17:55:30.888635: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6bdb00 of size 98304 next 380\n",
      "2024-01-11 17:55:30.888646: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6d5b00 of size 18432 next 386\n",
      "2024-01-11 17:55:30.888657: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4d6da300 of size 98304 next 396\n",
      "2024-01-11 17:55:30.888668: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8d4d6f2300 of size 25304064 next 247\n",
      "2024-01-11 17:55:30.888679: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4ef13f00 of size 256 next 246\n",
      "2024-01-11 17:55:30.888690: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4ef14000 of size 256 next 259\n",
      "2024-01-11 17:55:30.888701: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4ef14100 of size 256 next 248\n",
      "2024-01-11 17:55:30.888712: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4ef14200 of size 256 next 266\n",
      "2024-01-11 17:55:30.888723: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4ef14300 of size 256 next 267\n",
      "2024-01-11 17:55:30.888734: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d4ef14400 of size 99680256 next 260\n",
      "2024-01-11 17:55:30.888745: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d54e24400 of size 99680256 next 268\n",
      "2024-01-11 17:55:30.888756: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d5ad34400 of size 99680256 next 276\n",
      "2024-01-11 17:55:30.888768: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d60c44400 of size 99680256 next 242\n",
      "2024-01-11 17:55:30.888779: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d66b54400 of size 133605120 next 140\n",
      "2024-01-11 17:55:30.888791: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8d6eabeb00 of size 1256652800 next 195\n",
      "2024-01-11 17:55:30.888802: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db992eb00 of size 256 next 261\n",
      "2024-01-11 17:55:30.888813: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db992ec00 of size 256 next 275\n",
      "2024-01-11 17:55:30.888827: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db992ed00 of size 256 next 270\n",
      "2024-01-11 17:55:30.888838: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db992ee00 of size 256 next 258\n",
      "2024-01-11 17:55:30.888849: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db992ef00 of size 512 next 250\n",
      "2024-01-11 17:55:30.888861: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db992f100 of size 512 next 279\n",
      "2024-01-11 17:55:30.888871: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db992f300 of size 256 next 255\n",
      "2024-01-11 17:55:30.888882: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db992f400 of size 256 next 257\n",
      "2024-01-11 17:55:30.888893: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db992f500 of size 256 next 253\n",
      "2024-01-11 17:55:30.888904: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db992f600 of size 768 next 284\n",
      "2024-01-11 17:55:30.888915: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db992f900 of size 256 next 263\n",
      "2024-01-11 17:55:30.888926: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db992fa00 of size 256 next 256\n",
      "2024-01-11 17:55:30.888937: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db992fb00 of size 256 next 280\n",
      "2024-01-11 17:55:30.888972: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db992fc00 of size 768 next 285\n",
      "2024-01-11 17:55:30.888984: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db992ff00 of size 768 next 244\n",
      "2024-01-11 17:55:30.888994: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9930200 of size 256 next 249\n",
      "2024-01-11 17:55:30.889005: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9930300 of size 256 next 264\n",
      "2024-01-11 17:55:30.889016: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9930400 of size 256 next 283\n",
      "2024-01-11 17:55:30.889027: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9930500 of size 256 next 265\n",
      "2024-01-11 17:55:30.889038: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9930600 of size 512 next 262\n",
      "2024-01-11 17:55:30.889049: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9930800 of size 512 next 281\n",
      "2024-01-11 17:55:30.889061: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9930a00 of size 512 next 272\n",
      "2024-01-11 17:55:30.889072: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9930c00 of size 512 next 269\n",
      "2024-01-11 17:55:30.889082: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9930e00 of size 256 next 277\n",
      "2024-01-11 17:55:30.889093: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9930f00 of size 256 next 241\n",
      "2024-01-11 17:55:30.889104: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9931000 of size 256 next 286\n",
      "2024-01-11 17:55:30.889115: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9931100 of size 256 next 287\n",
      "2024-01-11 17:55:30.889126: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9931200 of size 256 next 288\n",
      "2024-01-11 17:55:30.889137: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9931300 of size 256 next 289\n",
      "2024-01-11 17:55:30.889148: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9931400 of size 256 next 290\n",
      "2024-01-11 17:55:30.889159: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9931500 of size 256 next 302\n",
      "2024-01-11 17:55:30.889170: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9931600 of size 256 next 318\n",
      "2024-01-11 17:55:30.889181: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9931700 of size 256 next 314\n",
      "2024-01-11 17:55:30.889194: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9931800 of size 256 next 299\n",
      "2024-01-11 17:55:30.889205: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9931900 of size 256 next 322\n",
      "2024-01-11 17:55:30.889217: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9931a00 of size 256 next 313\n",
      "2024-01-11 17:55:30.889227: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9931b00 of size 256 next 320\n",
      "2024-01-11 17:55:30.889238: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9931c00 of size 512 next 330\n",
      "2024-01-11 17:55:30.889249: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9931e00 of size 256 next 273\n",
      "2024-01-11 17:55:30.889260: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9931f00 of size 256 next 252\n",
      "2024-01-11 17:55:30.889271: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9932000 of size 256 next 254\n",
      "2024-01-11 17:55:30.889283: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8db9932100 of size 99680256 next 282\n",
      "2024-01-11 17:55:30.889294: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8dbf842100 of size 99680256 next 297\n",
      "2024-01-11 17:55:30.889305: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8dc5752100 of size 99680256 next 310\n",
      "2024-01-11 17:55:30.889316: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8dcb662100 of size 99680256 next 301\n",
      "2024-01-11 17:55:30.889327: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8dd1572100 of size 99680256 next 333\n",
      "2024-01-11 17:55:30.889338: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8dd7482100 of size 99680256 next 309\n",
      "2024-01-11 17:55:30.889349: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8ddd392100 of size 99680256 next 304\n",
      "2024-01-11 17:55:30.889360: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8de32a2100 of size 99680256 next 352\n",
      "2024-01-11 17:55:30.889372: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8de91b2100 of size 99680256 next 353\n",
      "2024-01-11 17:55:30.889383: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8def0c2100 of size 99680256 next 347\n",
      "2024-01-11 17:55:30.889394: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8df4fd2100 of size 199360512 next 404\n",
      "2024-01-11 17:55:30.889405: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e00df2100 of size 99680256 next 383\n",
      "2024-01-11 17:55:30.889416: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f8e06d02100 of size 1217038848 next 30\n",
      "2024-01-11 17:55:30.889428: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e4f5aab00 of size 99680256 next 53\n",
      "2024-01-11 17:55:30.889439: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e554bab00 of size 512 next 54\n",
      "2024-01-11 17:55:30.889450: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e554bad00 of size 512 next 55\n",
      "2024-01-11 17:55:30.889461: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e554baf00 of size 99680256 next 56\n",
      "2024-01-11 17:55:30.889472: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e5b3caf00 of size 99680256 next 57\n",
      "2024-01-11 17:55:30.889483: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612daf00 of size 512 next 58\n",
      "2024-01-11 17:55:30.889494: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612db100 of size 512 next 59\n",
      "2024-01-11 17:55:30.889505: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612db300 of size 512 next 60\n",
      "2024-01-11 17:55:30.889516: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612db500 of size 512 next 61\n",
      "2024-01-11 17:55:30.889527: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612db700 of size 256 next 62\n",
      "2024-01-11 17:55:30.889540: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612db800 of size 256 next 63\n",
      "2024-01-11 17:55:30.889551: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612db900 of size 512 next 64\n",
      "2024-01-11 17:55:30.889562: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dbb00 of size 512 next 65\n",
      "2024-01-11 17:55:30.889573: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dbd00 of size 256 next 66\n",
      "2024-01-11 17:55:30.889609: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dbe00 of size 256 next 67\n",
      "2024-01-11 17:55:30.889621: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dbf00 of size 256 next 68\n",
      "2024-01-11 17:55:30.889632: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dc000 of size 256 next 69\n",
      "2024-01-11 17:55:30.889643: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dc100 of size 256 next 70\n",
      "2024-01-11 17:55:30.889653: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dc200 of size 256 next 71\n",
      "2024-01-11 17:55:30.889665: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dc300 of size 256 next 72\n",
      "2024-01-11 17:55:30.889675: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dc400 of size 256 next 73\n",
      "2024-01-11 17:55:30.889686: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dc500 of size 256 next 74\n",
      "2024-01-11 17:55:30.889697: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dc600 of size 256 next 75\n",
      "2024-01-11 17:55:30.889708: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dc700 of size 256 next 76\n",
      "2024-01-11 17:55:30.889719: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dc800 of size 256 next 77\n",
      "2024-01-11 17:55:30.889730: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dc900 of size 256 next 104\n",
      "2024-01-11 17:55:30.889741: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dca00 of size 256 next 101\n",
      "2024-01-11 17:55:30.889752: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dcb00 of size 256 next 95\n",
      "2024-01-11 17:55:30.889763: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dcc00 of size 256 next 89\n",
      "2024-01-11 17:55:30.889774: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dcd00 of size 256 next 94\n",
      "2024-01-11 17:55:30.889785: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dce00 of size 256 next 100\n",
      "2024-01-11 17:55:30.889796: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dcf00 of size 256 next 99\n",
      "2024-01-11 17:55:30.889806: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dd000 of size 256 next 102\n",
      "2024-01-11 17:55:30.889817: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dd100 of size 256 next 103\n",
      "2024-01-11 17:55:30.889828: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dd200 of size 256 next 84\n",
      "2024-01-11 17:55:30.889839: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dd300 of size 256 next 79\n",
      "2024-01-11 17:55:30.889850: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dd400 of size 256 next 108\n",
      "2024-01-11 17:55:30.889861: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dd500 of size 1280 next 126\n",
      "2024-01-11 17:55:30.889872: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612dda00 of size 768 next 113\n",
      "2024-01-11 17:55:30.889884: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612ddd00 of size 768 next 90\n",
      "2024-01-11 17:55:30.889895: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612de000 of size 256 next 129\n",
      "2024-01-11 17:55:30.889907: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612de100 of size 256 next 78\n",
      "2024-01-11 17:55:30.889919: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612de200 of size 35584 next 92\n",
      "2024-01-11 17:55:30.889930: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612e6d00 of size 18432 next 85\n",
      "2024-01-11 17:55:30.889941: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e612eb500 of size 196352 next 112\n",
      "2024-01-11 17:55:30.889953: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e6131b400 of size 18432 next 87\n",
      "2024-01-11 17:55:30.889964: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e6131fc00 of size 256 next 111\n",
      "2024-01-11 17:55:30.889975: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e6131fd00 of size 256 next 114\n",
      "2024-01-11 17:55:30.889986: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e6131fe00 of size 768 next 122\n",
      "2024-01-11 17:55:30.889997: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61320100 of size 768 next 118\n",
      "2024-01-11 17:55:30.890008: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61320400 of size 256 next 91\n",
      "2024-01-11 17:55:30.890019: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61320500 of size 256 next 128\n",
      "2024-01-11 17:55:30.890030: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61320600 of size 256 next 93\n",
      "2024-01-11 17:55:30.890041: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61320700 of size 256 next 125\n",
      "2024-01-11 17:55:30.890052: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61320800 of size 256 next 82\n",
      "2024-01-11 17:55:30.890063: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61320900 of size 256 next 116\n",
      "2024-01-11 17:55:30.890074: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61320a00 of size 256 next 83\n",
      "2024-01-11 17:55:30.890084: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61320b00 of size 768 next 31\n",
      "2024-01-11 17:55:30.890096: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61320e00 of size 768 next 109\n",
      "2024-01-11 17:55:30.890107: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61321100 of size 768 next 98\n",
      "2024-01-11 17:55:30.890117: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61321400 of size 256 next 32\n",
      "2024-01-11 17:55:30.890129: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61321500 of size 36608 next 119\n",
      "2024-01-11 17:55:30.890140: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e6132a400 of size 18432 next 106\n",
      "2024-01-11 17:55:30.890151: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e6132ec00 of size 18432 next 97\n",
      "2024-01-11 17:55:30.890162: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61333400 of size 18432 next 117\n",
      "2024-01-11 17:55:30.890173: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61337c00 of size 256 next 278\n",
      "2024-01-11 17:55:30.890184: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61337d00 of size 256 next 207\n",
      "2024-01-11 17:55:30.890195: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61337e00 of size 256 next 217\n",
      "2024-01-11 17:55:30.890206: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61337f00 of size 256 next 218\n",
      "2024-01-11 17:55:30.890217: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61338000 of size 768 next 216\n",
      "2024-01-11 17:55:30.890228: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61338300 of size 768 next 220\n",
      "2024-01-11 17:55:30.890239: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61338600 of size 256 next 80\n",
      "2024-01-11 17:55:30.890252: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61338700 of size 256 next 223\n",
      "2024-01-11 17:55:30.890264: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61338800 of size 33792 next 219\n",
      "2024-01-11 17:55:30.890276: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61340c00 of size 24576 next 105\n",
      "2024-01-11 17:55:30.890288: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e61346c00 of size 343808 next 170\n",
      "2024-01-11 17:55:30.890299: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8e6139ab00 of size 5026201600 next 86\n",
      "2024-01-11 17:55:30.890311: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f8f8ccf6b00 of size 5051655936 next 120\n",
      "2024-01-11 17:55:30.890323: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f90b9e99200 of size 5026201600 next 150\n",
      "2024-01-11 17:55:30.890334: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f91e57f5200 of size 5026201600 next 169\n",
      "2024-01-11 17:55:30.890345: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9311151200 of size 5026201600 next 245\n",
      "2024-01-11 17:55:30.890356: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f943caad200 of size 5026201600 next 327\n",
      "2024-01-11 17:55:30.890367: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9568409200 of size 5026201600 next 375\n",
      "2024-01-11 17:55:30.890378: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9693d65200 of size 99680256 next 399\n",
      "2024-01-11 17:55:30.890390: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f9699c75200 of size 5026201600 next 397\n",
      "2024-01-11 17:55:30.890401: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f97c55d1200 of size 3090083328 next 18446744073709551615\n",
      "2024-01-11 17:55:30.890412: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-01-11 17:55:30.890429: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 248 Chunks of size 256 totalling 62.0KiB\n",
      "2024-01-11 17:55:30.890444: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 35 Chunks of size 512 totalling 17.5KiB\n",
      "2024-01-11 17:55:30.890458: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 29 Chunks of size 768 totalling 21.8KiB\n",
      "2024-01-11 17:55:30.890471: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1024 totalling 1.0KiB\n",
      "2024-01-11 17:55:30.890484: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 1280 totalling 3.8KiB\n",
      "2024-01-11 17:55:30.890498: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 22 Chunks of size 18432 totalling 396.0KiB\n",
      "2024-01-11 17:55:30.890512: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 18688 totalling 18.2KiB\n",
      "2024-01-11 17:55:30.890526: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 24576 totalling 24.0KiB\n",
      "2024-01-11 17:55:30.890540: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 24832 totalling 24.2KiB\n",
      "2024-01-11 17:55:30.890553: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 28160 totalling 27.5KiB\n",
      "2024-01-11 17:55:30.890566: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 33792 totalling 33.0KiB\n",
      "2024-01-11 17:55:30.890579: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 34304 totalling 67.0KiB\n",
      "2024-01-11 17:55:30.890593: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 35584 totalling 69.5KiB\n",
      "2024-01-11 17:55:30.890606: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 36608 totalling 35.8KiB\n",
      "2024-01-11 17:55:30.890620: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 8 Chunks of size 98304 totalling 768.0KiB\n",
      "2024-01-11 17:55:30.890635: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 115456 totalling 112.8KiB\n",
      "2024-01-11 17:55:30.890651: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 196352 totalling 191.8KiB\n",
      "2024-01-11 17:55:30.890665: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 343808 totalling 671.5KiB\n",
      "2024-01-11 17:55:30.890678: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 26 Chunks of size 99680256 totalling 2.41GiB\n",
      "2024-01-11 17:55:30.890693: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 133605120 totalling 127.42MiB\n",
      "2024-01-11 17:55:30.890707: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 198948352 totalling 189.73MiB\n",
      "2024-01-11 17:55:30.890721: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 199243264 totalling 190.01MiB\n",
      "2024-01-11 17:55:30.890734: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1256652800 totalling 1.17GiB\n",
      "2024-01-11 17:55:30.890748: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 7 Chunks of size 5026201600 totalling 32.77GiB\n",
      "2024-01-11 17:55:30.890761: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 5051655936 totalling 4.70GiB\n",
      "2024-01-11 17:55:30.890775: I external/local_tsl/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 41.55GiB\n",
      "2024-01-11 17:55:30.890797: I external/local_tsl/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 49149640704 memory_limit_: 49149640704 available bytes: 0 curr_region_allocation_bytes_: 98299281408\n",
      "2024-01-11 17:55:30.890827: I external/local_tsl/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                     49149640704\n",
      "InUse:                     44617809664\n",
      "MaxInUse:                  44817169664\n",
      "NumAllocs:                      390660\n",
      "MaxAllocSize:               5051655936\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-01-11 17:55:30.890915: W external/local_tsl/tsl/framework/bfc_allocator.cc:497] *********__***********************************************************************************______\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 84\u001b[0m\n\u001b[1;32m     80\u001b[0m encoder_with_contrastive_head\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate),\n\u001b[1;32m     81\u001b[0m                                       loss\u001b[38;5;241m=\u001b[39m[SupervisedContrastiveLoss(temperature\u001b[38;5;241m=\u001b[39mtemperature) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_tasks)],\n\u001b[1;32m     82\u001b[0m )\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_with_contrastive_head\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_tasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class SupervisedContrastiveLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def npairs_loss(self, y_true, y_pred) -> tf.Tensor:\n",
    "        \"\"\"Computes the npairs loss between `y_true` and `y_pred`.\n",
    "        \"\"\"\n",
    "        y_pred = tf.convert_to_tensor(y_pred)\n",
    "        y_true = tf.cast(y_true, y_pred.dtype)\n",
    "\n",
    "        # Expand to [batch_size, 1]\n",
    "        y_true = tf.expand_dims(y_true, -1)\n",
    "        # creates a matrix where 1s represent matching labels and 0s represent non-matching labels.\n",
    "        y_true = tf.cast(tf.equal(y_true, tf.transpose(y_true)), y_pred.dtype)\n",
    "        y_true /= tf.math.reduce_sum(y_true, 1, keepdims=True)\n",
    "\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true)\n",
    "\n",
    "        return tf.math.reduce_mean(loss)\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1) #feature_vectors #\n",
    "        # Compute logits\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        \n",
    "        loss = self.npairs_loss(tf.squeeze(labels), logits)\n",
    "        return loss \n",
    "    #tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "def create_encoder(input_shape=(320, 320, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Add contrastive and regression head\n",
    "def add_contrastive_head(input_shape, encoder, embedding_dim, num_tasks):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "\n",
    "    # Add dense layer for each task\n",
    "    contrastive_outputs = [Dense(embedding_dim, activation='linear', name=f\"contrastive_output_{i}\")(features) for i in range(num_tasks)]\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=contrastive_outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (320, 320, 1)\n",
    "embedding_dim = 128\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "validation_split = 0.2\n",
    "learning_rate = 0.001\n",
    "num_tasks = 1   # P, V\n",
    "temperature = 0.05\n",
    "\n",
    "# Build model\n",
    "encoder = create_encoder()\n",
    "encoder_with_contrastive_head = add_contrastive_head(input_shape, encoder, embedding_dim, num_tasks)\n",
    "encoder_with_contrastive_head.summary()\n",
    "\n",
    "# Compile model\n",
    "encoder_with_contrastive_head.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                                      loss=[SupervisedContrastiveLoss(temperature=temperature) for _ in range(num_tasks)],\n",
    ")\n",
    "# Fit model\n",
    "history = encoder_with_contrastive_head.fit(\n",
    "    x=X_train, \n",
    "    y=[y_train[:,i] for i in range(num_tasks)],\n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs, \n",
    "    validation_split=validation_split,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_22 (InputLayer)       [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " model_19 (Functional)       (None, 128)                  2492499   ['input_22[0][0]']            \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " contrastive_output_0 (Dens  (None, 128)                  16512     ['model_19[0][0]']            \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " contrastive_output_1 (Dens  (None, 128)                  16512     ['model_19[0][0]']            \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " regression_output_0 (Dense  (None, 1)                    129       ['model_19[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " regression_output_1 (Dense  (None, 1)                    129       ['model_19[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24958274 (95.21 MB)\n",
      "Trainable params: 24958274 (95.21 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "192/192 [==============================] - 14s 62ms/step - loss: 7.8487 - contrastive_output_0_loss: 3.4337 - contrastive_output_1_loss: 3.8968 - regression_output_0_loss: 0.2151 - regression_output_1_loss: 0.3032 - val_loss: 6.8085 - val_contrastive_output_0_loss: 3.0207 - val_contrastive_output_1_loss: 3.5546 - val_regression_output_0_loss: 0.0539 - val_regression_output_1_loss: 0.1792\n",
      "Epoch 2/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.6016 - contrastive_output_0_loss: 2.9526 - contrastive_output_1_loss: 3.4759 - regression_output_0_loss: 0.0682 - regression_output_1_loss: 0.1049 - val_loss: 6.4656 - val_contrastive_output_0_loss: 2.9290 - val_contrastive_output_1_loss: 3.4211 - val_regression_output_0_loss: 0.0401 - val_regression_output_1_loss: 0.0753\n",
      "Epoch 3/20\n",
      "192/192 [==============================] - 8s 43ms/step - loss: 6.4281 - contrastive_output_0_loss: 2.8998 - contrastive_output_1_loss: 3.3962 - regression_output_0_loss: 0.0527 - regression_output_1_loss: 0.0794 - val_loss: 6.5055 - val_contrastive_output_0_loss: 2.9251 - val_contrastive_output_1_loss: 3.4404 - val_regression_output_0_loss: 0.0669 - val_regression_output_1_loss: 0.0732\n",
      "Epoch 4/20\n",
      "192/192 [==============================] - 8s 42ms/step - loss: 6.3294 - contrastive_output_0_loss: 2.8772 - contrastive_output_1_loss: 3.3501 - regression_output_0_loss: 0.0391 - regression_output_1_loss: 0.0629 - val_loss: 6.3845 - val_contrastive_output_0_loss: 2.8915 - val_contrastive_output_1_loss: 3.3735 - val_regression_output_0_loss: 0.0493 - val_regression_output_1_loss: 0.0702\n",
      "Epoch 5/20\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.2834 - contrastive_output_0_loss: 2.8709 - contrastive_output_1_loss: 3.3198 - regression_output_0_loss: 0.0401 - regression_output_1_loss: 0.0526 - val_loss: 6.3188 - val_contrastive_output_0_loss: 2.8860 - val_contrastive_output_1_loss: 3.3538 - val_regression_output_0_loss: 0.0262 - val_regression_output_1_loss: 0.0529\n",
      "Epoch 6/20\n",
      "192/192 [==============================] - 8s 43ms/step - loss: 6.2416 - contrastive_output_0_loss: 2.8642 - contrastive_output_1_loss: 3.3005 - regression_output_0_loss: 0.0307 - regression_output_1_loss: 0.0462 - val_loss: 6.2923 - val_contrastive_output_0_loss: 2.8632 - val_contrastive_output_1_loss: 3.3275 - val_regression_output_0_loss: 0.0484 - val_regression_output_1_loss: 0.0533\n",
      "Epoch 7/20\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.2019 - contrastive_output_0_loss: 2.8498 - contrastive_output_1_loss: 3.2829 - regression_output_0_loss: 0.0286 - regression_output_1_loss: 0.0406 - val_loss: 6.2792 - val_contrastive_output_0_loss: 2.8576 - val_contrastive_output_1_loss: 3.3112 - val_regression_output_0_loss: 0.0401 - val_regression_output_1_loss: 0.0704\n",
      "Epoch 8/20\n",
      "192/192 [==============================] - 8s 43ms/step - loss: 6.1811 - contrastive_output_0_loss: 2.8488 - contrastive_output_1_loss: 3.2687 - regression_output_0_loss: 0.0264 - regression_output_1_loss: 0.0373 - val_loss: 6.2372 - val_contrastive_output_0_loss: 2.8365 - val_contrastive_output_1_loss: 3.2920 - val_regression_output_0_loss: 0.0651 - val_regression_output_1_loss: 0.0436\n",
      "Epoch 9/20\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.1557 - contrastive_output_0_loss: 2.8462 - contrastive_output_1_loss: 3.2495 - regression_output_0_loss: 0.0252 - regression_output_1_loss: 0.0347 - val_loss: 6.2084 - val_contrastive_output_0_loss: 2.8495 - val_contrastive_output_1_loss: 3.2835 - val_regression_output_0_loss: 0.0305 - val_regression_output_1_loss: 0.0449\n",
      "Epoch 10/20\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.1249 - contrastive_output_0_loss: 2.8380 - contrastive_output_1_loss: 3.2389 - regression_output_0_loss: 0.0193 - regression_output_1_loss: 0.0287 - val_loss: 6.1684 - val_contrastive_output_0_loss: 2.8429 - val_contrastive_output_1_loss: 3.2710 - val_regression_output_0_loss: 0.0176 - val_regression_output_1_loss: 0.0369\n",
      "Epoch 11/20\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.1118 - contrastive_output_0_loss: 2.8350 - contrastive_output_1_loss: 3.2294 - regression_output_0_loss: 0.0198 - regression_output_1_loss: 0.0276 - val_loss: 6.1193 - val_contrastive_output_0_loss: 2.8239 - val_contrastive_output_1_loss: 3.2504 - val_regression_output_0_loss: 0.0137 - val_regression_output_1_loss: 0.0312\n",
      "Epoch 12/20\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.0991 - contrastive_output_0_loss: 2.8331 - contrastive_output_1_loss: 3.2250 - regression_output_0_loss: 0.0168 - regression_output_1_loss: 0.0243 - val_loss: 6.1718 - val_contrastive_output_0_loss: 2.8662 - val_contrastive_output_1_loss: 3.2492 - val_regression_output_0_loss: 0.0200 - val_regression_output_1_loss: 0.0364\n",
      "Epoch 13/20\n",
      "192/192 [==============================] - 9s 45ms/step - loss: 6.0918 - contrastive_output_0_loss: 2.8347 - contrastive_output_1_loss: 3.2189 - regression_output_0_loss: 0.0167 - regression_output_1_loss: 0.0216 - val_loss: 6.1191 - val_contrastive_output_0_loss: 2.8210 - val_contrastive_output_1_loss: 3.2537 - val_regression_output_0_loss: 0.0125 - val_regression_output_1_loss: 0.0319\n",
      "Epoch 14/20\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.0829 - contrastive_output_0_loss: 2.8313 - contrastive_output_1_loss: 3.2143 - regression_output_0_loss: 0.0166 - regression_output_1_loss: 0.0207 - val_loss: 6.1597 - val_contrastive_output_0_loss: 2.8436 - val_contrastive_output_1_loss: 3.2607 - val_regression_output_0_loss: 0.0207 - val_regression_output_1_loss: 0.0347\n",
      "Epoch 15/20\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.0784 - contrastive_output_0_loss: 2.8290 - contrastive_output_1_loss: 3.2161 - regression_output_0_loss: 0.0135 - regression_output_1_loss: 0.0198 - val_loss: 6.1227 - val_contrastive_output_0_loss: 2.8307 - val_contrastive_output_1_loss: 3.2425 - val_regression_output_0_loss: 0.0212 - val_regression_output_1_loss: 0.0282\n",
      "Epoch 16/20\n",
      "192/192 [==============================] - 9s 45ms/step - loss: 6.0822 - contrastive_output_0_loss: 2.8339 - contrastive_output_1_loss: 3.2142 - regression_output_0_loss: 0.0150 - regression_output_1_loss: 0.0191 - val_loss: 6.1171 - val_contrastive_output_0_loss: 2.8340 - val_contrastive_output_1_loss: 3.2401 - val_regression_output_0_loss: 0.0130 - val_regression_output_1_loss: 0.0301\n",
      "Epoch 17/20\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.0743 - contrastive_output_0_loss: 2.8295 - contrastive_output_1_loss: 3.2128 - regression_output_0_loss: 0.0140 - regression_output_1_loss: 0.0179 - val_loss: 6.1051 - val_contrastive_output_0_loss: 2.8254 - val_contrastive_output_1_loss: 3.2388 - val_regression_output_0_loss: 0.0129 - val_regression_output_1_loss: 0.0281\n",
      "Epoch 18/20\n",
      "192/192 [==============================] - 8s 43ms/step - loss: 6.0654 - contrastive_output_0_loss: 2.8276 - contrastive_output_1_loss: 3.2098 - regression_output_0_loss: 0.0119 - regression_output_1_loss: 0.0162 - val_loss: 6.1125 - val_contrastive_output_0_loss: 2.8313 - val_contrastive_output_1_loss: 3.2340 - val_regression_output_0_loss: 0.0227 - val_regression_output_1_loss: 0.0244\n",
      "Epoch 19/20\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.0571 - contrastive_output_0_loss: 2.8239 - contrastive_output_1_loss: 3.2062 - regression_output_0_loss: 0.0113 - regression_output_1_loss: 0.0158 - val_loss: 6.1179 - val_contrastive_output_0_loss: 2.8417 - val_contrastive_output_1_loss: 3.2277 - val_regression_output_0_loss: 0.0179 - val_regression_output_1_loss: 0.0306\n",
      "Epoch 20/20\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.0563 - contrastive_output_0_loss: 2.8242 - contrastive_output_1_loss: 3.2048 - regression_output_0_loss: 0.0121 - regression_output_1_loss: 0.0152 - val_loss: 6.1214 - val_contrastive_output_0_loss: 2.8275 - val_contrastive_output_1_loss: 3.2419 - val_regression_output_0_loss: 0.0210 - val_regression_output_1_loss: 0.0310\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class SupervisedContrastiveLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "def create_encoder(input_shape=(320, 320, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    # add dense layer\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "def add_contrastive_and_regression_heads(input_shape, encoder, embedding_dim, num_tasks):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "\n",
    "    # Add dense layers for contrastive tasks\n",
    "    contrastive_outputs = [Dense(embedding_dim, activation='linear', name=f\"contrastive_output_{i}\")(features) for i in range(num_tasks)]\n",
    "\n",
    "    # Add dense layers for regression tasks\n",
    "    regression_outputs = [Dense(1, activation='linear', name=f\"regression_output_{i}\")(features) for i in range(num_tasks)]\n",
    "\n",
    "    # Concatenate contrastive and regression outputs\n",
    "    all_outputs = contrastive_outputs + regression_outputs\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=all_outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (320, 320, 1)\n",
    "embedding_dim = 128\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "validation_split = 0.2\n",
    "learning_rate = 0.001\n",
    "num_tasks = 2   # P, V\n",
    "temperature = 0.05\n",
    "\n",
    "# Build model\n",
    "encoder = create_encoder()\n",
    "model_with_contrastive_and_regression = add_contrastive_and_regression_heads(input_shape, encoder, embedding_dim, num_tasks)\n",
    "model_with_contrastive_and_regression.summary()\n",
    "\n",
    "# Compile model\n",
    "model_with_contrastive_and_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                                              loss=[SupervisedContrastiveLoss(temperature=temperature) for _ in range(num_tasks)] + ['mse'] * num_tasks,\n",
    ")\n",
    "# Fit model\n",
    "history = model_with_contrastive_and_regression.fit(\n",
    "    x=X_train, \n",
    "    y=[y_train[:, 0], y_train[:, 1], y_train[:, 0], y_train[:, 1]], \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs, \n",
    "    validation_split=validation_split,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_24 (InputLayer)       [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " model_21 (Functional)       (None, 194688)               4800      ['input_24[0][0]']            \n",
      "                                                                                                  \n",
      " contrastive_output_0 (Dens  (None, 128)                  2492019   ['model_21[0][0]']            \n",
      " e)                                                       2                                       \n",
      "                                                                                                  \n",
      " contrastive_output_1 (Dens  (None, 128)                  2492019   ['model_21[0][0]']            \n",
      " e)                                                       2                                       \n",
      "                                                                                                  \n",
      " regression_output_0 (Dense  (None, 1)                    129       ['contrastive_output_0[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " regression_output_1 (Dense  (None, 1)                    129       ['contrastive_output_1[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 49845442 (190.15 MB)\n",
      "Trainable params: 49845442 (190.15 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "192/192 [==============================] - 14s 62ms/step - loss: 35.2676 - contrastive_output_0_loss: 3.6660 - contrastive_output_1_loss: 4.0769 - regression_output_0_loss: 20.8971 - regression_output_1_loss: 6.6275 - val_loss: 7.3920 - val_contrastive_output_0_loss: 3.2179 - val_contrastive_output_1_loss: 3.6887 - val_regression_output_0_loss: 0.1591 - val_regression_output_1_loss: 0.3262\n",
      "Epoch 2/20\n",
      "192/192 [==============================] - 9s 45ms/step - loss: 7.1492 - contrastive_output_0_loss: 3.1493 - contrastive_output_1_loss: 3.5999 - regression_output_0_loss: 0.1501 - regression_output_1_loss: 0.2498 - val_loss: 6.9497 - val_contrastive_output_0_loss: 3.0826 - val_contrastive_output_1_loss: 3.5312 - val_regression_output_0_loss: 0.1272 - val_regression_output_1_loss: 0.2087\n",
      "Epoch 3/20\n",
      "192/192 [==============================] - 9s 45ms/step - loss: 6.8703 - contrastive_output_0_loss: 3.0517 - contrastive_output_1_loss: 3.5011 - regression_output_0_loss: 0.1231 - regression_output_1_loss: 0.1945 - val_loss: 6.7938 - val_contrastive_output_0_loss: 3.0338 - val_contrastive_output_1_loss: 3.4723 - val_regression_output_0_loss: 0.1123 - val_regression_output_1_loss: 0.1754\n",
      "Epoch 4/20\n",
      "192/192 [==============================] - 9s 45ms/step - loss: 6.7300 - contrastive_output_0_loss: 2.9985 - contrastive_output_1_loss: 3.4489 - regression_output_0_loss: 0.1076 - regression_output_1_loss: 0.1750 - val_loss: 6.7492 - val_contrastive_output_0_loss: 2.9928 - val_contrastive_output_1_loss: 3.4774 - val_regression_output_0_loss: 0.0866 - val_regression_output_1_loss: 0.1923\n",
      "Epoch 5/20\n",
      "192/192 [==============================] - 9s 45ms/step - loss: 6.6138 - contrastive_output_0_loss: 2.9613 - contrastive_output_1_loss: 3.4047 - regression_output_0_loss: 0.0929 - regression_output_1_loss: 0.1549 - val_loss: 6.5934 - val_contrastive_output_0_loss: 2.9577 - val_contrastive_output_1_loss: 3.4052 - val_regression_output_0_loss: 0.0776 - val_regression_output_1_loss: 0.1529\n",
      "Epoch 6/20\n",
      "192/192 [==============================] - 8s 43ms/step - loss: 6.5529 - contrastive_output_0_loss: 2.9429 - contrastive_output_1_loss: 3.3763 - regression_output_0_loss: 0.0901 - regression_output_1_loss: 0.1437 - val_loss: 6.5694 - val_contrastive_output_0_loss: 2.9671 - val_contrastive_output_1_loss: 3.3873 - val_regression_output_0_loss: 0.0815 - val_regression_output_1_loss: 0.1335\n",
      "Epoch 7/20\n",
      "192/192 [==============================] - 9s 47ms/step - loss: 6.4782 - contrastive_output_0_loss: 2.9251 - contrastive_output_1_loss: 3.3424 - regression_output_0_loss: 0.0843 - regression_output_1_loss: 0.1264 - val_loss: 6.4962 - val_contrastive_output_0_loss: 2.9396 - val_contrastive_output_1_loss: 3.3652 - val_regression_output_0_loss: 0.0677 - val_regression_output_1_loss: 0.1238\n",
      "Epoch 8/20\n",
      "192/192 [==============================] - 9s 45ms/step - loss: 6.4192 - contrastive_output_0_loss: 2.9059 - contrastive_output_1_loss: 3.3223 - regression_output_0_loss: 0.0732 - regression_output_1_loss: 0.1178 - val_loss: 6.4078 - val_contrastive_output_0_loss: 2.8963 - val_contrastive_output_1_loss: 3.3352 - val_regression_output_0_loss: 0.0639 - val_regression_output_1_loss: 0.1124\n",
      "Epoch 9/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.3671 - contrastive_output_0_loss: 2.8953 - contrastive_output_1_loss: 3.3026 - regression_output_0_loss: 0.0663 - regression_output_1_loss: 0.1029 - val_loss: 6.3802 - val_contrastive_output_0_loss: 2.8899 - val_contrastive_output_1_loss: 3.3253 - val_regression_output_0_loss: 0.0643 - val_regression_output_1_loss: 0.1007\n",
      "Epoch 10/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.3270 - contrastive_output_0_loss: 2.8901 - contrastive_output_1_loss: 3.2820 - regression_output_0_loss: 0.0614 - regression_output_1_loss: 0.0935 - val_loss: 6.3505 - val_contrastive_output_0_loss: 2.8946 - val_contrastive_output_1_loss: 3.3049 - val_regression_output_0_loss: 0.0614 - val_regression_output_1_loss: 0.0896\n",
      "Epoch 11/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.2799 - contrastive_output_0_loss: 2.8721 - contrastive_output_1_loss: 3.2750 - regression_output_0_loss: 0.0595 - regression_output_1_loss: 0.0733 - val_loss: 6.3286 - val_contrastive_output_0_loss: 2.8651 - val_contrastive_output_1_loss: 3.3247 - val_regression_output_0_loss: 0.0598 - val_regression_output_1_loss: 0.0789\n",
      "Epoch 12/20\n",
      "192/192 [==============================] - 9s 48ms/step - loss: 6.2109 - contrastive_output_0_loss: 2.8525 - contrastive_output_1_loss: 3.2551 - regression_output_0_loss: 0.0461 - regression_output_1_loss: 0.0572 - val_loss: 6.2714 - val_contrastive_output_0_loss: 2.8700 - val_contrastive_output_1_loss: 3.2911 - val_regression_output_0_loss: 0.0473 - val_regression_output_1_loss: 0.0630\n",
      "Epoch 13/20\n",
      "192/192 [==============================] - 9s 45ms/step - loss: 6.1803 - contrastive_output_0_loss: 2.8476 - contrastive_output_1_loss: 3.2448 - regression_output_0_loss: 0.0398 - regression_output_1_loss: 0.0482 - val_loss: 6.2340 - val_contrastive_output_0_loss: 2.8560 - val_contrastive_output_1_loss: 3.2807 - val_regression_output_0_loss: 0.0340 - val_regression_output_1_loss: 0.0633\n",
      "Epoch 14/20\n",
      "192/192 [==============================] - 9s 45ms/step - loss: 6.1637 - contrastive_output_0_loss: 2.8421 - contrastive_output_1_loss: 3.2379 - regression_output_0_loss: 0.0372 - regression_output_1_loss: 0.0465 - val_loss: 6.2154 - val_contrastive_output_0_loss: 2.8478 - val_contrastive_output_1_loss: 3.2783 - val_regression_output_0_loss: 0.0369 - val_regression_output_1_loss: 0.0525\n",
      "Epoch 15/20\n",
      "192/192 [==============================] - 9s 47ms/step - loss: 6.1438 - contrastive_output_0_loss: 2.8389 - contrastive_output_1_loss: 3.2319 - regression_output_0_loss: 0.0318 - regression_output_1_loss: 0.0411 - val_loss: 6.2240 - val_contrastive_output_0_loss: 2.8516 - val_contrastive_output_1_loss: 3.2758 - val_regression_output_0_loss: 0.0387 - val_regression_output_1_loss: 0.0579\n",
      "Epoch 16/20\n",
      "192/192 [==============================] - 9s 45ms/step - loss: 6.1379 - contrastive_output_0_loss: 2.8383 - contrastive_output_1_loss: 3.2301 - regression_output_0_loss: 0.0297 - regression_output_1_loss: 0.0397 - val_loss: 6.2063 - val_contrastive_output_0_loss: 2.8456 - val_contrastive_output_1_loss: 3.2775 - val_regression_output_0_loss: 0.0314 - val_regression_output_1_loss: 0.0518\n",
      "Epoch 17/20\n",
      "192/192 [==============================] - 9s 45ms/step - loss: 6.1285 - contrastive_output_0_loss: 2.8381 - contrastive_output_1_loss: 3.2227 - regression_output_0_loss: 0.0318 - regression_output_1_loss: 0.0360 - val_loss: 6.2168 - val_contrastive_output_0_loss: 2.8525 - val_contrastive_output_1_loss: 3.2696 - val_regression_output_0_loss: 0.0457 - val_regression_output_1_loss: 0.0490\n",
      "Epoch 18/20\n",
      "192/192 [==============================] - 9s 45ms/step - loss: 6.1208 - contrastive_output_0_loss: 2.8333 - contrastive_output_1_loss: 3.2220 - regression_output_0_loss: 0.0278 - regression_output_1_loss: 0.0378 - val_loss: 6.2097 - val_contrastive_output_0_loss: 2.8471 - val_contrastive_output_1_loss: 3.2739 - val_regression_output_0_loss: 0.0317 - val_regression_output_1_loss: 0.0569\n",
      "Epoch 19/20\n",
      "192/192 [==============================] - 9s 45ms/step - loss: 6.1110 - contrastive_output_0_loss: 2.8306 - contrastive_output_1_loss: 3.2186 - regression_output_0_loss: 0.0274 - regression_output_1_loss: 0.0345 - val_loss: 6.1957 - val_contrastive_output_0_loss: 2.8501 - val_contrastive_output_1_loss: 3.2638 - val_regression_output_0_loss: 0.0314 - val_regression_output_1_loss: 0.0504\n",
      "Epoch 20/20\n",
      "192/192 [==============================] - 9s 45ms/step - loss: 6.1065 - contrastive_output_0_loss: 2.8302 - contrastive_output_1_loss: 3.2150 - regression_output_0_loss: 0.0274 - regression_output_1_loss: 0.0338 - val_loss: 6.2019 - val_contrastive_output_0_loss: 2.8519 - val_contrastive_output_1_loss: 3.2580 - val_regression_output_0_loss: 0.0339 - val_regression_output_1_loss: 0.0581\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class SupervisedContrastiveLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "def create_encoder(input_shape=(320, 320, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "def add_contrastive_and_regression_heads(input_shape, encoder, embedding_dim, num_tasks):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "\n",
    "    # Add dense layers for contrastive tasks\n",
    "    contrastive_outputs = [Dense(embedding_dim, activation='linear', name=f\"contrastive_output_{i}\")(features) for i in range(num_tasks)]\n",
    "\n",
    "    # Add regression tasks based on contrastive outputs\n",
    "    regression_outputs = [Dense(1, activation='linear', name=f\"regression_output_{i}\")(output) for i, output in enumerate(contrastive_outputs)]\n",
    "\n",
    "    # Concatenate contrastive and regression outputs\n",
    "    all_outputs = contrastive_outputs + regression_outputs\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=all_outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (320, 320, 1)\n",
    "embedding_dim = 128\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "validation_split = 0.2\n",
    "learning_rate = 0.001\n",
    "num_tasks = 2   # P, V\n",
    "temperature = 0.05\n",
    "\n",
    "# Build model\n",
    "encoder = create_encoder()\n",
    "model_with_contrastive_and_regression = add_contrastive_and_regression_heads(input_shape, encoder, embedding_dim, num_tasks)\n",
    "model_with_contrastive_and_regression.summary()\n",
    "\n",
    "# Compile model\n",
    "model_with_contrastive_and_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                                              loss=[SupervisedContrastiveLoss(temperature=temperature) for _ in range(num_tasks)] + ['mse'] * num_tasks,\n",
    ")\n",
    "# Fit model\n",
    "history = model_with_contrastive_and_regression.fit(\n",
    "    x=X_train, \n",
    "    y=[y_train[:, 0], y_train[:, 1], y_train[:, 0], y_train[:, 1]],  # Use contrastive outputs for regression tasks\n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs, \n",
    "    validation_split=validation_split,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_26 (InputLayer)       [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " model_23 (Functional)       (None, 194688)               4800      ['input_26[0][0]']            \n",
      "                                                                                                  \n",
      " contrastive_output_0 (Dens  (None, 128)                  2492019   ['model_23[0][0]']            \n",
      " e)                                                       2                                       \n",
      "                                                                                                  \n",
      " contrastive_output_1 (Dens  (None, 128)                  2492019   ['model_23[0][0]']            \n",
      " e)                                                       2                                       \n",
      "                                                                                                  \n",
      " regression_output_0 (Dense  (None, 1)                    129       ['contrastive_output_0[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " regression_output_1 (Dense  (None, 1)                    129       ['contrastive_output_1[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 49845442 (190.15 MB)\n",
      "Trainable params: 49845442 (190.15 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "192/192 [==============================] - 14s 61ms/step - loss: 30.8961 - contrastive_output_0_loss: 3.7058 - contrastive_output_1_loss: 4.1936 - regression_output_0_loss: 17.2229 - regression_output_1_loss: 5.7738 - contrastive_output_0_contrastive_accuracy: 4.3634e-04 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 1.3120 - regression_output_1_regression_mae: 1.0880 - val_loss: 8.3940 - val_contrastive_output_0_loss: 3.4289 - val_contrastive_output_1_loss: 4.0609 - val_regression_output_0_loss: 0.2696 - val_regression_output_1_loss: 0.6345 - val_contrastive_output_0_contrastive_accuracy: 0.0062 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.4131 - val_regression_output_1_regression_mae: 0.6631\n",
      "Epoch 2/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 8.0966 - contrastive_output_0_loss: 3.3631 - contrastive_output_1_loss: 3.9271 - regression_output_0_loss: 0.2479 - regression_output_1_loss: 0.5585 - contrastive_output_0_contrastive_accuracy: 0.0020 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.3803 - regression_output_1_regression_mae: 0.6163 - val_loss: 7.8393 - val_contrastive_output_0_loss: 3.2923 - val_contrastive_output_1_loss: 3.8047 - val_regression_output_0_loss: 0.2033 - val_regression_output_1_loss: 0.5390 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.3440 - val_regression_output_1_regression_mae: 0.6048\n",
      "Epoch 3/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 7.6212 - contrastive_output_0_loss: 3.2599 - contrastive_output_1_loss: 3.6995 - regression_output_0_loss: 0.1950 - regression_output_1_loss: 0.4667 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.3280 - regression_output_1_regression_mae: 0.5510 - val_loss: 7.3855 - val_contrastive_output_0_loss: 3.2105 - val_contrastive_output_1_loss: 3.6238 - val_regression_output_0_loss: 0.1586 - val_regression_output_1_loss: 0.3925 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.2965 - val_regression_output_1_regression_mae: 0.4849\n",
      "Epoch 4/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 7.2390 - contrastive_output_0_loss: 3.1568 - contrastive_output_1_loss: 3.5801 - regression_output_0_loss: 0.1680 - regression_output_1_loss: 0.3341 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.2942 - regression_output_1_regression_mae: 0.4396 - val_loss: 7.1479 - val_contrastive_output_0_loss: 3.1214 - val_contrastive_output_1_loss: 3.5620 - val_regression_output_0_loss: 0.1822 - val_regression_output_1_loss: 0.2823 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.2793 - val_regression_output_1_regression_mae: 0.3809\n",
      "Epoch 5/20\n",
      "192/192 [==============================] - 9s 47ms/step - loss: 6.8896 - contrastive_output_0_loss: 3.0494 - contrastive_output_1_loss: 3.4851 - regression_output_0_loss: 0.1339 - regression_output_1_loss: 0.2210 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.2430 - regression_output_1_regression_mae: 0.3292 - val_loss: 6.7022 - val_contrastive_output_0_loss: 3.0202 - val_contrastive_output_1_loss: 3.4196 - val_regression_output_0_loss: 0.0993 - val_regression_output_1_loss: 0.1631 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.2192 - val_regression_output_1_regression_mae: 0.2810\n",
      "Epoch 6/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.5640 - contrastive_output_0_loss: 2.9471 - contrastive_output_1_loss: 3.4000 - regression_output_0_loss: 0.0911 - regression_output_1_loss: 0.1258 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.1980 - regression_output_1_regression_mae: 0.2491 - val_loss: 6.4897 - val_contrastive_output_0_loss: 2.9241 - val_contrastive_output_1_loss: 3.3858 - val_regression_output_0_loss: 0.0688 - val_regression_output_1_loss: 0.1110 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.1838 - val_regression_output_1_regression_mae: 0.2312\n",
      "Epoch 7/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.3934 - contrastive_output_0_loss: 2.9036 - contrastive_output_1_loss: 3.3390 - regression_output_0_loss: 0.0630 - regression_output_1_loss: 0.0877 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.1684 - regression_output_1_regression_mae: 0.2101 - val_loss: 6.3842 - val_contrastive_output_0_loss: 2.8977 - val_contrastive_output_1_loss: 3.3456 - val_regression_output_0_loss: 0.0523 - val_regression_output_1_loss: 0.0886 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.1559 - val_regression_output_1_regression_mae: 0.2102\n",
      "Epoch 8/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.2913 - contrastive_output_0_loss: 2.8775 - contrastive_output_1_loss: 3.2983 - regression_output_0_loss: 0.0464 - regression_output_1_loss: 0.0692 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.1438 - regression_output_1_regression_mae: 0.1875 - val_loss: 6.2913 - val_contrastive_output_0_loss: 2.8679 - val_contrastive_output_1_loss: 3.3178 - val_regression_output_0_loss: 0.0357 - val_regression_output_1_loss: 0.0699 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.1270 - val_regression_output_1_regression_mae: 0.1779\n",
      "Epoch 9/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.2512 - contrastive_output_0_loss: 2.8644 - contrastive_output_1_loss: 3.2801 - regression_output_0_loss: 0.0440 - regression_output_1_loss: 0.0627 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.1419 - regression_output_1_regression_mae: 0.1777 - val_loss: 6.2816 - val_contrastive_output_0_loss: 2.8686 - val_contrastive_output_1_loss: 3.3079 - val_regression_output_0_loss: 0.0385 - val_regression_output_1_loss: 0.0666 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.1344 - val_regression_output_1_regression_mae: 0.1733\n",
      "Epoch 10/20\n",
      "192/192 [==============================] - 9s 47ms/step - loss: 6.2241 - contrastive_output_0_loss: 2.8587 - contrastive_output_1_loss: 3.2692 - regression_output_0_loss: 0.0390 - regression_output_1_loss: 0.0572 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.1342 - regression_output_1_regression_mae: 0.1703 - val_loss: 6.2669 - val_contrastive_output_0_loss: 2.8603 - val_contrastive_output_1_loss: 3.2963 - val_regression_output_0_loss: 0.0398 - val_regression_output_1_loss: 0.0706 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.1406 - val_regression_output_1_regression_mae: 0.1846\n",
      "Epoch 11/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.1952 - contrastive_output_0_loss: 2.8496 - contrastive_output_1_loss: 3.2601 - regression_output_0_loss: 0.0353 - regression_output_1_loss: 0.0501 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.1278 - regression_output_1_regression_mae: 0.1581 - val_loss: 6.2526 - val_contrastive_output_0_loss: 2.8534 - val_contrastive_output_1_loss: 3.3010 - val_regression_output_0_loss: 0.0347 - val_regression_output_1_loss: 0.0635 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.1296 - val_regression_output_1_regression_mae: 0.1701\n",
      "Epoch 12/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.1879 - contrastive_output_0_loss: 2.8468 - contrastive_output_1_loss: 3.2539 - regression_output_0_loss: 0.0364 - regression_output_1_loss: 0.0508 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.1320 - regression_output_1_regression_mae: 0.1606 - val_loss: 6.2505 - val_contrastive_output_0_loss: 2.8590 - val_contrastive_output_1_loss: 3.2929 - val_regression_output_0_loss: 0.0317 - val_regression_output_1_loss: 0.0669 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.1202 - val_regression_output_1_regression_mae: 0.1764\n",
      "Epoch 13/20\n",
      "192/192 [==============================] - 9s 48ms/step - loss: 6.1722 - contrastive_output_0_loss: 2.8430 - contrastive_output_1_loss: 3.2487 - regression_output_0_loss: 0.0328 - regression_output_1_loss: 0.0478 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.1232 - regression_output_1_regression_mae: 0.1565 - val_loss: 6.2187 - val_contrastive_output_0_loss: 2.8480 - val_contrastive_output_1_loss: 3.2813 - val_regression_output_0_loss: 0.0344 - val_regression_output_1_loss: 0.0551 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.1276 - val_regression_output_1_regression_mae: 0.1619\n",
      "Epoch 14/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.1675 - contrastive_output_0_loss: 2.8435 - contrastive_output_1_loss: 3.2425 - regression_output_0_loss: 0.0353 - regression_output_1_loss: 0.0462 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.1281 - regression_output_1_regression_mae: 0.1538 - val_loss: 6.2202 - val_contrastive_output_0_loss: 2.8520 - val_contrastive_output_1_loss: 3.2790 - val_regression_output_0_loss: 0.0337 - val_regression_output_1_loss: 0.0555 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.1229 - val_regression_output_1_regression_mae: 0.1570\n",
      "Epoch 15/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.1558 - contrastive_output_0_loss: 2.8418 - contrastive_output_1_loss: 3.2412 - regression_output_0_loss: 0.0314 - regression_output_1_loss: 0.0414 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.1204 - regression_output_1_regression_mae: 0.1443 - val_loss: 6.2034 - val_contrastive_output_0_loss: 2.8433 - val_contrastive_output_1_loss: 3.2733 - val_regression_output_0_loss: 0.0333 - val_regression_output_1_loss: 0.0535 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.1234 - val_regression_output_1_regression_mae: 0.1574\n",
      "Epoch 16/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.1499 - contrastive_output_0_loss: 2.8352 - contrastive_output_1_loss: 3.2390 - regression_output_0_loss: 0.0323 - regression_output_1_loss: 0.0434 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.1236 - regression_output_1_regression_mae: 0.1506 - val_loss: 6.2045 - val_contrastive_output_0_loss: 2.8412 - val_contrastive_output_1_loss: 3.2717 - val_regression_output_0_loss: 0.0373 - val_regression_output_1_loss: 0.0543 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.1431 - val_regression_output_1_regression_mae: 0.1627\n",
      "Epoch 17/20\n",
      "192/192 [==============================] - 9s 47ms/step - loss: 6.1772 - contrastive_output_0_loss: 2.8413 - contrastive_output_1_loss: 3.2424 - regression_output_0_loss: 0.0407 - regression_output_1_loss: 0.0527 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.1350 - regression_output_1_regression_mae: 0.1616 - val_loss: 6.2519 - val_contrastive_output_0_loss: 2.8631 - val_contrastive_output_1_loss: 3.2971 - val_regression_output_0_loss: 0.0344 - val_regression_output_1_loss: 0.0573 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.1304 - val_regression_output_1_regression_mae: 0.1726\n",
      "Epoch 18/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.1195 - contrastive_output_0_loss: 2.8263 - contrastive_output_1_loss: 3.2284 - regression_output_0_loss: 0.0264 - regression_output_1_loss: 0.0384 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.1085 - regression_output_1_regression_mae: 0.1401 - val_loss: 6.2062 - val_contrastive_output_0_loss: 2.8446 - val_contrastive_output_1_loss: 3.2748 - val_regression_output_0_loss: 0.0313 - val_regression_output_1_loss: 0.0555 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.1269 - val_regression_output_1_regression_mae: 0.1638\n",
      "Epoch 19/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.1197 - contrastive_output_0_loss: 2.8273 - contrastive_output_1_loss: 3.2305 - regression_output_0_loss: 0.0252 - regression_output_1_loss: 0.0367 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.1053 - regression_output_1_regression_mae: 0.1363 - val_loss: 6.1893 - val_contrastive_output_0_loss: 2.8423 - val_contrastive_output_1_loss: 3.2667 - val_regression_output_0_loss: 0.0262 - val_regression_output_1_loss: 0.0541 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.1077 - val_regression_output_1_regression_mae: 0.1605\n",
      "Epoch 20/20\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.1260 - contrastive_output_0_loss: 2.8287 - contrastive_output_1_loss: 3.2286 - regression_output_0_loss: 0.0303 - regression_output_1_loss: 0.0383 - contrastive_output_0_contrastive_accuracy: 0.0000e+00 - contrastive_output_1_contrastive_accuracy: 0.0000e+00 - regression_output_0_regression_mae: 0.1171 - regression_output_1_regression_mae: 0.1399 - val_loss: 6.1703 - val_contrastive_output_0_loss: 2.8351 - val_contrastive_output_1_loss: 3.2617 - val_regression_output_0_loss: 0.0260 - val_regression_output_1_loss: 0.0475 - val_contrastive_output_0_contrastive_accuracy: 0.0000e+00 - val_contrastive_output_1_contrastive_accuracy: 0.0000e+00 - val_regression_output_0_regression_mae: 0.1070 - val_regression_output_1_regression_mae: 0.1469\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class SupervisedContrastiveLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        contrastive_loss = tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "        return contrastive_loss\n",
    "\n",
    "def create_encoder(input_shape=(320, 320, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "def add_contrastive_and_regression_heads(input_shape, encoder, embedding_dim, num_tasks):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "\n",
    "    # Add dense layers for contrastive tasks\n",
    "    contrastive_outputs = [Dense(embedding_dim, activation='linear', name=f\"contrastive_output_{i}\")(features) for i in range(num_tasks)]\n",
    "\n",
    "    # Add regression tasks based on contrastive outputs\n",
    "    regression_outputs = [Dense(1, activation='linear', name=f\"regression_output_{i}\")(output) for i, output in enumerate(contrastive_outputs)]\n",
    "\n",
    "    # Concatenate contrastive and regression outputs\n",
    "    all_outputs = contrastive_outputs + regression_outputs\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=all_outputs)\n",
    "    return model\n",
    "\n",
    "# Custom metric for contrastive loss\n",
    "def contrastive_accuracy(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_true, axis=1), tf.argmax(y_pred, axis=1)), dtype=tf.float32))\n",
    "\n",
    "# Custom metric for regression loss (Mean Absolute Error, MAE)\n",
    "def regression_mae(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "\n",
    "input_shape = (320, 320, 1)\n",
    "embedding_dim = 128\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "validation_split = 0.2\n",
    "learning_rate = 0.001\n",
    "num_tasks = 2   # P, V\n",
    "temperature = 0.05\n",
    "\n",
    "# Build model\n",
    "encoder = create_encoder()\n",
    "model_with_contrastive_and_regression = add_contrastive_and_regression_heads(input_shape, encoder, embedding_dim, num_tasks)\n",
    "model_with_contrastive_and_regression.summary()\n",
    "\n",
    "# Compile model\n",
    "model_with_contrastive_and_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                                              loss=[SupervisedContrastiveLoss(temperature=temperature) for _ in range(num_tasks)] + ['mse'] * num_tasks,\n",
    "                                              metrics={'contrastive_output_0': contrastive_accuracy, 'contrastive_output_1': contrastive_accuracy, \n",
    "                                                       'regression_output_0': regression_mae, 'regression_output_1': regression_mae},\n",
    ")\n",
    "# Fit model\n",
    "history = model_with_contrastive_and_regression.fit(\n",
    "    x=X_train, \n",
    "    y=[y_train[:, 0], y_train[:, 1], y_train[:, 0], y_train[:, 1]],  # Use contrastive outputs for regression tasks\n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs, \n",
    "    validation_split=validation_split,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6YElEQVR4nO3deXiU9b3//9c9k8xk3yQhiUlYI4sIVUSKW61SESvFamtVrlaucmxrwVNLuWr5HhWpx0OrHpe2lLbXUdDTUk89dalL5QcooJRFEeoegRM22ZfsZJLMfH5/zJKZ7DOZmSTM83Fd08zc9z33fO7cTPPyc3/u98cyxhgBAADEia2vGwAAABIL4QMAAMQV4QMAAMQV4QMAAMQV4QMAAMQV4QMAAMQV4QMAAMQV4QMAAMRVUl83oC2Px6ODBw8qMzNTlmX1dXMAAEAPGGNUW1ur4uJi2Wxd9230u/Bx8OBBlZaW9nUzAABABPbv36+SkpIut+l34SMzM1OSt/FZWVl93BoAANATNTU1Ki0tDfwd70q/Cx/+Sy1ZWVmEDwAABpieDJlgwCkAAIgrwgcAAIgrwgcAAIirfjfmAwBw5nC73Wpubu7rZiBKkpOTZbfbe70fwgcAICbq6up04MABGWP6uimIEsuyVFJSooyMjF7th/ABAIg6t9utAwcOKC0tTfn5+RSNPAMYY3Ts2DEdOHBA5eXlveoBIXwAAKKuublZxhjl5+crNTW1r5uDKMnPz9eePXvU3Nzcq/DBgFMAQMzQ43Fmidb5JHwAAIC4InwAAIC4InwAABADQ4cO1eOPP97XzeiXGHAKAIDPFVdcoS984QtRCQ3vvPOO0tPTe9+oM1DChI/D1Y1avrFSsqSF08f0dXMAAAOQMUZut1tJSd3/+czPz49DiwamhLnsUt/Uot9v+D+t3LKvr5sCAAnHGKOGppY+efS0yNns2bO1fv16PfHEE7IsS5ZlacWKFbIsS3//+981ceJEOZ1Ovf3229q9e7dmzpypwYMHKyMjQ5MmTdKaNWtC9tf2sotlWfqv//ovff3rX1daWprKy8v1t7/9LZq/5gEjYXo+ctMckqTaxhY1uz1KtidM7gKAPne62a2x963qk8/++OfTlObo/s/dE088oc8++0zjxo3Tz3/+c0nSRx99JEn62c9+pkceeUTDhw9Xbm6u9u/fr2uvvVYPPvignE6nnnnmGc2YMUMVFRUqKyvr9DMWL16shx56SA8//LB+/etfa9asWdq7d6/y8vKic7ADRML8Bc5OTZb/9uSqBuYZAACEys7OlsPhUFpamgoLC1VYWBgopPXzn/9cX/nKVzRixAjl5eVpwoQJ+v73v69x48apvLxcDzzwgEaMGNFtT8bs2bN1yy23aOTIkfqP//gP1dXVaevWrfE4vH4lYXo+7DZLOanJOtXQrFMNTcrPdPZ1kwAgYaQm2/Xxz6f12Wf31oUXXhjyuq6uTvfff79effVVHTp0SC0tLTp9+rT27ev60v748eMDz9PT05WVlaWjR4/2un0DTcKED8l76eVUQ7NO1jf1dVMAIKFYltWjSx/9Vdu7VhYsWKDVq1frkUce0ciRI5WamqpvfOMbamrq+u9LcnJyyGvLsuTxeKLe3v5u4P5LiEBuukM6Xq+qBsIHAKA9h8Mht9vd7XYbN27U7Nmz9fWvf12Stydkz549MW7dmSNhxnxIUm6aN3GerGfMBwCgvaFDh2rLli3as2ePjh8/3mmvRHl5uZ5//nnt2LFD//znP3XrrbcmZA9GpBIsfHjveDlFzwcAoAMLFiyQ3W7X2LFjlZ+f3+kYjkcffVS5ubm6+OKLNWPGDE2bNk0XXHBBnFs7cIV12WXZsmVatmxZoGvp3HPP1X333afp06dLkhobG/WTn/xEzz77rFwul6ZNm6bf/va3Gjx4cNQbHom8dF/4YMwHAKAD55xzjjZt2hSybPbs2e22Gzp0qN54442QZXPnzg153fYyTEf1RqqqqiJq50AXVs9HSUmJfvGLX2jbtm169913deWVV2rmzJmB+6B//OMf6+WXX9Zzzz2n9evX6+DBg7rhhhti0vBI5Ph6Pk7S8wEAQJ8Jq+djxowZIa8ffPBBLVu2TJs3b1ZJSYmefPJJrVy5UldeeaUkafny5RozZow2b96sL37xi9FrdYTy0r1jPuj5AACg70Q85sPtduvZZ59VfX29pkyZom3btqm5uVlTp04NbDN69GiVlZW168LqK61jPhhwCgBAXwn7VtsPPvhAU6ZMUWNjozIyMvTCCy9o7Nix2rFjhxwOh3JyckK2Hzx4sA4fPtzp/lwul1wuV+B1TU1NuE3qsdx0BpwCANDXwu75GDVqlHbs2KEtW7bojjvu0G233aaPP/444gYsWbJE2dnZgUdpaWnE++qOv+eDImMAAPSdsMOHw+HQyJEjNXHiRC1ZskQTJkzQE088ocLCQjU1NbUbuXvkyBEVFhZ2ur+FCxequro68Ni/f3/YB9FT/rtd/JPLAQCA+Ot1nQ+PxyOXy6WJEycqOTlZa9euDayrqKjQvn37NGXKlE7f73Q6lZWVFfKIFSaXAwCg74U15mPhwoWaPn26ysrKVFtbq5UrV2rdunVatWqVsrOzNWfOHM2fP195eXnKysrSnXfeqSlTpvSLO10k7+Ry2anJqmpoVhWTywEA0CfC6vk4evSovvOd72jUqFG66qqr9M4772jVqlX6yle+Ikl67LHHdN111+nGG2/U5ZdfrsLCQj3//PMxaXik8hj3AQCIoaFDh+rxxx8PvLYsSy+++GKn2+/Zs0eWZWnHjh29+txo7Scewur5ePLJJ7tcn5KSoqVLl2rp0qW9alQs5fjmd+GOFwBAPBw6dEi5ublR3efs2bNVVVUVEmpKS0t16NAhDRo0KKqfFQsJNautFFRinTEfAIA46Oqmi2iy2+1x+6zeSqiJ5SRutwUAdO4Pf/iDiouL281QO3PmTH33u9/V7t27NXPmTA0ePFgZGRmaNGmS1qxZ0+U+21522bp1q84//3ylpKTowgsv1Pbt20O2d7vdmjNnjoYNG6bU1FSNGjVKTzzxRGD9/fffr6efflovvfSSLMuSZVlat25dh5dd1q9fr4suukhOp1NFRUX62c9+ppaWlsD6K664Qv/6r/+qn/70p8rLy1NhYaHuv//+8H9xYUq4no9cJpcDgPgzRmpu6JvPTk5T4FbHbnzzm9/UnXfeqTfffFNXXXWVJOnkyZN6/fXX9dprr6murk7XXnutHnzwQTmdTj3zzDOaMWOGKioqVFZW1u3+6+rqdN111+krX/mK/vjHP6qyslI/+tGPQrbxeDwqKSnRc889p7POOkv/+Mc/9L3vfU9FRUW66aabtGDBAn3yySeqqanR8uXLJUl5eXk6ePBgyH4+//xzXXvttZo9e7aeeeYZffrpp7r99tuVkpISEjCefvppzZ8/X1u2bNGmTZs0e/ZsXXLJJYHxnLGQeOGDEusAEH/NDdJ/FPfNZ/+/g5IjvUeb5ubmavr06Vq5cmUgfPzv//6vBg0apC9/+cuy2WyaMGFCYPsHHnhAL7zwgv72t79p3rx53e5/5cqV8ng8evLJJ5WSkqJzzz1XBw4c0B133BHYJjk5WYsXLw68HjZsmDZt2qS//OUvuummm5SRkaHU1FS5XK4uL7P89re/VWlpqX7zm9/IsiyNHj1aBw8e1N1336377rtPNpv34sf48eO1aNEiSVJ5ebl+85vfaO3atTENHwl32SUwuRwDTgEAHZg1a5b++te/Bqb++NOf/qSbb75ZNptNdXV1WrBggcaMGaOcnBxlZGTok08+0b59+3q0708++UTjx49XSkpKYFlHtbCWLl2qiRMnKj8/XxkZGfrDH/7Q488I/qwpU6bICur1ueSSS1RXV6cDBw4Elo0fPz7kfUVFRTp69GhYnxWuhOv5yGHMBwDEX3Katweirz47DDNmzJAxRq+++qomTZqkt956S4899pgkacGCBVq9erUeeeQRjRw5UqmpqfrGN76hpqbo/U159tlntWDBAv3nf/6npkyZoszMTD388MPasmVL1D4jWHJycshry7LajXmJtoQLH/67Xaro+QCA+LGsHl/66GspKSm64YYb9Kc//Um7du3SqFGjdMEFF0iSNm7cqNmzZ+vrX/+6JO8Yjj179vR432PGjNF///d/q7GxMdD7sXnz5pBtNm7cqIsvvlg//OEPA8t2794dso3D4ZDb7e72s/7617/KGBPo/di4caMyMzNVUlLS4zbHQsJddsn11fmg5wMA0JlZs2bp1Vdf1VNPPaVZs2YFlpeXl+v555/Xjh079M9//lO33nprWL0Et956qyzL0u23366PP/5Yr732mh555JGQbcrLy/Xuu+9q1apV+uyzz3TvvffqnXfeCdlm6NChev/991VRUaHjx4+rubn9OMYf/vCH2r9/v+688059+umneumll7Ro0SLNnz8/MN6jryRg+PD2fNQ0tqiFyeUAAB248sorlZeXp4qKCt16662B5Y8++qhyc3N18cUXa8aMGZo2bVqgV6QnMjIy9PLLL+uDDz7Q+eefr3/7t3/TL3/5y5Btvv/97+uGG27Qt771LU2ePFknTpwI6QWRpNtvv12jRo3ShRdeqPz8fG3cuLHdZ5199tl67bXXtHXrVk2YMEE/+MEPNGfOHN1zzz1h/jaizzLGmL5uRLCamhplZ2eruro6JpPMtbg9Kr/n7zJGeveeqRqUwfwuABBtjY2Nqqys1LBhw0IGV2Jg6+q8hvP3O+F6PpLsNmWl+O544dILAABxl3DhQ2oddMq4DwAA4i8hw0duYHI5Co0BABBvCRo+/FVO6fkAACDeEjN8pBM+AADoKwkZPvKYXA4A4qKf3VCJXorW+UzI8JETKDTGmA8AiAW73S5JUS07jr7nP5/+8xuphCuvLkl5aZRYB4BYSkpKUlpamo4dO6bk5OQ+r6iJ3vN4PDp27JjS0tKUlNS7+JCQ4cM/5uMk4QMAYsKyLBUVFamyslJ79+7t6+YgSmw2m8rKykJmyo1EYoaPNMZ8AECsORwOlZeXc+nlDOJwOKLSi5WQ4SMvnTofABAPNpuN8upoJyEvwvl7PqpPNzO5HAAAcZaQ4SM7NTnwvOo0vR8AAMRTQoaPJLstEEC44wUAgPhKyPAhBU8uR88HAADxlLDho7XQGD0fAADEU8KGDwqNAQDQNxI2fOSkUWgMAIC+kLDhI1Drg8suAADEVcKGD3+JdQqNAQAQX4kbPiixDgBAn0j48MGYDwAA4ithw4e/zkcVl10AAIirhA0fudT5AACgTyRu+PD1fNQ0MrkcAADxlLDhI8c3t4sx3tltAQBAfCRs+Eiy25SVkiRJOsWgUwAA4iZhw4fUOuiUWh8AAMRPQoeP3MDMtvR8AAAQL4kdPig0BgBA3BE+xGUXAADiKaHDR2ByOQacAgAQNwkdPnLSGPMBAEC8JXT4aC2xTvgAACBeEjp85NLzAQBA3CV4+PCP+WDAKQAA8ZLQ4aO1yBg9HwAAxEtChw9/kbHq00wuBwBAvCR0+GByOQAA4i+hw0fo5HKEDwAA4iGhw4fUeumFcR8AAMQH4YP5XQAAiKuEDx/c8QIAQHwlfPjI8dX6OFnPmA8AAOIh4cNHXhol1gEAiKeEDx/+AaeUWAcAID4IH2mM+QAAIJ7CCh9LlizRpEmTlJmZqYKCAl1//fWqqKgI2eaKK66QZVkhjx/84AdRbXQ05aUzvwsAAPEUVvhYv3695s6dq82bN2v16tVqbm7W1Vdfrfr6+pDtbr/9dh06dCjweOihh6La6GjiVlsAAOIrKZyNX3/99ZDXK1asUEFBgbZt26bLL788sDwtLU2FhYXRaWGMBcZ8cNkFAIC46NWYj+rqaklSXl5eyPI//elPGjRokMaNG6eFCxeqoaGh0324XC7V1NSEPOLJ3/NRfbpZbo+J62cDAJCIwur5CObxeHTXXXfpkksu0bhx4wLLb731Vg0ZMkTFxcV6//33dffdd6uiokLPP/98h/tZsmSJFi9eHGkzes1f58M/uZy/6BgAAIgNyxgT0X/u33HHHfr73/+ut99+WyUlJZ1u98Ybb+iqq67Srl27NGLEiHbrXS6XXC5X4HVNTY1KS0tVXV2trKysSJoWtvPuX6Xaxhatmf8ljSzIiMtnAgBwJqmpqVF2dnaP/n5H1PMxb948vfLKK9qwYUOXwUOSJk+eLEmdhg+n0ymn0xlJM6ImL92h2sYWCo0BABAHYY35MMZo3rx5euGFF/TGG29o2LBh3b5nx44dkqSioqKIGhgP/nEfFBoDACD2wur5mDt3rlauXKmXXnpJmZmZOnz4sCQpOztbqamp2r17t1auXKlrr71WZ511lt5//339+Mc/1uWXX67x48fH5ACiITfNX+uD8AEAQKyFFT6WLVsmyVtILNjy5cs1e/ZsORwOrVmzRo8//rjq6+tVWlqqG2+8Uffcc0/UGhwLuYGZbSk0BgBArIUVProbm1paWqr169f3qkF9IY9CYwAAxE3Cz+0iBfd8ED4AAIg1woeCB5xy2QUAgFgjfIgBpwAAxBPhQ1x2AQAgnggfUqCkOgNOAQCIPcKHWud3qWJyOQAAYo7wodYBp8ZINacZdAoAQCwRPiQl223KTPGWPDnJuA8AAGKK8OGTS6ExAADigvDhQ4l1AADig/Dhk+ev9UHPBwAAMUX48AlUOWXMBwAAMUX48KHQGAAA8UH48KHQGAAA8UH48PEXGmNyOQAAYovw4ZPnG/NRxWUXAABiivDh4x/zwYBTAABii/DhQ5ExAADig/Dhk5vuHfNRzeRyAADEFOHDx9/z4WFyOQAAYorw4ZNstynT6Z1cjlofAADEDuEjCIXGAACIPcJHkFxqfQAAEHOEjyD0fAAAEHuEjyB53G4LAEDMET6C5DCzLQAAMUf4CJLnq/VRxZgPAABihvARhBLrAADEHuEjCCXWAQCIPcJHkED4oOcDAICYIXwEyQvcasuYDwAAYoXwEcRfZKyqoUkeJpcDACAmCB9BcoInl2uk9wMAgFggfARxJLVOLneSQacAAMQE4aONHF+tDwadAgAQG4SPNlpLrHPZBQCAWCB8tEGhMQAAYovw0Ya/1kcV4QMAgJggfLThDx8nuewCAEBMED7a8E8uR4l1AABig/DRRg4l1gEAiCnCRxutJdYJHwAAxALho40cX4l1iowBABAbhI82/D0fVUwuBwBATBA+2sgLGvPB5HIAAEQf4aMNJpcDACC2CB9tOJJsyvBNLneKSy8AAEQd4aMDuekMOgUAIFYIHx3IDUwuR/gAACDaCB8dyKXQGAAAMUP46ACFxgAAiB3CRwdaC40x4BQAgGgjfHTAX+ujip4PAACijvDRgVzfZRfudgEAIPoIHx3ITaPEOgAAsUL46ECgzgeXXQAAiDrCRwcCd7tw2QUAgKgLK3wsWbJEkyZNUmZmpgoKCnT99deroqIiZJvGxkbNnTtXZ511ljIyMnTjjTfqyJEjUW10rAUuu5xuZnI5AACiLKzwsX79es2dO1ebN2/W6tWr1dzcrKuvvlr19fWBbX784x/r5Zdf1nPPPaf169fr4MGDuuGGG6Le8Fjy32rr9hjVNrb0cWsAADizJIWz8euvvx7yesWKFSooKNC2bdt0+eWXq7q6Wk8++aRWrlypK6+8UpK0fPlyjRkzRps3b9YXv/jF6LU8hpxJdmU4k1TnatHJhiZl+8IIAADovV6N+aiurpYk5eXlSZK2bdum5uZmTZ06NbDN6NGjVVZWpk2bNnW4D5fLpZqampBHf+Dv/aDKKQAA0RVx+PB4PLrrrrt0ySWXaNy4cZKkw4cPy+FwKCcnJ2TbwYMH6/Dhwx3uZ8mSJcrOzg48SktLI21SVDHoFACA2Ig4fMydO1cffvihnn322V41YOHChaqurg489u/f36v9RUtOGoXGAACIhbDGfPjNmzdPr7zyijZs2KCSkpLA8sLCQjU1Namqqiqk9+PIkSMqLCzscF9Op1NOpzOSZsRUnu+yC4XGAACIrrB6Powxmjdvnl544QW98cYbGjZsWMj6iRMnKjk5WWvXrg0sq6io0L59+zRlypTotDhOAiXWGfMBAEBUhdXzMXfuXK1cuVIvvfSSMjMzA+M4srOzlZqaquzsbM2ZM0fz589XXl6esrKydOedd2rKlCkD5k4XP3+tD8Z8AAAQXWGFj2XLlkmSrrjiipDly5cv1+zZsyVJjz32mGw2m2688Ua5XC5NmzZNv/3tb6PS2Hjy93xwtwsAANEVVvgwpvtqnykpKVq6dKmWLl0acaP6g7xAzwdjPgAAiCbmdulEbhqTywEAEAuEj074L7tUET4AAIgqwkcnAkXGGphcDgCAaCJ8dILJ5QAAiA3CRyecSXalO+ySuOMFAIBoInx0gUJjAABEH+GjC/5CYww6BQAgeggfXQj0fFDrAwCAqCF8dME/uRwl1gEAiB7CRxdy0iixDgBAtBE+upDH/C4AAEQd4aMLrWM+CB8AAEQL4aML/vldTjUw4BQAgGghfHShdWZbej4AAIgWwkcXGHAKAED0ET66EDy5nDFMLgcAQDQQProQPLlcDZPLAQAQFYSPLqQk25Xmn1yOcR8AAEQF4aMbuYz7AAAgqggf3aDQGAAA0UX46IZ/3AeTywEAEB2Ej274ez6q6PkAACAqCB/d8I/5oMQ6AADRQfjoRuuAUy67AAAQDYSPbuSl++Z3oecDAICoIHx0IzCzLWM+AACICsJHN/yXXRhwCgBAdBA+utE64JQxHwAARAPhoxvBt9oyuRwAAL1H+OiGv8hYi8eo1sXkcgAA9BbhoxtMLgcAQHQRPnqAQmMAAEQP4aMHcn21PqooNAYAQK8RPnqAng8AAKKH8NEDrSXWCR8AAPQW4aMH/LfbEj4AAOg9wkcPUGgMAIDoIXz0QC6TywEAEDWEjx5gzAcAANFD+OgBxnwAABA9hI8e8JdYZ8wHAAC9R/joASaXAwAgeggfPeAf88HkcgAA9B7howdSku1KTfZOLlfFpRcAAHqF8NFD/ksvJxl0CgBArxA+eohaHwAARAfho4eo9QEAQHQQPnqImW0BAIgOwkcPUWgMAIDoIHz0kL/Q2KkG7nYBAKA3CB89FOj54LILAAC9QvjoIcZ8AAAQHYSPHvKHjyouuwAA0CuEjx7y1/mgyBgAAL1D+OihQJ2PeiaXAwCgNwgfPRQ8uVwdk8sBABAxwkcPpTpaJ5c7xeRyAABELOzwsWHDBs2YMUPFxcWyLEsvvvhiyPrZs2fLsqyQxzXXXBOt9vap3DTGfQAA0Fthh4/6+npNmDBBS5cu7XSba665RocOHQo8/vznP/eqkf1FLlVOAQDotaRw3zB9+nRNnz69y22cTqcKCwsjblR/RaExAAB6LyZjPtatW6eCggKNGjVKd9xxh06cONHpti6XSzU1NSGP/ionMLMtYz4AAIhU1MPHNddco2eeeUZr167VL3/5S61fv17Tp0+X2+3ucPslS5YoOzs78CgtLY12k6Imzz+/Cz0fAABELOzLLt25+eabA8/PO+88jR8/XiNGjNC6det01VVXtdt+4cKFmj9/fuB1TU1Nvw0g/jEfDDgFACByMb/Vdvjw4Ro0aJB27drV4Xqn06msrKyQR3/VWmKd8AEAQKRiHj4OHDigEydOqKioKNYfFXOBng8uuwAAELGwL7vU1dWF9GJUVlZqx44dysvLU15enhYvXqwbb7xRhYWF2r17t376059q5MiRmjZtWlQb3hfyAiXWGXAKAECkwg4f7777rr785S8HXvvHa9x2221atmyZ3n//fT399NOqqqpScXGxrr76aj3wwANyOp3Ra3UfyfEPOOWyCwAAEQs7fFxxxRVdTqy2atWqXjWoP8sLKjJmjJFlWX3cIgAABh7mdgmDf8Bps5vJ5QAAiBThIwypDrtSkr2/sioKjQEAEBHCR5j8g0654wUAgMgQPsJEoTEAAHqH8BEmCo0BANA7hI8wtRYaY8wHAACRIHyEKZfJ5QAA6BXCR5j8l10oNAYAQGQIH2EKLjQGAADCR/gIU6DEOmM+AACICOEjTPR8AADQO4SPMOVSZAwAgF4hfITJf6ttVUNzlxPsAQCAjhE+wuQvr97k9qi+yd3HrQEAYOAhfIQpeHI5an0AABA+wkcEqPUBAEDkCB8RYNApAACRI3xEgNttAQCIHOEjAhQaAwAgcoSPCNDzAQBA5AgfEWDMBwAAkSN8RCDXd9mlqoHLLgAAhIvwEQF/lVN6PgAACB/hIwKM+QAAIHKEjwhQZAwAgMgRPiLgv+xyqp7J5QAACBfhIwL+AadMLgcAQPgIHxFITbbLmcTkcgAARILwEQHLshh0CgBAhAgfEcoJDDql1gcAAOEgfEQoL90/vws9HwAAhIPwESFKrAMAEBnCR4T84aOKMR8AAISF8BGhQIl1wgcAAGEhfEQoL80/5oMBpwAAhIPwEaFcbrUFACAihI8IMeAUAIDIED4iRJExAAAiQ/iIUI5/zEcDk8sBABAOwkeE/D0fTS0eNTC5HAAAPUb4iFDw5HKM+wAAoOcIHxGyLCuo0Bi32wIA0FOEj16g0BgAAOEjfPQCk8sBABA+wkcv5KRxuy0AAOEifPRCnj980PMBAECPET56ITeo1gcAAOgZwkcvMOAUAIDwET56IVBincsuAAD0GOGjF1oHnHLZBQCAniJ89AIDTgEACB/hoxdyfXU+TjY0MbkcAAA9RPjoBX959aYWj043M7kcAAA9QfjohTSHXQ4mlwMAICyEj16wLCto3AeDTgEA6AnCRy/lBAqN0fMBAEBPED56KVDrg/ABAECPhB0+NmzYoBkzZqi4uFiWZenFF18MWW+M0X333aeioiKlpqZq6tSp2rlzZ7Ta2+8Eqpwy5gMAgB4JO3zU19drwoQJWrp0aYfrH3roIf3qV7/S7373O23ZskXp6emaNm2aGhsbe93Y/oj5XQAACE9SuG+YPn26pk+f3uE6Y4wef/xx3XPPPZo5c6Yk6ZlnntHgwYP14osv6uabb+5da/shCo0BABCeqI75qKys1OHDhzV16tTAsuzsbE2ePFmbNm3q8D0ul0s1NTUhj4GEyeUAAAhPVMPH4cOHJUmDBw8OWT548ODAuraWLFmi7OzswKO0tDSaTYo5f6GxKsIHAAA90ud3uyxcuFDV1dWBx/79+/u6SWFpHXDKmA8AAHoiquGjsLBQknTkyJGQ5UeOHAmsa8vpdCorKyvkMZAw5gMAgPBENXwMGzZMhYWFWrt2bWBZTU2NtmzZoilTpkTzo/qN4CJjTC4HAED3wr7bpa6uTrt27Qq8rqys1I4dO5SXl6eysjLddddd+vd//3eVl5dr2LBhuvfee1VcXKzrr78+mu3uN/xFxly+yeXSHGH/SgEASChh/6V899139eUvfznwev78+ZKk2267TStWrNBPf/pT1dfX63vf+56qqqp06aWX6vXXX1dKSkr0Wt2PpDnscthtanJ7dKqhmfABAEA3LNPPrhXU1NQoOztb1dXVA2b8x+T/WKMjNS69cuelGnd2dl83BwCAuAvn73ef3+1yJvDfbkuJdQAAukf4iAJ/+GByOQAAukf4iILAzLb0fAAA0C3CRxTkpntvtz3J5HIAAHSL8BEFlFgHAKDnCB9RwIBTAAB6jvARBYExH/R8AADQLcJHFARKrDO5HAAA3SJ8RAE9HwAA9BzhIwoY8wEAQM8RPqIgN3hyuSZ3H7cGAID+jfARBem+yeUk6SSXXgAA6BLhIwosywoUGqPKKQAAXUus8PHGg9LuNyR39O9KYX4XAAB6JqmvGxA3xyqkDQ95n6dkS+dcI42+Thp5leRI7/XuGXQKAEDPJE74sCVJF9wmVbwm1R+T3v8f7yMpVRpxpTTmOm8gScuLaPf+222rmN8FAIAuJU74OGuE9LVfSZ7HpP1bpU9elj59WaraJ1W86n1YdmnoJdKYr0mjvyplFfd49/5CY/R8AADQtcQJH342uzRkivcx7UHp8AfSp69In7wiHf1Iqtzgfby2QDp7ovfSzJgZ0qDyLnfr7/k4WHVaxhhZlhWPowEAYMCxjDGmrxsRrKamRtnZ2aqurlZWVlZ8P/zE7tYgcmBr6LpBo7whZMx1UtEXpDbhYsXGSt3/8seSpPxMpy4dOUiXlQ/SpSMHqSArJU4HAABA3wjn7zfhozO1h6VPX/WGkcoNkqeldV12qfeyzOjrpLIpkj1JR2sb9f+e/1Bv7zqmxmZPyK5GF2Z6w8g5+bpoaJ5SHfY4HwwAALFF+Ii201XSzv/PO05k1xqpuaF1XWqeNOpab6/I8CvkspK1be8pvbXzuN7eeVwfHqxW8G/YkWTTpKG5uqw8X5eOHKSxRVmy2bhEAwAY2AgfsdR82lsr5JNXpM/+Lp0+1brOkSENvVQa9iVp2OVSwVidPN2ijbuO662dx/TWzuM6VN0Ysruz0h26xHeJ5rLyfBVmc4kGADDwED7ixd0i7d3YOk6k9mDo+rRB0rDLvEFk2Jdkcodp9/EGvbXzmN7eeVyb/u+EGtrMBVNekKHLyvN1WfkgTR6epzRH4o0JBgAMPISPvmCMdOifUuV67xiRvf8IvTwjSVkl0nBfr8iwy9WUVqjt+7yXaN7adVzvH6gKuUSTbLc0cUhuIIyMK87mEg0AoF8ifPQHLU3S59taw8j+rZKnTQGys8q9QWT4l6Shl6lKGfrH7hN6a+cxbfjsuD6vOh2yeU5asi4oy9X5pTn6QlmOJpTmKCslOY4HBQBAxwgf/VFTg7Rvk6+OyHpvL4kJvivGkgrH+caLfEmm7IvaU2fX2zuPacPO49q0+4TqXC0hu7QsaWR+hs4vy9H5Zbk6vyxH5QWZstM7AgCIM8LHQHD6lPfSzP/5ekaOfRK63pbkLXLmGy/SXDxRHx1t0o59p7R9f5W276vSvpMN7Xab7rBrQmmON5CU5uoLZTkalOGM00EBABIV4WMgqj0i7Xmr9TLNqT2h65NSpJJJ3kqrucOk3KE6lXK2dtTm6t3DTdq+r0r/3F+l+jYDWCWpLC9N55fl6Aul3h6SsUVZciQl1oTGAIDYInycCU7tbb1EU7lBqjvS+bbp+VLuMHlyh+qko1g7m/P1Xm2ONhxL19YTyTIm9DKMI8mmccVZgUs155flqjg7hZLwAICIET7ONMZIxz+TDrwjnaz09oqcqvQ+P32y67cmp6khrURHkoq0s3mQ3qvN0aeuQdprCvS5yVezb3qfgkynJpTm6Lyzs3VeSbbOOzubyzUAgB4jfCSSxmpvGDlZ2RpITvkCSvWBNoNaQ3lk0zHbIO1uydceT4F2mRJt9ozRJ6ZMRjYVZado3NneIHLe2dkad3a28jMJJACA9ggf8Gppkqr3hwaS4Odt65D4VFuZ+kfLaG3yjNUmz7naac6W5L0kU5jVGkjGlxBIAABehA90zxip7mhob8nn73lvB26qC9m01p6rd62xWn3aG0gqTaH8YUQKDSTnlWRp3NnZKsikTDwAJBLCByLnbpYO7pD2bPAOdN23RWoJLXZW78zXJ84vaF3TaL1UPUL7TUG73QzOcgYu1fh7SAgkAHDmInwgelpcvkqtb3nDyIGtkrspZBNX+tnamzVR7+hcvVI7UptPpKqjf1X5mU6NLcrS2OIsjSnK0tiiLA0blE5RNAA4AxA+EDvNp72l4vf4wsjn2yRPaOVVT+5wHc+/SB87JuhN1yhtPJKk3cfqOgwkKck2jSr0BpGxRZkaW5yl0YVZSncyoR4ADCSED8SPq07av9nbM7LnLeng9vZ32AwapeayS3QwtVy7XLn6Z22WtpxM1fuHm3S6uX1RNMuShuSlaWyxN5SM8fWWFGZRiwQA+ivCB/pOY7W0d1Nrz8jhDyR1/E/MpOfLlX62TiYX6oDnLH3WmKPttZn6qD5Hn5tBqlVayPY5acm+HpLWQDKyIEPJdqq1AkBfI3yg/2g4Ke3dKO3ZKJ3cLVXt997+2+aOmo64kjJ03D5Y+9xnaacrR/s9g/S58T/ydVxZctjtGlmQoTFFWTo7J0X5WSkqyHR6H1kpys9wUkoeAOKA8IH+zRjvxHrV+6Wqfa2BpGqf7+f+biu3SlKjkvV5UCCpVoZqTJpqlKYak6Za308rJUvOjDylZeUqMytHBVmpvnDiVEFmSuB5moNxJgAQKcIHBj5XnbdCayCgBAWT6v1S7WF1djmnK25jqVZpqvWFlNqgoHLaliGPI1NKyZY9LVuO9FylZOYpIytXmTlnKSUjR2mZucrIyFBWqkPOJBtjUADAJ5y/3/ynHvonZ4ZUMNr76EhLk1RzoDWMVH8uNVZJjTXen64amcZqeU5XyzRWy+aqlc20yG4Z5aheOVZ9x/tt9j1qO2+a21iqU6pOKlUNVpoabWly2dLUnJSulqQMeRwZMo4MyZkpW0qm7ClZsqdmyZGeJWd6jtIycpSWmaP0rFylpabJsnFZCEBiIXxgYEpySHnDvY9OWJLs/hfGeG8TbqyWXDXen0FBxVV3Sg01J+Wqr1JLfZU8p6tluaqV1FwrR0utUtz1SlWjbDKyW0bZalC2GiSdkDzyPlo6aUgXmo1d9VaqmuWQsSwZWd6WWzbJ/9oKXSb5fvpeW/7nsiSbTZYsb6DxrbMse2B7y7JJNptk2X3btC6zLLssW+tyW+Cnd5l/nWXZZfO/tixZNrsU9BldPzrYxmbven3gdxB8Zv1Pe7Pcx2aXbEmSLVmyJwU9T/atS/Yus/t+Bp771geeJ3l/t4g+j0dyu7x1h9xNbX66vP8xEvjpe+5u9p0fp2R3eP8/o93zZCnJ2ea5o+N/J4gqwgcSg2VJjjTvQ0XtVjt9jy55PFJzvYyrVg11VTpdW6XTddVy1VerqaFaLadr5DldI09jreSqla2pTvbmOiW11CvZXS+nu0EppkFppkHpapQkJVtu5cg3+Db4KlK/uhiKnjKyydjs8tiSZawkGZtdIeFHkiXTblm7E+67Gh7yN7CzK+S+kGYCgc0b5owtOBDaQ3/aOgp+dl8QtQet87c0+H/bt9fy/4+/3f4tLcnq9Mq+kTwtMi1NMoEQ0TZIuGS5m2SZ9rfkx5QtKIh0GFx8j5DfYfDvzQr6nbfdxurkPR0FcnvoOn/QDw78IcvavKfdMnvruXdkSCUXxvf3GoTwAfSUzSY5M2U5M5WeVaz0XuzKeNw6XV+t+poqNdSeUlNjo5rdHrk9brndHrW43YGH2+2W223U7Hvu8Ri1uFvk9ni86zxGLW63PG63b5lHLR6PjMf7PrfHLY/HI2M8ksct+Z4b45HxeCTjkTHukHUypnW58Ugej2wysuT9aZORzfLIkpE9aFnIennX23zbhL63/ba2kNeh6/2sTp631XZd6PtCl9ssoyS5laQWJcmjJLmVrBbZ5VGS1fq89ad3W7vV/vMteWR5PLJ5miP4V5GYfP16YXGZZLmUpCYlq0lJajLJalaS93lgWZKS5JHDalayWuRQixxqlsMKeq4WJatFyVabcONplprO7HN4wlmmsxZ+0GefT/gA+oBlsystM09pmXl93ZQe83iMWjzGG3Y8Ht9Poxa3kdsYud3e5YFlQds1d/PaFXiPJ+gzjFrcHrk9kpHx5iFJMkYeE7rM+F4r8Lr9Ov9/gBtjAss9gefez/T4lnmCnxsjj8f/vHWZ8XgkT4tsnhbJeH9anhZZxvuwGbcst/cPmFFQX4ExvstrQe2WZExrRDLGyNO2n8H3Pn/bvYu8QdEmb4i0jFuWjCzT9rVblvH9lMe7Xh7ZfSHTJrdkWkOiXR5fQOw84JlOIoMx7Zd3tpcW2VvDgpLVZFrDQ4vlkNuWLLfN+9NjOeS2OWRsSUqy22W3WUqyWbL7Hkl2S3abLbDMZkktbqPGFrdczZ7AT1eLR43NbrlaWosh2nzhMiSUWN7nTt+yZLX4gktrmPEHZnu7IO4N06Gv/b9f7+uO3+N/Hfz+oOVW6D7tvod/PyHbW552+wx+76mWwZrS6dmNPcIHgB6x2Sw5AvPw2LvcFgOTP7R52gQ877rgoBQU8hR0RahdKDRqDVRtA6K3MzHJZgsJEv6fsb6TzBgjV4s3jLh8YcQfSlwtbjU2d/AzsJ1HTW536+WlcD9brUPEuupfsfyXvSzvJ3lfW4HllqXA78m/Lvh9wdt7l7fuJzs1OaK2RwvhAwAgyffHyZJsEf5RHUgsy1JKsl0pyXapj/8QJyKGZgMAgLgifAAAgLgifAAAgLgifAAAgLgifAAAgLgifAAAgLgifAAAgLgifAAAgLiKevi4//77fYVqWh+jR3cyLToAAEg4Malweu6552rNmjWtH5JEIVUAAOAVk1SQlJSkwsLCWOwaAAAMcDEZ87Fz504VFxdr+PDhmjVrlvbt2xeLjwEAAANQ1Hs+Jk+erBUrVmjUqFE6dOiQFi9erMsuu0wffvihMjMz223vcrnkcrkCr2tqaqLdJAAA0I9YxgQmQ46JqqoqDRkyRI8++qjmzJnTbv3999+vxYsXt1u+f/9+ZWVlxbJpAAAgSmpqalRaWqqqqiplZ2d3uW3Mw4ckTZo0SVOnTtWSJUvarWvb8/H5559r7NixsW4SAACIgf3796ukpKTLbWJ+G0pdXZ12796tb3/72x2udzqdcjqdgdcZGRnav3+/MjMzZVlWVNviT2WJ0KuSSMcqJdbxcqxnrkQ6Xo71zGOMUW1trYqLi7vdNurhY8GCBZoxY4aGDBmigwcPatGiRbLb7brlllt69H6bzdZtYuqtrKysM/ofQLBEOlYpsY6XYz1zJdLxcqxnlu4ut/hFPXwcOHBAt9xyi06cOKH8/Hxdeuml2rx5s/Lz86P9UQAAYACKevh49tlno71LAABwBkmouV2cTqcWLVoUMsbkTJVIxyol1vFyrGeuRDpejjWxxeVuFwAAAL+E6vkAAAB9j/ABAADiivABAADiivABAADi6owLH0uXLtXQoUOVkpKiyZMna+vWrV1u/9xzz2n06NFKSUnReeedp9deey1OLY3ckiVLNGnSJGVmZqqgoEDXX3+9KioqunzPihUrZFlWyCMlJSVOLe6d+++/v13bR48e3eV7BuJ5laShQ4e2O1bLsjR37twOtx9I53XDhg2aMWOGiouLZVmWXnzxxZD1xhjdd999KioqUmpqqqZOnaqdO3d2u99wv/Px0tXxNjc36+6779Z5552n9PR0FRcX6zvf+Y4OHjzY5T4j+S7EQ3fndvbs2e3afc0113S73/54brs71o6+v5Zl6eGHH+50n/31vMbSGRU+/ud//kfz58/XokWL9N5772nChAmaNm2ajh492uH2//jHP3TLLbdozpw52r59u66//npdf/31+vDDD+Pc8vCsX79ec+fO1ebNm7V69Wo1Nzfr6quvVn19fZfvy8rK0qFDhwKPvXv3xqnFvXfuueeGtP3tt9/udNuBel4l6Z133gk5ztWrV0uSvvnNb3b6noFyXuvr6zVhwgQtXbq0w/UPPfSQfvWrX+l3v/udtmzZovT0dE2bNk2NjY2d7jPc73w8dXW8DQ0Neu+993Tvvffqvffe0/PPP6+Kigp97Wtf63a/4XwX4qW7cytJ11xzTUi7//znP3e5z/56brs71uBjPHTokJ566ilZlqUbb7yxy/32x/MaU+YMctFFF5m5c+cGXrvdblNcXGyWLFnS4fY33XST+epXvxqybPLkyeb73/9+TNsZbUePHjWSzPr16zvdZvny5SY7Ozt+jYqiRYsWmQkTJvR4+zPlvBpjzI9+9CMzYsQI4/F4Olw/UM+rJPPCCy8EXns8HlNYWGgefvjhwLKqqirjdDrNn//85073E+53vq+0Pd6ObN261Ugye/fu7XSbcL8LfaGjY73tttvMzJkzw9rPQDi3PTmvM2fONFdeeWWX2wyE8xptZ0zPR1NTk7Zt26apU6cGltlsNk2dOlWbNm3q8D2bNm0K2V6Spk2b1un2/VV1dbUkKS8vr8vt6urqNGTIEJWWlmrmzJn66KOP4tG8qNi5c6eKi4s1fPhwzZo1S/v27et02zPlvDY1NemPf/yjvvvd73Y5yeJAPq9+lZWVOnz4cMh5y87O1uTJkzs9b5F85/uz6upqWZalnJycLrcL57vQn6xbt04FBQUaNWqU7rjjDp04caLTbc+Uc3vkyBG9+uqrmjNnTrfbDtTzGqkzJnwcP35cbrdbgwcPDlk+ePBgHT58uMP3HD58OKzt+yOPx6O77rpLl1xyicaNG9fpdqNGjdJTTz2ll156SX/84x/l8Xh08cUX68CBA3FsbWQmT56sFStW6PXXX9eyZctUWVmpyy67TLW1tR1ufyacV0l68cUXVVVVpdmzZ3e6zUA+r8H85yac8xbJd76/amxs1N13361bbrmly4nHwv0u9BfXXHONnnnmGa1du1a//OUvtX79ek2fPl1ut7vD7c+Uc/v0008rMzNTN9xwQ5fbDdTz2htRn9sF8TV37lx9+OGH3V4fnDJliqZMmRJ4ffHFF2vMmDH6/e9/rwceeCDWzeyV6dOnB56PHz9ekydP1pAhQ/SXv/ylR/9FMVA9+eSTmj59epfTUw/k8wqv5uZm3XTTTTLGaNmyZV1uO1C/CzfffHPg+Xnnnafx48drxIgRWrduna666qo+bFlsPfXUU5o1a1a3g8AH6nntjTOm52PQoEGy2+06cuRIyPIjR46osLCww/cUFhaGtX1/M2/ePL3yyit68803VVJSEtZ7k5OTdf7552vXrl0xal3s5OTk6Jxzzum07QP9vErS3r17tWbNGv3Lv/xLWO8bqOfVf27COW+RfOf7G3/w2Lt3r1avXh32dOvdfRf6q+HDh2vQoEGdtvtMOLdvvfWWKioqwv4OSwP3vIbjjAkfDodDEydO1Nq1awPLPB6P1q5dG/JfhsGmTJkSsr0krV69utPt+wtjjObNm6cXXnhBb7zxhoYNGxb2Ptxutz744AMVFRXFoIWxVVdXp927d3fa9oF6XoMtX75cBQUF+upXvxrW+wbqeR02bJgKCwtDzltNTY22bNnS6XmL5Dvfn/iDx86dO7VmzRqdddZZYe+ju+9Cf3XgwAGdOHGi03YP9HMreXsuJ06cqAkTJoT93oF6XsPS1yNeo+nZZ581TqfTrFixwnz88cfme9/7nsnJyTGHDx82xhjz7W9/2/zsZz8LbL9x40aTlJRkHnnkEfPJJ5+YRYsWmeTkZPPBBx/01SH0yB133GGys7PNunXrzKFDhwKPhoaGwDZtj3Xx4sVm1apVZvfu3Wbbtm3m5ptvNikpKeajjz7qi0MIy09+8hOzbt06U1lZaTZu3GimTp1qBg0aZI4ePWqMOXPOq5/b7TZlZWXm7rvvbrduIJ/X2tpas337drN9+3YjyTz66KNm+/btgbs7fvGLX5icnBzz0ksvmffff9/MnDnTDBs2zJw+fTqwjyuvvNL8+te/Drzu7jvfl7o63qamJvO1r33NlJSUmB07doR8j10uV2AfbY+3u+9CX+nqWGtra82CBQvMpk2bTGVlpVmzZo254IILTHl5uWlsbAzsY6Cc2+7+HRtjTHV1tUlLSzPLli3rcB8D5bzG0hkVPowx5te//rUpKyszDofDXHTRRWbz5s2BdV/60pfMbbfdFrL9X/7yF3POOecYh8Nhzj33XPPqq6/GucXhk9ThY/ny5YFt2h7rXXfdFfi9DB482Fx77bXmvffei3/jI/Ctb33LFBUVGYfDYc4++2zzrW99y+zatSuw/kw5r36rVq0ykkxFRUW7dQP5vL755psd/rv1H4/H4zH33nuvGTx4sHE6neaqq65q9zsYMmSIWbRoUciyrr7zfamr462srOz0e/zmm28G9tH2eLv7LvSVro61oaHBXH311SY/P98kJyebIUOGmNtvv71diBgo57a7f8fGGPP73//epKammqqqqg73MVDOayxZxhgT064VAACAIGfMmA8AADAwED4AAEBcET4AAEBcET4AAEBcET4AAEBcET4AAEBcET4AAEBcET4AAEBcET4AAEBcET4AAEBcET4AAEBcET4AAEBc/f+IJEBmIBpxvwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
