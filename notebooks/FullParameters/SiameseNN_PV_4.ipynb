{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 11:28:22.602090: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-21 11:28:22.670377: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-21 11:28:22.670414: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-21 11:28:22.672423: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-21 11:28:22.684380: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-21 11:28:23.486821: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "import tensorflow as tf\n",
    "# dont display much info of tensorflow\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any level you prefer\n",
    "\n",
    "# limit gpu memory usage only as much as needed\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "        print(\"Setting memory growth to True for GPU: \", gpu)\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(\"Physical GPUs: \", len(gpus), \"Logical GPUs: \", len(logical_gpus))\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "from tensorflow.keras import layers, models, Input, Model\n",
    "from tensorflow.keras.layers import Lambda, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Activation, GlobalAveragePooling2D, Concatenate, Add, AveragePooling2D\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manta shape:  (9587, 320, 320)\n",
      "xiris shape:  (9587, 320, 320)\n",
      "feats shape:  (9587, 8)\n",
      "y shape:  (9587, 2)\n",
      "max of each column:  [2750   15]\n",
      "feats max:  [232. 159.]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "manta_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_manta.npy\"\n",
    "xiris_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_xiris.npy\"\n",
    "y_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_y.npy\"\n",
    "feats_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_feats.npy\"\n",
    "\n",
    "# load numpy arrays and display shapes\n",
    "manta = np.load(manta_path)\n",
    "xiris = np.load(xiris_path)\n",
    "params = np.load(y_path)\n",
    "print(\"manta shape: \", manta.shape)\n",
    "print(\"xiris shape: \", xiris.shape)\n",
    "feats = np.load(feats_path)\n",
    "print(\"feats shape: \", feats.shape)\n",
    "\n",
    "\n",
    "\n",
    "# use laser power and velocity as labels\n",
    "params = params[:, :2]\n",
    "print(\"y shape: \", params.shape)\n",
    "\n",
    "#y = np.concatenate((params, feats[:, 1:3]), axis=1) # L, H\n",
    "#print(\"y shape: \", y.shape)\n",
    "\n",
    "params_max = np.max(params, axis=0)\n",
    "y = params / params_max\n",
    "\n",
    "# print max of each column\n",
    "print(\"max of each column: \", params_max)\n",
    "\n",
    "feats = feats[:, 1:3] # remove laser power and velocity\n",
    "\n",
    "feats_max = np.max(feats, axis=0)\n",
    "feats = feats / feats_max\n",
    "\n",
    "print(\"feats max: \", feats_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9587"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into train and test sets\n",
    "train_split = 0.8\n",
    "# randomize data with seed\n",
    "np.random.seed(42)\n",
    "indices = np.arange(len(y))\n",
    "\n",
    "# shuffle indices\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "manta = manta[indices]\n",
    "xiris = xiris[indices]\n",
    "y = y[indices]\n",
    "feats = feats[indices]\n",
    "\n",
    "# split data\n",
    "train_samples = int(train_split * len(y))\n",
    "train_manta = manta[:train_samples]\n",
    "train_xiris = xiris[:train_samples]\n",
    "train_y = y[:train_samples]\n",
    "train_feats = feats[:train_samples]\n",
    "\n",
    "test_manta = manta[train_samples:]\n",
    "test_xiris = xiris[train_samples:]\n",
    "test_y = y[train_samples:]\n",
    "test_feats = feats[train_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to encode y\n",
    "def encode_one_column(y):\n",
    "    # create a new array of zeros with the same shape as y\n",
    "    encoded_y = np.zeros(y.shape)\n",
    "    # get the unique values in y\n",
    "    unique_values = np.unique(y)\n",
    "    # loop through the unique values\n",
    "    for i, value in enumerate(unique_values):\n",
    "        # find the indices where y equals the unique value\n",
    "        indices = np.where(y == value)\n",
    "        # set the indices in encoded_y to i\n",
    "        encoded_y[indices] = i\n",
    "    return encoded_y\n",
    "\n",
    "# create new array to store encoded y\n",
    "encoded_y = np.zeros(y.shape)\n",
    "# loop through each column in y and encode it\n",
    "for i in range(y.shape[1]):\n",
    "    encoded_y[:, i] = encode_one_column(y[:, i])\n",
    "    \n",
    "# convert to int\n",
    "encoded_y = encoded_y.astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9587, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_y = encoded_y[:train_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pairs for image 0/7669, Completed 0%\n",
      "Creating pairs for image 1000/7669, Completed 13%\n",
      "Creating pairs for image 2000/7669, Completed 26%\n",
      "Creating pairs for image 3000/7669, Completed 39%\n",
      "Creating pairs for image 4000/7669, Completed 52%\n",
      "Creating pairs for image 5000/7669, Completed 65%\n",
      "Creating pairs for image 6000/7669, Completed 78%\n",
      "Creating pairs for image 7000/7669, Completed 91%\n",
      "pairs shape:  (30676, 2, 320, 320)\n",
      "labels shape:  (30676, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# crate pairs\n",
    "def create_pairs_2_labels(manta, xiris, y_encoded, feats):\n",
    "    # set seed\n",
    "    np.random.seed(42)\n",
    "        \n",
    "    pairs = []\n",
    "    labels = []\n",
    "    features = []\n",
    "    \n",
    "    # define numclasses with the same columns as y_encoded\n",
    "    numclasses = np.zeros(y_encoded.shape[1], dtype=int)\n",
    "\n",
    "    for i in range(y_encoded.shape[1]):\n",
    "        unique_values, unique_indices = np.unique(y_encoded[:, i], return_inverse=True)\n",
    "        numclasses[i] = len(unique_values)\n",
    "    \n",
    "    # creade idx1 and idx2\n",
    "    idx1 = [np.where(y_encoded==i)[0] for i in range(numclasses[0])]\n",
    "    idx2  = [np.where(y_encoded==i)[0] for i in range(numclasses[1])]\n",
    "\n",
    "    for idxA in range(len(y_encoded)):\n",
    "        # grab the current image and label belonging to the current iteration\n",
    "        currentImage = manta[idxA]\n",
    "        label = y_encoded[idxA]\n",
    "        p1 = label[0]\n",
    "        v1 = label[1]\n",
    "        p2 = np.random.choice(np.delete(np.arange(numclasses[0]), p1))\n",
    "        v2 = np.random.choice(np.delete(np.arange(numclasses[1]), v1))\n",
    "\n",
    "        # randomly pick an image that belongs to the same class label\n",
    "        idxB = np.random.choice(np.intersect1d(idx1[p1], idx2[v1])) #np.random.choice(idx[p1][v1])\n",
    "        x11 = xiris[idxB]\n",
    "        # prepare a positive pair and update the images and labels lists, respectively\n",
    "        pairs.append([currentImage, x11])\n",
    "        labels.append([p1, v1, p1, v1])\n",
    "        features.append([feats[idxA][0], feats[idxA][1], feats[idxB][0], feats[idxB][1]])\n",
    "\n",
    "        idxC = np.random.choice(np.intersect1d(idx1[p2], idx2[v1]))\n",
    "        x21 = xiris[idxC]\n",
    "        pairs.append([currentImage, x21])\n",
    "        labels.append([p1, v1, p2, v1])\n",
    "        features.append([feats[idxA][0], feats[idxA][1], feats[idxC][0], feats[idxC][1]])   \n",
    "            \n",
    "        idxD = np.random.choice(np.intersect1d(idx1[p1], idx2[v2]))\n",
    "        x12 = xiris[idxD]\n",
    "        pairs.append([currentImage, x12])\n",
    "        labels.append([p1, v1, p1, v2])\n",
    "        features.append([feats[idxA][0], feats[idxA][1], feats[idxD][0], feats[idxD][1]])\n",
    "        \n",
    "        idxE = np.random.choice(np.intersect1d(idx1[p2], idx2[v2]))\n",
    "        x22 = xiris[idxE]\n",
    "        pairs.append([currentImage, x22])\n",
    "        labels.append([p1, v1, p2, v2])\n",
    "        features.append([feats[idxA][0], feats[idxA][1], feats[idxE][0], feats[idxE][1]])\n",
    "    \n",
    "\n",
    "        if idxA % 1000 == 0:\n",
    "            print(f\"Creating pairs for image {idxA}/{len(y_encoded)}, Completed {int(idxA/len(y_encoded)*100)}%\")\n",
    "    \n",
    "    return np.array(pairs), np.array(labels), np.array(features)\n",
    "\n",
    "                                                                                             \n",
    "# create pairs\n",
    "pairs, labels, features = create_pairs_2_labels(train_manta, train_xiris, train_encoded_y, train_feats)\n",
    "print(\"pairs shape: \", pairs.shape)\n",
    "print(\"labels shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from sklearn.model_selection import train_test_split\\n\\nX_train, X_test, y_train, y_test = train_test_split(pairs, labels, test_size=0.2, random_state=42, shuffle=True)\\n\\ndel pairs, labels\\n\\n# print shapes\\nprint(\"X_train shape: \", X_train.shape, \"y_train shape: \", y_train.shape)\\nprint(\"X_test shape: \", X_test.shape, \"y_test shape: \", y_test.shape) '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pairs, labels, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "del pairs, labels\n",
    "\n",
    "# print shapes\n",
    "print(\"X_train shape: \", X_train.shape, \"y_train shape: \", y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape, \"y_test shape: \", y_test.shape) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# visualize pairs\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m visualize(\u001b[43mX_train\u001b[49m, y_train, to_show\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, num_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "def visualize(pairs, labels, to_show=6, num_col=3, predictions=None, test=False):\n",
    "    \"\"\"Creates a plot of pairs and labels, and prediction if it's test dataset.\n",
    "\n",
    "    Arguments:\n",
    "        pairs: Numpy Array, of pairs to visualize, having shape\n",
    "               (Number of pairs, 2, 28, 28).\n",
    "        to_show: Int, number of examples to visualize (default is 6)\n",
    "                `to_show` must be an integral multiple of `num_col`.\n",
    "                 Otherwise it will be trimmed if it is greater than num_col,\n",
    "                 and incremented if if it is less then num_col.\n",
    "        num_col: Int, number of images in one row - (default is 3)\n",
    "                 For test and train respectively, it should not exceed 3 and 7.\n",
    "        predictions: Numpy Array of predictions with shape (to_show, 1) -\n",
    "                     (default is None)\n",
    "                     Must be passed when test=True.\n",
    "        test: Boolean telling whether the dataset being visualized is\n",
    "              train dataset or test dataset - (default False).\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    num_row = to_show // num_col if to_show // num_col != 0 else 1\n",
    "\n",
    "    # `to_show` must be an integral multiple of `num_col`\n",
    "    #  we found num_row and we have num_col\n",
    "    #  to increment or decrement to_show\n",
    "    #  to make it integral multiple of `num_col`\n",
    "    #  simply set it equal to num_row * num_col\n",
    "    to_show = num_row * num_col\n",
    "\n",
    "    # Plot the images\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(5, 5))\n",
    "    for i in range(to_show):\n",
    "        # If the number of rows is 1, the axes array is one-dimensional\n",
    "        if num_row == 1:\n",
    "            ax = axes[i % num_col]\n",
    "        else:\n",
    "            ax = axes[i // num_col, i % num_col]\n",
    "\n",
    "        ax.imshow(tf.keras.layers.concatenate([pairs[i][0], pairs[i][1]], axis=1), cmap=\"gray\")\n",
    "        ax.set_axis_off()\n",
    "        if test:\n",
    "            ax.set_title(\"True: {} | Pred: {:.5f}\".format(labels[i], predictions[i][0]))\n",
    "        else:\n",
    "            ax.set_title(\"Label: {}\".format(labels[i]))\n",
    "    if test:\n",
    "        plt.tight_layout(rect=(0, 0, 1.9, 1.9), w_pad=0.0)\n",
    "    else:\n",
    "        plt.tight_layout(rect=(0, 0, 1.5, 1.5))\n",
    "    plt.show()\n",
    "\n",
    "# visualize pairs\n",
    "visualize(X_train, y_train, to_show=4, num_col=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " model_1 (Functional)        (None, 128)                  1186918   ['input_3[0][0]',             \n",
      "                                                          4          'input_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128)                  16512     ['model_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 128)                  16512     ['model_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 128)                  16512     ['model_1[1][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 128)                  16512     ['model_1[1][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 1)                    129       ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 1)                    129       ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 1)                    129       ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 1)                    129       ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11935748 (45.53 MB)\n",
      "Trainable params: 11935748 (45.53 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_encoder(input_shape=(320, 320, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# add projection head\n",
    "def add_projection_head(input_shape, encoder, embedding_dim):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    features = Dense(128, activation='relu')(features)\n",
    "\n",
    "    #outputs_p = Dense(embedding_dim, activation='relu')(features)\n",
    "    #outputs_v = Dense(embedding_dim, activation='relu')(features)\n",
    "    #model = Model(inputs=inputs, outputs=[outputs_p, outputs_v] )  \n",
    "    model = Model(inputs=inputs, outputs=features)  \n",
    "    return model\n",
    "\n",
    "input_shape = (320, 320, 1)\n",
    "embedding_dim= 128\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "validation_split = 0.2\n",
    "learning_rate = 0.0001\n",
    "\n",
    "encoder = create_encoder(input_shape)\n",
    "encoder_with_projection_head = add_projection_head(input_shape, encoder, embedding_dim)\n",
    "\n",
    "manta = Input(shape=input_shape)\n",
    "xiris = Input(shape=input_shape)\n",
    "\n",
    "manta_encoded = encoder_with_projection_head(manta)\n",
    "xiris_encoded = encoder_with_projection_head(xiris)\n",
    "\n",
    "manta_outputs_p = Dense(embedding_dim, activation='relu')(manta_encoded)\n",
    "manta_outputs_v = Dense(embedding_dim, activation='relu')(manta_encoded)\n",
    "\n",
    "xiris_outputs_p = Dense(embedding_dim, activation='relu')(xiris_encoded)\n",
    "xiris_outputs_v = Dense(embedding_dim, activation='relu')(xiris_encoded)\n",
    "\n",
    "reg_manta_p = tf.keras.layers.Dense(1, activation=\"linear\")(manta_outputs_p) \n",
    "reg_manta_v = tf.keras.layers.Dense(1, activation=\"linear\")(manta_outputs_v) \n",
    "\n",
    "reg_xiris_p = tf.keras.layers.Dense(1, activation=\"linear\")(xiris_outputs_p) \n",
    "reg_xiris_v = tf.keras.layers.Dense(1, activation=\"linear\")(xiris_outputs_v) \n",
    "\n",
    "siamese_net = tf.keras.Model(inputs=[manta, xiris], outputs=[manta_outputs_p, manta_outputs_v, xiris_outputs_p, xiris_outputs_v, reg_manta_p, reg_manta_v, reg_xiris_p, reg_xiris_v])\n",
    "\n",
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(Model):\n",
    "    \"\"\"\n",
    "        The Siamese Network model with a custom training and testing loops.\n",
    "        Computes the contrastive loss using the two embeddings produced by the Siamese Network.\n",
    "    \"\"\"\n",
    "    def __init__(self, siamese_network):\n",
    "        super().__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = 1.0\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data\n",
    "        X, y = data  \n",
    "        #print(y)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.siamese_network(X) # Forward pass\n",
    "            #print(y_pred)\n",
    "            # compute loss\n",
    "            loss = self.contrastive_loss_PV(y_true=y, y_pred=y_pred)\n",
    "            loss_reg_manta_p = tf.keras.losses.MeanSquaredError()(y[:, 0], y_pred[4])\n",
    "            loss_reg_manta_v = tf.keras.losses.MeanSquaredError()(y[:, 1], y_pred[5])\n",
    "            loss_reg_xiris_p = tf.keras.losses.MeanSquaredError()(y[:, 2], y_pred[6])\n",
    "            loss_reg_xiris_v = tf.keras.losses.MeanSquaredError()(y[:, 3], y_pred[7])\n",
    "            loss = loss + loss_reg_manta_p + loss_reg_manta_v + loss_reg_xiris_p + loss_reg_xiris_v\n",
    "            \n",
    "        # Storing the gradients of the loss function with respect to the weights/parameters.\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.siamese_network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data): # model.evaluate() stores the losses and metrics in a list\n",
    "        # Unpack the data\n",
    "        X, y = data\n",
    "        \n",
    "        # Compute predictions\n",
    "        y_pred = self.siamese_network(X, training=False)\n",
    "        # The loss is computed on the test set\n",
    "        loss = self.contrastive_loss_PV(y_true=y, y_pred=y_pred)\n",
    "        loss_reg_manta_p = tf.keras.losses.MeanSquaredError()(y[:, 0], y_pred[4])\n",
    "        loss_reg_manta_v = tf.keras.losses.MeanSquaredError()(y[:, 1], y_pred[5])\n",
    "        loss_reg_xiris_p = tf.keras.losses.MeanSquaredError()(y[:, 2], y_pred[6])\n",
    "        loss_reg_xiris_v = tf.keras.losses.MeanSquaredError()(y[:, 3], y_pred[7])\n",
    "        loss = loss + loss_reg_manta_p + loss_reg_manta_v + loss_reg_xiris_p + loss_reg_xiris_v\n",
    "        \n",
    "        # Update the loss metric\n",
    "        self.loss_tracker.update_state(loss)\n",
    "    \n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "    \n",
    "\n",
    "    def contrastive_loss_PV(self, y_true, y_pred):\n",
    "        # Extract embeddings\n",
    "        #p1, v1, p2, v2, _ = tf.split(y_pred, num_or_size_splits=[128, 128, 128, 128], axis=1)\n",
    "        # Extract embeddings\n",
    "        p1, v1, p2, v2 = y_pred[0], y_pred[1], y_pred[2], y_pred[3]\n",
    "\n",
    "        # Calculate distances\n",
    "        distance_p = tf.reduce_sum(tf.square(p1 - p2), axis=1, keepdims=True)\n",
    "        distance_v = tf.reduce_sum(tf.square(v1 - v2), axis=1, keepdims=True)\n",
    "        \n",
    "        # convert to float32\n",
    "        distance_p = tf.cast(distance_p, dtype=tf.float32)\n",
    "        distance_v = tf.cast(distance_v, dtype=tf.float32)\n",
    "        \n",
    "        # squeeze distance_p and distance_v\n",
    "        distance_p = tf.squeeze(distance_p, axis=-1)\n",
    "        distance_v = tf.squeeze(distance_v, axis=-1)\n",
    "\n",
    "        # Convert y_true to float32\n",
    "        y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "        # Ensure margin has the same data type as distance_p and distance_v\n",
    "        margin = tf.cast(self.margin, dtype=tf.float32)\n",
    "\n",
    "        # Extract true labels for each task\n",
    "        y_true_p = tf.cast(tf.not_equal(y_true[:, 0], y_true[:, 2]), tf.float32)\n",
    "        y_true_v = tf.cast(tf.not_equal(y_true[:, 1], y_true[:, 3]), tf.float32)\n",
    "        \n",
    "        square_pred_p = tf.square(distance_p)\n",
    "        margin_square_p = tf.square(tf.maximum(margin - distance_p, 0))\n",
    "        loss_p = tf.reduce_mean((1 - y_true_p) * square_pred_p + (y_true_p) * margin_square_p)\n",
    "        \n",
    "        square_pred_v = tf.square(distance_v)\n",
    "        margin_square_v = tf.square(tf.maximum(margin - distance_v, 0))\n",
    "        loss_v = tf.reduce_mean((1 - y_true_v) * square_pred_v + (y_true_v) * margin_square_v)\n",
    "\n",
    "        # Combine the losses\n",
    "        combined_loss = loss_p + loss_v\n",
    "\n",
    "        return combined_loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 11:09:25.929534: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-01-21 11:09:26.270428: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-21 11:09:27.581382: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-21 11:09:28.507356: I external/local_xla/xla/service/service.cc:168] XLA service 0x563fbc016b20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-21 11:09:28.507467: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2024-01-21 11:09:28.540421: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1705835368.806493 1940885 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 54s 112ms/step - loss: 3.2519 - val_loss: 2.1820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f29884987f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create siamese model\n",
    "siamese_model = SiameseModel(siamese_net)\n",
    "# compile model\n",
    "siamese_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
    "# fit model\n",
    "siamese_model.fit(\n",
    "    x=[pairs[:, 0], pairs[:, 1]], \n",
    "    y=labels,\n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs,\n",
    "    validation_split=validation_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" # plot history\\nplt.plot(siamese_model.history.history['loss'], label='train loss')\\nplt.plot(siamese_model.history.history['val_loss'], label='val loss')\\nplt.legend()\\nplt.show() \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # plot history\n",
    "plt.plot(siamese_model.history.history['loss'], label='train loss')\n",
    "plt.plot(siamese_model.history.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_3\n",
      "1 input_4\n",
      "2 model_1\n",
      "3 dense_2\n",
      "4 dense_3\n",
      "5 dense_4\n",
      "6 dense_5\n",
      "7 dense_6\n",
      "8 dense_7\n",
      "9 dense_8\n",
      "10 dense_9\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(siamese_model.siamese_network.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_with_projection_head = add_projection_head(input_shape, encoder, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 320, 320, 1) dtype=float32 (created by layer 'input_3')>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_model.siamese_network.inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " model_1 (Functional)        (None, 128)                  1186918   ['input_3[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128)                  16512     ['model_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 128)                  16512     ['model_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11902208 (45.40 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 11902208 (45.40 MB)\n",
      "__________________________________________________________________________________________________\n",
      "input_3 weights set\n",
      "model_1 weights set\n",
      "dense_2 weights set\n",
      "dense_3 weights set\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)        [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " model_7 (Functional)        [(None, 128),                1190220   ['input_9[0][0]']             \n",
      "                              (None, 128)]                8                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 256)                  0         ['model_7[0][0]',             \n",
      " )                                                                   'model_7[0][1]']             \n",
      "                                                                                                  \n",
      " lenght (Dense)              (None, 1)                    257       ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " height (Dense)              (None, 1)                    257       ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11902722 (45.41 MB)\n",
      "Trainable params: 514 (2.01 KB)\n",
      "Non-trainable params: 11902208 (45.40 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(320, 320, 1))\n",
    "\n",
    "new_model = tf.keras.Model(inputs=siamese_model.siamese_network.inputs[0], outputs=[siamese_model.siamese_network.layers[3].output, siamese_model.siamese_network.layers[4].output])\n",
    "new_model.summary()\n",
    "\n",
    "# set weights of new model \n",
    "for layer in new_model.layers:\n",
    "    layer.set_weights(siamese_model.siamese_network.get_layer(layer.name).get_weights())\n",
    "    print(layer.name, \"weights set\")\n",
    "    layer.trainable = False\n",
    "    \n",
    "\n",
    "x = new_model(inputs)\n",
    "# merge the last 2 layers in a single layer\n",
    "x = layers.concatenate(x)\n",
    "# add a two regression heads\n",
    "#x = Dense(128, activation='relu')(x)\n",
    "output_l = Dense(1, activation=\"linear\", name=\"lenght\")(x)\n",
    "output_h = Dense(1, activation=\"linear\", name=\"height\")(x)\n",
    "\n",
    "model_3 = Model(inputs=inputs, outputs=[output_l, output_h])\n",
    "model_3.summary()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15338, 320, 320)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.concatenate((train_manta, train_xiris), axis=0)\n",
    "\n",
    "X_train.shape\n",
    "del train_manta, train_xiris, train_y, train_encoded_y, pairs, labels, features\n",
    "\n",
    "\n",
    "y_train = np.concatenate((train_feats, train_feats), axis=0)\n",
    "y_train.shape\n",
    "\n",
    "del train_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 10s 45ms/step - loss: 0.2642 - lenght_loss: 0.2488 - height_loss: 0.0154 - val_loss: 0.0457 - val_lenght_loss: 0.0317 - val_height_loss: 0.0140\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "learning_rate = 0.0001\n",
    "model_3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='mse')\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "history = model_3.fit(x=X_train,\n",
    "            y=[y_train[:, 0], y_train[:, 1]],\n",
    "            #y=y_train[:, 2:], # L, H\n",
    "            batch_size=batch_size, epochs=epochs, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate((test_manta, test_xiris), axis=0)\n",
    "y_test = np.concatenate((test_feats, test_feats), axis=0)\n",
    "\n",
    "del  test_xiris, test_y#, test_feats #test_manta,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12275025248527527, 0.11200489103794098, 0.010745353996753693]\n"
     ]
    }
   ],
   "source": [
    "score = model_3.evaluate(X_test, [y_test[:, 0], y_test[:, 1]], verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 11ms/step\n",
      "r2 score:  -1.0602583563639878 0.08073210738722991\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# eval regression model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "y_pred_l, y_pred_h = model_3.predict(X_test)\n",
    "r2_l = r2_score(y_test[:,0], y_pred_l)\n",
    "r2_h = r2_score(y_test[:,1], y_pred_h)\n",
    "print(\"r2 score: \", r2_l, r2_h)\n",
    "\n",
    "# plot loss and metrics: mse and mae\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Training and validation loss')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = test_manta\n",
    "del test_manta\n",
    "\n",
    "y_test_new = test_feats \n",
    "del test_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_l_new, y_pred_h_new = model_3.predict(X_test_new)\n",
    "r2_l_new = r2_score(y_test_new[:,2], y_pred_l_new)\n",
    "r2_h_new = r2_score(y_test_new[:,3], y_pred_h_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Increase overall text size\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plotting the first scatter plot (length prediction)\n",
    "axs[0].scatter(y_test[:, 2], y_pred_l, alpha=0.7, edgecolors='w', label='Both Channels')\n",
    "axs[0].scatter(y_test_new[:, 2], y_pred_l_new, alpha=0.7, edgecolors='w', label='Only Channel 1')\n",
    "axs[0].plot([min(y_test[:, 2]), max(y_test[:, 2])], [min(y_test[:, 2]), max(y_test[:, 2])], '--', color='red', linewidth=2)\n",
    "axs[0].set_title(\"Length Prediction\")\n",
    "axs[0].set_xlabel(\"True Length\")\n",
    "axs[0].set_ylabel(\"Predicted Length\")\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plotting the second scatter plot (height prediction)\n",
    "axs[1].scatter(y_test[:, 3], y_pred_h, alpha=0.7, edgecolors='w', label='Both Channels')\n",
    "axs[1].scatter(y_test_new[:, 3], y_pred_h_new, alpha=0.7, edgecolors='w', label='Only Channel 1')\n",
    "axs[1].plot([min(y_test[:, 3]), max(y_test[:, 3])], [min(y_test[:, 3]), max(y_test[:, 3])], '--', color='red', linewidth=2)\n",
    "axs[1].set_title(\"Height Prediction\")\n",
    "axs[1].set_xlabel(\"True Height\")\n",
    "axs[1].set_ylabel(\"Predicted Height\")\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Adjust layout for better visualization\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
