{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 10:36:30.433416: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-17 10:36:30.509077: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-17 10:36:30.509132: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-17 10:36:30.511416: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-17 10:36:30.526650: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-17 10:36:31.436530: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_1430045/3769053210.py:7: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n",
      "Setting memory growth to True for GPU:  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 10:36:33.007637: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-17 10:36:33.073669: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-17 10:36:33.073874: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-17 10:36:33.156240: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-17 10:36:33.156402: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-17 10:36:33.156506: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-17 10:36:33.156590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "2024-01-17 10:36:33.158340: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-17 10:36:33.158480: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-17 10:36:33.158564: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
    "import numpy as np\n",
    "\n",
    "# verify if GPU is available\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "# set memory growth to true\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Setting memory growth to True for GPU: \", physical_devices[0])\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# dont display much info of tensorflow\n",
    "tf.get_logger().setLevel('ERROR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manta shape:  (9587, 320, 320)\n",
      "xiris shape:  (9587, 320, 320)\n",
      "y shape:  (9587, 2)\n",
      "y shape:  (9587, 2)\n",
      "max of each column:  [2750   15]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "manta_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_manta.npy\"\n",
    "xiris_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_xiris.npy\"\n",
    "y_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_y.npy\"\n",
    "feats_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_feats.npy\"\n",
    "\n",
    "# load numpy arrays and display shapes\n",
    "manta = np.load(manta_path)\n",
    "xiris = np.load(xiris_path)\n",
    "y = np.load(y_path)\n",
    "print(\"manta shape: \", manta.shape)\n",
    "print(\"xiris shape: \", xiris.shape)\n",
    "print(\"y shape: \", y.shape) # laser power and velocity\n",
    "\n",
    "\"\"\" #feats = np.load(feats_path)\n",
    "#print(\"feats shape: \", feats.shape)\n",
    "y = y[:, 0] # only use laser power\n",
    "print(\"y shape: \", y.shape)\n",
    "\n",
    "# normalize y\n",
    "y = y / np.max(y) \"\"\"\n",
    "\n",
    "# use laser power and velocity as labels\n",
    "y = y[:, :2]\n",
    "print(\"y shape: \", y.shape)\n",
    "\n",
    "# print max of each column\n",
    "print(\"max of each column: \", np.max(y, axis=0))\n",
    "# normalize y by dividing laser power by max of each column\n",
    "y = y / np.max(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9587, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a function to encode y\n",
    "def encode_one_column(y):\n",
    "    # create a new array of zeros with the same shape as y\n",
    "    encoded_y = np.zeros(y.shape)\n",
    "    # get the unique values in y\n",
    "    unique_values = np.unique(y)\n",
    "    # loop through the unique values\n",
    "    for i, value in enumerate(unique_values):\n",
    "        # find the indices where y equals the unique value\n",
    "        indices = np.where(y == value)\n",
    "        # set the indices in encoded_y to i\n",
    "        encoded_y[indices] = i\n",
    "    return encoded_y\n",
    "\n",
    "# create new array to store encoded y\n",
    "y_encoded = np.zeros(y.shape)\n",
    "# loop through each column in y and encode it\n",
    "for i in range(y.shape[1]):\n",
    "    y_encoded[:, i] = encode_one_column(y[:, i])\n",
    "    \n",
    "# convert to int\n",
    "y_encoded = y_encoded.astype(int)\n",
    "y_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  (19174, 320, 320)\n",
      "y shape:  (19174, 2)\n",
      "x_train shape:  (15339, 320, 320)\n",
      "y_train shape:  (15339, 2)\n",
      "x_test shape:  (3835, 320, 320)\n",
      "y_test shape:  (3835, 2)\n"
     ]
    }
   ],
   "source": [
    "# concatenate manta and xiris images with label y_encoded as rows\n",
    "# concatenate the two inputs (manta and xiris) along rows\n",
    "x = np.concatenate((manta, xiris), axis=0)\n",
    "y = np.concatenate((y_encoded, y_encoded), axis=0)\n",
    "print(\"x shape: \", x.shape)\n",
    "print(\"y shape: \", y.shape)\n",
    "\n",
    "# split data into train and test (manta as input and y as output) with shuffle as true\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "print(\"x_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"x_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del manta, xiris, y, y_encoded, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vm/laser/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "2024-01-17 10:36:52.391428: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-17 10:36:52.391649: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-17 10:36:52.391737: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-17 10:36:52.391882: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " model (Functional)          (None, 128)                  1185267   ['input_2[0][0]']             \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " contrastive_output_0 (Dens  (None, 128)                  16512     ['model[0][0]']               \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " contrastive_output_1 (Dens  (None, 128)                  16512     ['model[0][0]']               \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11885696 (45.34 MB)\n",
      "Trainable params: 11885696 (45.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L355\n",
      "2024-01-17 10:36:52.391969: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-17 10:36:52.392040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 128)\n",
      "(None,)\n",
      "Tensor(\"truediv:0\", shape=(None, None), dtype=float32)\n",
      "Tensor(\"strided_slice:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"truediv_1:0\", shape=(None, None), dtype=float32)\n",
      "Tensor(\"strided_slice_1:0\", shape=(None,), dtype=int64)\n",
      "(None, 128)\n",
      "(None,)\n",
      "Tensor(\"truediv:0\", shape=(None, None), dtype=float32)\n",
      "Tensor(\"strided_slice:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"truediv_1:0\", shape=(None, None), dtype=float32)\n",
      "Tensor(\"strided_slice_1:0\", shape=(None,), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-17 10:37:06.115074: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-01-17 10:37:06.236747: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-17 10:37:06.741418: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-17 10:37:09.130848: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f0fc0dc8d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-17 10:37:09.130897: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2024-01-17 10:37:09.139372: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1705487829.349203 1430139 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - ETA: 0s - loss: 7.5312 - loss_p: 3.7344 - loss_v: 4.1843Tensor(\"truediv:0\", shape=(None, None), dtype=float32)\n",
      "Tensor(\"strided_slice:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"truediv_1:0\", shape=(None, None), dtype=float32)\n",
      "Tensor(\"strided_slice_1:0\", shape=(None,), dtype=int64)\n",
      "192/192 [==============================] - 21s 69ms/step - loss: 7.5312 - loss_p: 3.7329 - loss_v: 4.1838 - val_loss: 6.8442 - val_loss_p: 3.3840 - val_loss_v: 4.0098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1058119750>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "def create_encoder(input_shape=(320, 320, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# add projection head\n",
    "def add_projection_head(input_shape, encoder, embedding_dim):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    \n",
    "    contrastive_outputs = [Dense(embedding_dim, activation='linear', name=f\"contrastive_output_{i}\")(features) for i in range(num_tasks)]\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=contrastive_outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (320, 320, 1)\n",
    "embedding_dim = 128\n",
    "num_tasks = 2\n",
    " \n",
    "encoder = create_encoder(input_shape)\n",
    "# build model\n",
    "encoder_with_projection_head = add_projection_head(input_shape, encoder, embedding_dim)\n",
    "# summarize model\n",
    "encoder_with_projection_head.summary()\n",
    "\n",
    "class SupConModel(Model):\n",
    "    def __init__(self, sup_model, temperature=0.05):\n",
    "        super().__init__()\n",
    "        self.sup_model = sup_model\n",
    "        self.temperature = 0.05\n",
    "        #self.contrastive_loss = SupervisedContrastiveLoss()\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        # track loss_p and loss_v\n",
    "        self.loss_p_tracker = tf.keras.metrics.Mean(name=\"loss_p\")\n",
    "        self.loss_v_tracker = tf.keras.metrics.Mean(name=\"loss_v\")\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.sup_model(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data\n",
    "        X, y = data  \n",
    "        #print(y) y is (none, 2)\n",
    "        y_p = y[:, 0]\n",
    "        y_v = y[:, 1]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.sup_model(X) # Forward pass\n",
    "            print(y_pred[0].shape)\n",
    "            print(y_p.shape)\n",
    "            # compute loss\n",
    "            loss_p = self.supervised_contrastive_loss(y_p, y_pred[0])\n",
    "            loss_v = self.supervised_contrastive_loss(y_v, y_pred[1])\n",
    "            loss = loss_p + loss_v\n",
    "            \n",
    "        # Storing the gradients of the loss function with respect to the weights/parameters.\n",
    "        gradients = tape.gradient(loss, self.sup_model.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.sup_model.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.loss_p_tracker.update_state(loss_p)\n",
    "        self.loss_v_tracker.update_state(loss_v)\n",
    "   \n",
    "        return {\"loss\": self.loss_tracker.result(), \"loss_p\": self.loss_p_tracker.result(), \"loss_v\": self.loss_v_tracker.result()}\n",
    "\n",
    "    def test_step(self, data): # model.evaluate() stores the losses and metrics in a list\n",
    "        # Unpack the data\n",
    "        X, y = data\n",
    "        y_p = y[:, 0]\n",
    "        y_v = y[:, 1]\n",
    "               \n",
    "        # Compute predictions\n",
    "        y_pred = self.sup_model(X, training=False)\n",
    "        # The loss is computed on the test set\n",
    "        loss_p = self.supervised_contrastive_loss(y_p, y_pred[0])\n",
    "        loss_v = self.supervised_contrastive_loss(y_v, y_pred[1])\n",
    "        loss = loss_p + loss_v\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.loss_p_tracker.update_state(loss_p)\n",
    "        self.loss_v_tracker.update_state(loss_v)\n",
    "\n",
    "        return {\"loss\": self.loss_tracker.result(), \"loss_p\": self.loss_p_tracker.result(), \"loss_v\": self.loss_v_tracker.result()}\n",
    "    \n",
    "    def supervised_contrastive_loss(self, labels, feature_vectors):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        # Compute logits\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        print(logits)\n",
    "        print(labels)\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]\n",
    "    \n",
    "model = SupConModel(encoder_with_projection_head, temperature=0.05)\n",
    "\n",
    "# Compile the model\n",
    "learning_rate = 0.0001\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 1\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    x=X_train, \n",
    "    y=y_train,\n",
    "    batch_size=batch_size, epochs=epochs, validation_split=0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_14 (InputLayer)       [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " model_12 (Functional)       (None, 128)                  1185267   ['input_14[0][0]']            \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " contrastive_output_0 (Dens  (None, 128)                  16512     ['model_12[0][0]']            \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " contrastive_output_1 (Dens  (None, 128)                  16512     ['model_12[0][0]']            \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " regression_output_0 (Dense  (None, 1)                    129       ['contrastive_output_0[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " regression_output_1 (Dense  (None, 1)                    129       ['contrastive_output_1[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11885954 (45.34 MB)\n",
      "Trainable params: 11885954 (45.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 13s 62ms/step - loss: 7.5090 - loss_p: 3.7388 - loss_v: 4.1663 - loss_reg: 5.0373 - val_loss: 6.6741 - val_loss_p: 3.3337 - val_loss_v: 4.0084 - val_loss_reg: 4.9047\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 9s 48ms/step - loss: 6.4317 - loss_p: 3.2344 - loss_v: 3.8832 - loss_reg: 4.7918 - val_loss: 6.2562 - val_loss_p: 3.1332 - val_loss_v: 3.7361 - val_loss_reg: 4.7068\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 9s 48ms/step - loss: 6.2105 - loss_p: 3.0936 - loss_v: 3.6732 - loss_reg: 4.6695 - val_loss: 6.2553 - val_loss_p: 3.0537 - val_loss_v: 3.5990 - val_loss_reg: 4.6374\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 9s 47ms/step - loss: 6.1575 - loss_p: 3.0327 - loss_v: 3.5636 - loss_reg: 4.6159 - val_loss: 6.1327 - val_loss_p: 3.0069 - val_loss_v: 3.5207 - val_loss_reg: 4.6035\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 9s 49ms/step - loss: 6.1091 - loss_p: 2.9930 - loss_v: 3.4970 - loss_reg: 4.5937 - val_loss: 6.1132 - val_loss_p: 2.9755 - val_loss_v: 3.4687 - val_loss_reg: 4.5833\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 9s 47ms/step - loss: 6.0881 - loss_p: 2.9659 - loss_v: 3.4524 - loss_reg: 4.5750 - val_loss: 6.1014 - val_loss_p: 2.9533 - val_loss_v: 3.4319 - val_loss_reg: 4.5709\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 9s 49ms/step - loss: 6.0657 - loss_p: 2.9459 - loss_v: 3.4193 - loss_reg: 4.5651 - val_loss: 6.0854 - val_loss_p: 2.9365 - val_loss_v: 3.4036 - val_loss_reg: 4.5613\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 9s 47ms/step - loss: 6.0595 - loss_p: 2.9311 - loss_v: 3.3942 - loss_reg: 4.5552 - val_loss: 6.0637 - val_loss_p: 2.9235 - val_loss_v: 3.3817 - val_loss_reg: 4.5543\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 9s 48ms/step - loss: 6.0483 - loss_p: 2.9190 - loss_v: 3.3742 - loss_reg: 4.5491 - val_loss: 6.0697 - val_loss_p: 2.9128 - val_loss_v: 3.3643 - val_loss_reg: 4.5483\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.0316 - loss_p: 2.9088 - loss_v: 3.3577 - loss_reg: 4.5460 - val_loss: 6.0580 - val_loss_p: 2.9038 - val_loss_v: 3.3493 - val_loss_reg: 4.5438\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "def create_encoder(input_shape=(320, 320, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "def add_projection_head(input_shape, encoder, embedding_dim, regression_dim=1):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    \n",
    "    contrastive_outputs = [Dense(embedding_dim, activation='linear', name=f\"contrastive_output_{i}\")(features) for i in range(num_tasks)]\n",
    "\n",
    "    # Add regression head\n",
    "    regression_outputs = [Dense(regression_dim, activation='linear', name=f\"regression_output_{i}\")(output) for i, output in enumerate(contrastive_outputs)]\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=contrastive_outputs + regression_outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (320, 320, 1)\n",
    "embedding_dim = 128\n",
    "regression_dim = 1\n",
    "num_tasks = 2  # Number of contrastive tasks\n",
    "\n",
    "encoder = create_encoder(input_shape)\n",
    "encoder_with_projection_head = add_projection_head(input_shape, encoder, embedding_dim, regression_dim)\n",
    "encoder_with_projection_head.summary()\n",
    "\n",
    "class SupConModel(Model):\n",
    "    def __init__(self, sup_model, temperature=0.05):\n",
    "        super().__init__()\n",
    "        self.sup_model = sup_model\n",
    "        self.temperature = 0.05\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.loss_p_tracker = tf.keras.metrics.Mean(name=\"loss_p\")\n",
    "        self.loss_v_tracker = tf.keras.metrics.Mean(name=\"loss_v\")\n",
    "        self.loss_reg_tracker = tf.keras.metrics.Mean(name=\"loss_reg\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.sup_model(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        X, y = data\n",
    "        #y_p = y[:, 0]\n",
    "        #y_v = y[:, 1]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.sup_model(X)\n",
    "            loss_p = self.supervised_contrastive_loss(y[:, 0], y_pred[0])\n",
    "            loss_v = self.supervised_contrastive_loss(y[:, 1], y_pred[1])\n",
    "            \n",
    "            loss_reg_p = tf.keras.losses.MSE(y[:, 0], y_pred[2])\n",
    "            loss_reg_v = tf.keras.losses.MSE(y[:, 1], y_pred[3])\n",
    "            loss = loss_p + loss_v #+ loss_reg_p + loss_reg_v\n",
    "\n",
    "        gradients = tape.gradient(loss, self.sup_model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.sup_model.trainable_weights))\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.loss_p_tracker.update_state(loss_p)\n",
    "        self.loss_v_tracker.update_state(loss_v)\n",
    "        self.loss_reg_tracker.update_state(loss_reg_p + loss_reg_v)\n",
    "\n",
    "        return {\"loss\": self.loss_tracker.result(), \"loss_p\": self.loss_p_tracker.result(),\n",
    "                \"loss_v\": self.loss_v_tracker.result(), \"loss_reg\": self.loss_reg_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        X, y = data\n",
    "        y_p = y[:, 0]\n",
    "        y_v = y[:, 1]\n",
    "\n",
    "        y_pred = self.sup_model(X, training=False)\n",
    "        loss_p = self.supervised_contrastive_loss(y_p, y_pred[0])\n",
    "        loss_v = self.supervised_contrastive_loss(y_v, y_pred[1])\n",
    "        loss_reg_p = tf.keras.losses.MSE(y_p, y_pred[2])\n",
    "        loss_reg_v = tf.keras.losses.MSE(y_v, y_pred[3])\n",
    "        loss = loss_p + loss_v #+ loss_reg_p + loss_reg_v\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.loss_p_tracker.update_state(loss_p)\n",
    "        self.loss_v_tracker.update_state(loss_v)\n",
    "        self.loss_reg_tracker.update_state(loss_reg_p + loss_reg_v)\n",
    "\n",
    "        return {\"loss\": self.loss_tracker.result(), \"loss_p\": self.loss_p_tracker.result(),\n",
    "                \"loss_v\": self.loss_v_tracker.result(), \"loss_reg\": self.loss_reg_tracker.result()}\n",
    "\n",
    "    def supervised_contrastive_loss(self, labels, feature_vectors):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        # Compute logits\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker]\n",
    "    \n",
    "model = SupConModel(encoder_with_projection_head, temperature=0.05)\n",
    "learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(x=X_train, y=y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Loss vs. epochs\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_14\n",
      "1 model_12\n",
      "2 contrastive_output_0\n",
      "3 contrastive_output_1\n",
      "4 regression_output_0\n",
      "5 regression_output_1\n"
     ]
    }
   ],
   "source": [
    "# list all layers in econder_with_projection_head and print index and name\n",
    "for i, layer in enumerate(encoder_with_projection_head.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_14 (InputLayer)       [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " model_12 (Functional)       (None, 128)                  1185267   ['input_14[0][0]']            \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " contrastive_output_0 (Dens  (None, 128)                  16512     ['model_12[0][0]']            \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " contrastive_output_1 (Dens  (None, 128)                  16512     ['model_12[0][0]']            \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11885696 (45.34 MB)\n",
      "Trainable params: 11885696 (45.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = Model(inputs=encoder_with_projection_head.input, outputs=[encoder_with_projection_head.layers[2].output, encoder_with_projection_head.layers[3].output])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)       [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " model_17 (Functional)       [(None, 128),                1188569   ['input_16[0][0]']            \n",
      "                              (None, 128)]                6                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 256)                  0         ['model_17[1][0]',            \n",
      " )                                                                   'model_17[1][1]']            \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 128)                  32896     ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 1)                    129       ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 1)                    2         ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11918723 (45.47 MB)\n",
      "Trainable params: 11918723 (45.47 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "192/192 [==============================] - 11s 49ms/step - loss: 1.5715 - mse: 1.5715 - val_loss: 1.1695 - val_mse: 1.1695\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 1.0325 - mse: 1.0325 - val_loss: 0.9614 - val_mse: 0.9614\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.8784 - mse: 0.8784 - val_loss: 0.8479 - val_mse: 0.8479\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.7950 - mse: 0.7950 - val_loss: 0.7886 - val_mse: 0.7886\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.7531 - mse: 0.7531 - val_loss: 0.7580 - val_mse: 0.7580\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.7319 - mse: 0.7319 - val_loss: 0.7410 - val_mse: 0.7410\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7195 - mse: 0.7195 - val_loss: 0.7300 - val_mse: 0.7300\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.7104 - mse: 0.7104 - val_loss: 0.7214 - val_mse: 0.7214\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.7024 - mse: 0.7024 - val_loss: 0.7129 - val_mse: 0.7129\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.6944 - mse: 0.6944 - val_loss: 0.7053 - val_mse: 0.7053\n"
     ]
    }
   ],
   "source": [
    "# merge the last 2 layers in a single layer and add a two regression heads\n",
    "# from model_2\n",
    "inputs = Input(shape=(320, 320, 1))\n",
    "x = model_2(inputs)\n",
    "# merge the last 2 layers in a single layer\n",
    "x = layers.concatenate(x)\n",
    "# add a two regression heads\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(1, activation='linear')(x)\n",
    "x = Dense(1, activation='linear')(x)\n",
    "\n",
    "model_3 = Model(inputs=inputs, outputs=x)\n",
    "model_3.summary()\n",
    "\n",
    "\n",
    "# freezw the model except the last 3 layers\n",
    "for layer in model_3.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model\n",
    "learning_rate = 0.0001\n",
    "model_3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='mse', metrics=['mse'])\n",
    "\n",
    "# train the model\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "history = model_3.fit(x=X_train, y=y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Loss vs. epochs\")\n",
    "plt.ylabel(\"Loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"regression_output_0\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (128,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 145\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmetrics\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;66;03m# We need to list our metrics here so the `reset_states()` can be\u001b[39;00m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;66;03m# called automatically.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_tracker]\n\u001b[0;32m--> 145\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSupConModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[1;32m    148\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0001\u001b[39m\n",
      "Cell \u001b[0;32mIn[26], line 44\u001b[0m, in \u001b[0;36mSupConModel.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m create_encoder(input_shape)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msup_model \u001b[38;5;241m=\u001b[39m add_projection_head(input_shape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder, embedding_dim, num_tasks)\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregression_model \u001b[38;5;241m=\u001b[39m \u001b[43madd_regression_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_tasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_tracker \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mMean(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[26], line 33\u001b[0m, in \u001b[0;36madd_regression_head\u001b[0;34m(input_shape, encoder_with_projection_head, num_tasks)\u001b[0m\n\u001b[1;32m     30\u001b[0m inputs \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39minput_shape)\n\u001b[1;32m     31\u001b[0m features \u001b[38;5;241m=\u001b[39m encoder_with_projection_head(inputs)\n\u001b[0;32m---> 33\u001b[0m regression_outputs \u001b[38;5;241m=\u001b[39m [Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression_output_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)(features[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_tasks)]\n\u001b[1;32m     35\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39mregression_outputs)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "Cell \u001b[0;32mIn[26], line 33\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m inputs \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39minput_shape)\n\u001b[1;32m     31\u001b[0m features \u001b[38;5;241m=\u001b[39m encoder_with_projection_head(inputs)\n\u001b[0;32m---> 33\u001b[0m regression_outputs \u001b[38;5;241m=\u001b[39m [\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mregression_output_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_tasks)]\n\u001b[1;32m     35\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39mregression_outputs)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/input_spec.py:253\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    251\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m<\u001b[39m spec\u001b[38;5;241m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 253\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    254\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    255\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected min_ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mmin_ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m         )\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# Check dtype.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"regression_output_0\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (128,)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "def create_encoder(input_shape=(320, 320, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "def add_projection_head(input_shape, encoder, embedding_dim, num_tasks):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    \n",
    "    contrastive_outputs = [Dense(embedding_dim, activation='linear', name=f\"contrastive_output_{i}\")(features) for i in range(num_tasks)]\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=contrastive_outputs)\n",
    "    return model\n",
    "\n",
    "def add_regression_head(input_shape, encoder_with_projection_head, num_tasks):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder_with_projection_head(inputs)\n",
    "    \n",
    "    regression_outputs = [Dense(1, activation='linear', name=f\"regression_output_{i}\")(features[i]) for i in range(num_tasks)]\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=regression_outputs)\n",
    "    return model\n",
    "\n",
    "class SupConModel(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = create_encoder(input_shape)\n",
    "        self.sup_model = add_projection_head(input_shape, self.encoder, embedding_dim, num_tasks)\n",
    "        self.regression_model = add_regression_head(input_shape, self.encoder, num_tasks)\n",
    "        self.temperature = 0.05\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.loss_p_tracker = tf.keras.metrics.Mean(name=\"loss_p\")\n",
    "        self.loss_v_tracker = tf.keras.metrics.Mean(name=\"loss_v\")\n",
    "        self.loss_reg_tracker = tf.keras.metrics.Mean(name=\"loss_reg\")\n",
    "        self.loss_reg_p_tracker = tf.keras.metrics.Mean(name=\"loss_reg_p\")\n",
    "        self.loss_reg_v_tracker = tf.keras.metrics.Mean(name=\"loss_reg_v\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.sup_model(inputs)\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        X, y = data  \n",
    "        y_p = y[:, 0]\n",
    "        y_v = y[:, 1]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.sup_model(X)\n",
    "            loss_p = self.supervised_contrastive_loss(y_p, y_pred[0])\n",
    "            loss_v = self.supervised_contrastive_loss(y_v, y_pred[1])\n",
    "            loss = loss_p + loss_v\n",
    "            \n",
    "        gradients = tape.gradient(loss, self.sup_model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.sup_model.trainable_weights)\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_reg_pred = self.regression_model(X)\n",
    "            loss_reg_p = tf.keras.losses.MSE(y_p, y_reg_pred[0])\n",
    "            loss_reg_v = tf.keras.losses.MSE(y_v, y_reg_pred[1])\n",
    "            loss_reg = loss_reg_p + loss_reg_v\n",
    "        \n",
    "        gradients_reg = tape.gradient(loss_reg, self.regression_model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients_reg, self.regression_model.trainable_weights)\n",
    "        )\n",
    "\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.loss_p_tracker.update_state(loss_p)\n",
    "        self.loss_v_tracker.update_state(loss_v)\n",
    "        \n",
    "        self.loss_reg_tracker.update_state(loss_reg)\n",
    "        self.loss_reg_p_tracker.update_state(loss_reg_p)\n",
    "        self.loss_reg_v_tracker.update_state(loss_reg_v)\n",
    "   \n",
    "        return {\"loss\": self.loss_tracker.result(), \n",
    "                \"loss_p\": self.loss_p_tracker.result(), \"loss_v\": self.loss_v_tracker.result(),\n",
    "                \"loss_reg\": self.loss_reg_tracker.result(),\n",
    "                \"loss_reg_p\": self.loss_reg_p_tracker.result(), \"loss_reg_v\": self.loss_reg_v_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        X, y = data\n",
    "        y_p = y[:, 0]\n",
    "        y_v = y[:, 1]\n",
    "               \n",
    "        y_pred = self.sup_model(X, training=False)\n",
    "        loss_p = self.supervised_contrastive_loss(y_p, y_pred[0])\n",
    "        loss_v = self.supervised_contrastive_loss(y_v, y_pred[1])\n",
    "        loss = loss_p + loss_v\n",
    "        \n",
    "        y_reg_pred = self.regression_model(X, training=False)   \n",
    "        \n",
    "        loss_reg_p = tf.keras.losses.MSE(y_p, y_reg_pred[0])\n",
    "        loss_reg_v = tf.keras.losses.MSE(y_v, y_reg_pred[1])\n",
    "        loss_reg = loss_reg_p + loss_reg_v\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.loss_p_tracker.update_state(loss_p)\n",
    "        self.loss_v_tracker.update_state(loss_v)\n",
    "        \n",
    "        self.loss_reg_tracker.update_state(loss_reg)\n",
    "        self.loss_reg_p_tracker.update_state(loss_reg_p)\n",
    "        self.loss_reg_v_tracker.update_state(loss_reg_v)\n",
    "\n",
    "        return {\"loss\": self.loss_tracker.result(),\n",
    "                \"loss_p\": self.loss_p_tracker.result(), \"loss_v\": self.loss_v_tracker.result(),\n",
    "                \"loss_reg\": self.loss_reg_tracker.result(),\n",
    "                \"loss_reg_p\": self.loss_reg_p_tracker.result(), \"loss_reg_v\": self.loss_reg_v_tracker.result()}\n",
    "\n",
    "    def supervised_contrastive_loss(self, labels, feature_vectors):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        # Compute logits\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]\n",
    "    \n",
    "    \n",
    "\n",
    "model = SupConModel()\n",
    "\n",
    "# Compile the model\n",
    "learning_rate = 0.0001\n",
    "model.compile()\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    x=X_train, \n",
    "    y=y_train,\n",
    "    batch_size=batch_size, epochs=epochs, validation_split=0.2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     25\u001b[0m classifier \u001b[38;5;241m=\u001b[39m create_classifier(encoder, trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 27\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/training.py:1745\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_coordinator \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1736\u001b[0m         tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mcoordinator\u001b[38;5;241m.\u001b[39mClusterCoordinator(\n\u001b[1;32m   1737\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\n\u001b[1;32m   1738\u001b[0m         )\n\u001b[1;32m   1739\u001b[0m     )\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   1742\u001b[0m     \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1743\u001b[0m ):\n\u001b[1;32m   1744\u001b[0m     \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m     data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1762\u001b[0m     \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1688\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1292\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[1;32m   1291\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1292\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:253\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    242\u001b[0m     x,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    251\u001b[0m ):\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 253\u001b[0m     x, y, sample_weights \u001b[38;5;241m=\u001b[39m \u001b[43m_process_tensorlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     sample_weight_modes \u001b[38;5;241m=\u001b[39m broadcast_sample_weight_modes(\n\u001b[1;32m    255\u001b[0m         sample_weights, sample_weight_modes\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# If sample_weights are not specified for an output use 1.0 as weights.\u001b[39;00m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1163\u001b[0m, in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m-> 1163\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_single_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mlist_to_tuple(inputs)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/util/nest.py:631\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    547\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1066\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1066\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1068\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1158\u001b[0m, in \u001b[0;36m_process_tensorlike.<locals>._convert_single_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[1;32m   1157\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[0;32m-> 1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_scipy_sparse(x):\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion.py:161\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m\u001b[38;5;241m.\u001b[39mtf_export(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m     97\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[1;32m     99\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tensor_lib\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion.py:171\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# preferred_dtype = preferred_dtype or dtype_hint\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:335\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    333\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    334\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 335\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    174\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:284\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    283\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 284\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    288\u001b[0m )\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:296\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[1;32m    293\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[1;32m    294\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[1;32m    295\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dropout_rate = 0.2\n",
    "hidden_units = 128\n",
    "num_classes = 4\n",
    "num_epochs = 20\n",
    "def create_classifier(encoder, trainable=False):\n",
    "\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    #features = layers.Dropout(dropout_rate)(features)\n",
    "    #features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "classifier = create_classifier(encoder, trainable=False)\n",
    "\n",
    "history = classifier.fit(x=X_train, y=y_train, batch_size=batch_size, epochs=num_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with x_test and y_test...\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.1364 - sparse_categorical_accuracy: 0.9718\n",
      "loss:  0.136428564786911\n",
      "acc:  0.9718456864356995\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with x_test and y_test\n",
    "loss, acc = classifier.evaluate(x=X_test, y=y_test)\n",
    "print(\"loss: \", loss)\n",
    "print(\"acc: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 16ms/step - loss: 0.0651 - sparse_categorical_accuracy: 0.9838\n"
     ]
    }
   ],
   "source": [
    "# test model with only manta images -> manta_test with first alph of y_test\n",
    "y_test_manta = y_test[:len(y_test)//2]\n",
    "#manta_test = X_test[:len(X_test)//2]\n",
    "\n",
    "accuracy = classifier.evaluate(x=manta_test, y=y_test_manta)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distance_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 76\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(y_true \u001b[38;5;241m*\u001b[39m square_pred \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y_true) \u001b[38;5;241m*\u001b[39m (margin_square_laser_power \u001b[38;5;241m+\u001b[39m margin_square_velocity))\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Create the distance layer\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m distance \u001b[38;5;241m=\u001b[39m \u001b[43mdistance_layer\u001b[49m(image1_network\u001b[38;5;241m.\u001b[39moutput, image2_network\u001b[38;5;241m.\u001b[39moutput, laser_power1, velocity1, laser_power2, velocity2)\n\u001b[1;32m     77\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m[image1_network\u001b[38;5;241m.\u001b[39minput, image2_network\u001b[38;5;241m.\u001b[39minput, laser_power1, velocity1, laser_power2, velocity2], outputs\u001b[38;5;241m=\u001b[39mdistance)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'distance_layer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming you have your images and features preprocessed and stored in numpy arrays\n",
    "# image1, image2, laser_power, velocity\n",
    "\n",
    "# Define the base network architecture\n",
    "def create_base_network():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(32))\n",
    "    return model\n",
    "\n",
    "# Create two instances of the base network\n",
    "base_network = create_base_network()\n",
    "image1_network = models.Model(inputs=base_network.input, outputs=base_network.output)\n",
    "image2_network = models.Model(inputs=base_network.input, outputs=base_network.output)\n",
    "\n",
    "# Define the distance layer\n",
    "class DistanceLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, image1, image2, laser_power1, velocity1, laser_power2, velocity2):\n",
    "        image_distance = tf.reduce_sum(tf.square(image1 - image2), axis=-1)\n",
    "        laser_power_distance = tf.square(laser_power1 - laser_power2)\n",
    "        velocity_distance = tf.square(velocity1 - velocity2)\n",
    "        return image_distance + laser_power_distance + velocity_distance\n",
    "    \n",
    "\n",
    "class ContrastiveLossLaserPower(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, laser_power2):\n",
    "        # Calculate the margin as a function of laser power\n",
    "        margin_laser_power = tf.abs(laser_power1 - laser_power2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_laser_power = tf.square(tf.maximum(margin_laser_power - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square_laser_power)\n",
    "\n",
    "class ContrastiveLossVelocity(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, velocity1, velocity2):\n",
    "        # Calculate the margin as a function of velocity\n",
    "        margin_velocity = tf.abs(velocity1 - velocity2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_velocity = tf.square(tf.maximum(margin_velocity - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square_velocity)\n",
    "    \n",
    "class ContrastiveLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, velocity1, laser_power2, velocity2):\n",
    "        # Calculate the margins as functions of laser power and velocity\n",
    "        margin_laser_power = tf.abs(laser_power1 - laser_power2)\n",
    "        margin_velocity = tf.abs(velocity1 - velocity2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_laser_power = tf.square(tf.maximum(margin_laser_power - y_pred, 0))\n",
    "        margin_square_velocity = tf.square(tf.maximum(margin_velocity - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * (margin_square_laser_power + margin_square_velocity))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the distance layer\n",
    "distance = distance_layer(image1_network.output, image2_network.output, laser_power1, velocity1, laser_power2, velocity2)\n",
    "model = models.Model(inputs=[image1_network.input, image2_network.input, laser_power1, velocity1, laser_power2, velocity2], outputs=distance)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='contrastive_loss')  # You need to define 'contrastive_loss'\n",
    "\n",
    "# Train the model\n",
    "# model.fit([image1, image2, laser_power, velocity], labels, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.contrastive_loss_laser_power = ContrastiveLossLaserPower()\n",
    "        self.contrastive_loss_velocity = ContrastiveLossVelocity()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, laser_power2, velocity1, velocity2):\n",
    "        loss_laser_power = self.contrastive_loss_laser_power(y_true, y_pred, laser_power1, laser_power2)\n",
    "        loss_velocity = self.contrastive_loss_velocity(y_true, y_pred, velocity1, velocity2)\n",
    "        return self.alpha * loss_laser_power + (1 - self.alpha) * loss_velocity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m         margin_square_velocity \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msquare(tf\u001b[38;5;241m.\u001b[39mmaximum(margin_velocity \u001b[38;5;241m-\u001b[39m y_pred, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(y_true \u001b[38;5;241m*\u001b[39m square_pred \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y_true) \u001b[38;5;241m*\u001b[39m margin_square_velocity)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m[ContrastiveLossLaserPower(), ContrastiveLossVelocity()])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "class ContrastiveLossLaserPower(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, laser_power2):\n",
    "        # Calculate the margin as a function of laser power\n",
    "        margin_laser_power = tf.abs(laser_power1 - laser_power2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_laser_power = tf.square(tf.maximum(margin_laser_power - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square_laser_power)\n",
    "\n",
    "class ContrastiveLossVelocity(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, velocity1, velocity2):\n",
    "        # Calculate the margin as a function of velocity\n",
    "        margin_velocity = tf.abs(velocity1 - velocity2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_velocity = tf.square(tf.maximum(margin_velocity - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square_velocity)\n",
    "    \n",
    "model.compile(optimizer='adam', loss=[ContrastiveLossLaserPower(), ContrastiveLossVelocity()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
