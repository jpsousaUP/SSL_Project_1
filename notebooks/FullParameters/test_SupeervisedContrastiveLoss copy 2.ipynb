{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 19:19:35.044536: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-15 19:19:35.101183: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-15 19:19:35.101236: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-15 19:19:35.103850: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-15 19:19:35.116814: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-15 19:19:36.193562: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_1223934/3769053210.py:7: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n",
      "Setting memory growth to True for GPU:  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 19:19:37.745769: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 19:19:37.815589: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 19:19:37.815769: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 19:19:37.892063: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 19:19:37.892223: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 19:19:37.892335: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 19:19:37.892421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "2024-01-15 19:19:37.895805: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 19:19:37.895951: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-15 19:19:37.896035: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
    "import numpy as np\n",
    "\n",
    "# verify if GPU is available\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "# set memory growth to true\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Setting memory growth to True for GPU: \", physical_devices[0])\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# dont display much info of tensorflow\n",
    "tf.get_logger().setLevel('ERROR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manta shape:  (9587, 320, 320)\n",
      "xiris shape:  (9587, 320, 320)\n",
      "y shape:  (9587, 2)\n",
      "y shape:  (9587, 2)\n",
      "max of each column:  [2750   15]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "manta_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_manta.npy\"\n",
    "xiris_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_xiris.npy\"\n",
    "y_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_y.npy\"\n",
    "feats_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_feats.npy\"\n",
    "\n",
    "# load numpy arrays and display shapes\n",
    "manta = np.load(manta_path)\n",
    "xiris = np.load(xiris_path)\n",
    "y = np.load(y_path)\n",
    "print(\"manta shape: \", manta.shape)\n",
    "print(\"xiris shape: \", xiris.shape)\n",
    "print(\"y shape: \", y.shape) # laser power and velocity\n",
    "\n",
    "\"\"\" #feats = np.load(feats_path)\n",
    "#print(\"feats shape: \", feats.shape)\n",
    "y = y[:, 0] # only use laser power\n",
    "print(\"y shape: \", y.shape)\n",
    "\n",
    "# normalize y\n",
    "y = y / np.max(y) \"\"\"\n",
    "\n",
    "# use laser power and velocity as labels\n",
    "y = y[:, :2]\n",
    "print(\"y shape: \", y.shape)\n",
    "\n",
    "# print max of each column\n",
    "print(\"max of each column: \", np.max(y, axis=0))\n",
    "# normalize y by dividing laser power by max of each column\n",
    "y = y / np.max(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9587, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a function to encode y\n",
    "def encode_one_column(y):\n",
    "    # create a new array of zeros with the same shape as y\n",
    "    encoded_y = np.zeros(y.shape)\n",
    "    # get the unique values in y\n",
    "    unique_values = np.unique(y)\n",
    "    # loop through the unique values\n",
    "    for i, value in enumerate(unique_values):\n",
    "        # find the indices where y equals the unique value\n",
    "        indices = np.where(y == value)\n",
    "        # set the indices in encoded_y to i\n",
    "        encoded_y[indices] = i\n",
    "    return encoded_y\n",
    "\n",
    "# create new array to store encoded y\n",
    "y_encoded = np.zeros(y.shape)\n",
    "# loop through each column in y and encode it\n",
    "for i in range(y.shape[1]):\n",
    "    y_encoded[:, i] = encode_one_column(y[:, i])\n",
    "    \n",
    "# convert to int\n",
    "y_encoded = y_encoded.astype(int)\n",
    "y_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  (19174, 320, 320)\n",
      "y shape:  (19174, 2)\n",
      "x_train shape:  (15339, 320, 320)\n",
      "y_train shape:  (15339, 2)\n",
      "x_test shape:  (3835, 320, 320)\n",
      "y_test shape:  (3835, 2)\n"
     ]
    }
   ],
   "source": [
    "# concatenate manta and xiris images with label y_encoded as rows\n",
    "# concatenate the two inputs (manta and xiris) along rows\n",
    "x = np.concatenate((manta, xiris), axis=0)\n",
    "y = np.concatenate((y_encoded, y_encoded), axis=0)\n",
    "print(\"x shape: \", x.shape)\n",
    "print(\"y shape: \", y.shape)\n",
    "\n",
    "# split data into train and test (manta as input and y as output) with shuffle as true\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "print(\"x_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"x_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del manta, xiris, y, y_encoded, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tasks = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None, 320, 320, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " model_4 (Functional)        (None, 128)                  1185267   ['input_6[0][0]']             \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " contrastive_output_0 (Dens  (None, 128)                  16512     ['model_4[0][0]']             \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " contrastive_output_1 (Dens  (None, 128)                  16512     ['model_4[0][0]']             \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11885696 (45.34 MB)\n",
      "Trainable params: 11885696 (45.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_encoder(input_shape=(320, 320, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(16, (3, 3), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# add projection head\n",
    "def add_projection_head(input_shape, encoder, embedding_dim):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    \n",
    "    contrastive_outputs = [Dense(embedding_dim, activation='linear', name=f\"contrastive_output_{i}\")(features) for i in range(num_tasks)]\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=contrastive_outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (320, 320, 1)\n",
    "embedding_dim = 128\n",
    " \n",
    "encoder = create_encoder(input_shape)\n",
    "# build model\n",
    "encoder_with_projection_head = add_projection_head(input_shape, encoder, embedding_dim)\n",
    "# summarize model\n",
    "encoder_with_projection_head.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "class SupConModel(Model):\n",
    "    def __init__(self, sup_model, temperature=0.05):\n",
    "        super().__init__()\n",
    "        self.sup_model = sup_model\n",
    "        self.temperature = 0.05\n",
    "        #self.contrastive_loss = SupervisedContrastiveLoss()\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        # track loss_p and loss_v\n",
    "        self.loss_p_tracker = tf.keras.metrics.Mean(name=\"loss_p\")\n",
    "        self.loss_v_tracker = tf.keras.metrics.Mean(name=\"loss_v\")\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.sup_model(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data\n",
    "        X, y = data  \n",
    "        #print(y) y is (none, 2)\n",
    "        y_p = y[:, 0]\n",
    "        y_v = y[:, 1]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.sup_model(X) # Forward pass\n",
    "            #print(y_pred)\n",
    "            # compute loss\n",
    "            #loss = self.contrastive_loss(y_true=y, y_pred=y_pred)\n",
    "            loss_p = self.supervised_contrastive_loss(y_p, y_pred[0])\n",
    "            loss_v = self.supervised_contrastive_loss(y_v, y_pred[1])\n",
    "            loss = loss_p + loss_v\n",
    "            \n",
    "        # Storing the gradients of the loss function with respect to the weights/parameters.\n",
    "        gradients = tape.gradient(loss, self.sup_model.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.sup_model.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.loss_p_tracker.update_state(loss_p)\n",
    "        self.loss_v_tracker.update_state(loss_v)\n",
    "   \n",
    "        return {\"loss\": self.loss_tracker.result(), \"loss_p\": self.loss_p_tracker.result(), \"loss_v\": self.loss_v_tracker.result()}\n",
    "\n",
    "    def test_step(self, data): # model.evaluate() stores the losses and metrics in a list\n",
    "        # Unpack the data\n",
    "        X, y = data\n",
    "        y_p = y[:, 0]\n",
    "        y_v = y[:, 1]\n",
    "               \n",
    "        # Compute predictions\n",
    "        y_pred = self.sup_model(X, training=False)\n",
    "        # The loss is computed on the test set\n",
    "        #loss = self.supervised_contrastive_loss(y, y_pred)\n",
    "        loss_p = self.supervised_contrastive_loss(y_p, y_pred[0])\n",
    "        loss_v = self.supervised_contrastive_loss(y_v, y_pred[1])\n",
    "        loss = loss_p + loss_v\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.loss_p_tracker.update_state(loss_p)\n",
    "        self.loss_v_tracker.update_state(loss_v)\n",
    "\n",
    "        return {\"loss\": self.loss_tracker.result(), \"loss_p\": self.loss_p_tracker.result(), \"loss_v\": self.loss_v_tracker.result()}\n",
    "    \n",
    "    def supervised_contrastive_loss(self, labels, feature_vectors):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        # Compute logits\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 19:34:38.762927: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-01-15 19:34:38.940021: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-15 19:34:39.535425: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-15 19:34:42.131391: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fa5886a96a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-15 19:34:42.131433: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2024-01-15 19:34:42.142740: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1705347282.381044 1224443 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 21s 69ms/step - loss: 7.3198 - loss_p: 3.6925 - loss_v: 4.1385 - val_loss: 6.5457 - val_loss_p: 3.2880 - val_loss_v: 3.8770\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.3405 - loss_p: 3.1977 - loss_v: 3.7638 - val_loss: 6.2498 - val_loss_p: 3.1079 - val_loss_v: 3.6357\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.1609 - loss_p: 3.0694 - loss_v: 3.5812 - val_loss: 6.1457 - val_loss_p: 3.0273 - val_loss_v: 3.5211\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 9s 46ms/step - loss: 6.0986 - loss_p: 3.0066 - loss_v: 3.4907 - val_loss: 6.1132 - val_loss_p: 2.9821 - val_loss_v: 3.4546\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.0663 - loss_p: 2.9693 - loss_v: 3.4352 - val_loss: 6.0748 - val_loss_p: 2.9521 - val_loss_v: 3.4109\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.0463 - loss_p: 2.9435 - loss_v: 3.3973 - val_loss: 6.0632 - val_loss_p: 2.9309 - val_loss_v: 3.3798\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.0334 - loss_p: 2.9242 - loss_v: 3.3696 - val_loss: 6.0551 - val_loss_p: 2.9151 - val_loss_v: 3.3567\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.0353 - loss_p: 2.9100 - loss_v: 3.3489 - val_loss: 6.0674 - val_loss_p: 2.9038 - val_loss_v: 3.3392\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.0242 - loss_p: 2.8998 - loss_v: 3.3331 - val_loss: 6.0493 - val_loss_p: 2.8940 - val_loss_v: 3.3253\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 8s 44ms/step - loss: 6.0104 - loss_p: 2.8904 - loss_v: 3.3200 - val_loss: 6.0570 - val_loss_p: 2.8857 - val_loss_v: 3.3135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fa5edf6ac80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SupConModel(encoder_with_projection_head, temperature=0.05)\n",
    "\n",
    "# Compile the model\n",
    "learning_rate = 0.0001\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    x=X_train, \n",
    "    y=y_train,\n",
    "    batch_size=batch_size, epochs=epochs, validation_split=0.2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Loss vs. epochs\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     25\u001b[0m classifier \u001b[38;5;241m=\u001b[39m create_classifier(encoder, trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 27\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/training.py:1745\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_coordinator \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1736\u001b[0m         tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mcoordinator\u001b[38;5;241m.\u001b[39mClusterCoordinator(\n\u001b[1;32m   1737\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\n\u001b[1;32m   1738\u001b[0m         )\n\u001b[1;32m   1739\u001b[0m     )\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   1742\u001b[0m     \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1743\u001b[0m ):\n\u001b[1;32m   1744\u001b[0m     \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m     data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1762\u001b[0m     \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1688\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1292\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[1;32m   1291\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1292\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:253\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    242\u001b[0m     x,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    251\u001b[0m ):\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 253\u001b[0m     x, y, sample_weights \u001b[38;5;241m=\u001b[39m \u001b[43m_process_tensorlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     sample_weight_modes \u001b[38;5;241m=\u001b[39m broadcast_sample_weight_modes(\n\u001b[1;32m    255\u001b[0m         sample_weights, sample_weight_modes\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# If sample_weights are not specified for an output use 1.0 as weights.\u001b[39;00m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1163\u001b[0m, in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m-> 1163\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_single_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mlist_to_tuple(inputs)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/util/nest.py:631\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    547\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1066\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1066\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1068\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1158\u001b[0m, in \u001b[0;36m_process_tensorlike.<locals>._convert_single_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[1;32m   1157\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[0;32m-> 1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_scipy_sparse(x):\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion.py:161\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m\u001b[38;5;241m.\u001b[39mtf_export(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m     97\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[1;32m     99\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tensor_lib\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    101\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion.py:171\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# preferred_dtype = preferred_dtype or dtype_hint\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:335\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    333\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    334\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 335\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    174\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:284\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    283\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 284\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    288\u001b[0m )\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:296\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[1;32m    293\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[1;32m    294\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[1;32m    295\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/laser/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dropout_rate = 0.2\n",
    "hidden_units = 128\n",
    "num_classes = 4\n",
    "num_epochs = 20\n",
    "def create_classifier(encoder, trainable=False):\n",
    "\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    #features = layers.Dropout(dropout_rate)(features)\n",
    "    #features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "classifier = create_classifier(encoder, trainable=False)\n",
    "\n",
    "history = classifier.fit(x=X_train, y=y_train, batch_size=batch_size, epochs=num_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with x_test and y_test...\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 0.1364 - sparse_categorical_accuracy: 0.9718\n",
      "loss:  0.136428564786911\n",
      "acc:  0.9718456864356995\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with x_test and y_test\n",
    "loss, acc = classifier.evaluate(x=X_test, y=y_test)\n",
    "print(\"loss: \", loss)\n",
    "print(\"acc: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 16ms/step - loss: 0.0651 - sparse_categorical_accuracy: 0.9838\n"
     ]
    }
   ],
   "source": [
    "# test model with only manta images -> manta_test with first alph of y_test\n",
    "y_test_manta = y_test[:len(y_test)//2]\n",
    "#manta_test = X_test[:len(X_test)//2]\n",
    "\n",
    "accuracy = classifier.evaluate(x=manta_test, y=y_test_manta)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distance_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 76\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(y_true \u001b[38;5;241m*\u001b[39m square_pred \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y_true) \u001b[38;5;241m*\u001b[39m (margin_square_laser_power \u001b[38;5;241m+\u001b[39m margin_square_velocity))\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Create the distance layer\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m distance \u001b[38;5;241m=\u001b[39m \u001b[43mdistance_layer\u001b[49m(image1_network\u001b[38;5;241m.\u001b[39moutput, image2_network\u001b[38;5;241m.\u001b[39moutput, laser_power1, velocity1, laser_power2, velocity2)\n\u001b[1;32m     77\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m[image1_network\u001b[38;5;241m.\u001b[39minput, image2_network\u001b[38;5;241m.\u001b[39minput, laser_power1, velocity1, laser_power2, velocity2], outputs\u001b[38;5;241m=\u001b[39mdistance)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'distance_layer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming you have your images and features preprocessed and stored in numpy arrays\n",
    "# image1, image2, laser_power, velocity\n",
    "\n",
    "# Define the base network architecture\n",
    "def create_base_network():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(32))\n",
    "    return model\n",
    "\n",
    "# Create two instances of the base network\n",
    "base_network = create_base_network()\n",
    "image1_network = models.Model(inputs=base_network.input, outputs=base_network.output)\n",
    "image2_network = models.Model(inputs=base_network.input, outputs=base_network.output)\n",
    "\n",
    "# Define the distance layer\n",
    "class DistanceLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, image1, image2, laser_power1, velocity1, laser_power2, velocity2):\n",
    "        image_distance = tf.reduce_sum(tf.square(image1 - image2), axis=-1)\n",
    "        laser_power_distance = tf.square(laser_power1 - laser_power2)\n",
    "        velocity_distance = tf.square(velocity1 - velocity2)\n",
    "        return image_distance + laser_power_distance + velocity_distance\n",
    "    \n",
    "\n",
    "class ContrastiveLossLaserPower(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, laser_power2):\n",
    "        # Calculate the margin as a function of laser power\n",
    "        margin_laser_power = tf.abs(laser_power1 - laser_power2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_laser_power = tf.square(tf.maximum(margin_laser_power - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square_laser_power)\n",
    "\n",
    "class ContrastiveLossVelocity(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, velocity1, velocity2):\n",
    "        # Calculate the margin as a function of velocity\n",
    "        margin_velocity = tf.abs(velocity1 - velocity2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_velocity = tf.square(tf.maximum(margin_velocity - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square_velocity)\n",
    "    \n",
    "class ContrastiveLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, velocity1, laser_power2, velocity2):\n",
    "        # Calculate the margins as functions of laser power and velocity\n",
    "        margin_laser_power = tf.abs(laser_power1 - laser_power2)\n",
    "        margin_velocity = tf.abs(velocity1 - velocity2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_laser_power = tf.square(tf.maximum(margin_laser_power - y_pred, 0))\n",
    "        margin_square_velocity = tf.square(tf.maximum(margin_velocity - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * (margin_square_laser_power + margin_square_velocity))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the distance layer\n",
    "distance = distance_layer(image1_network.output, image2_network.output, laser_power1, velocity1, laser_power2, velocity2)\n",
    "model = models.Model(inputs=[image1_network.input, image2_network.input, laser_power1, velocity1, laser_power2, velocity2], outputs=distance)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='contrastive_loss')  # You need to define 'contrastive_loss'\n",
    "\n",
    "# Train the model\n",
    "# model.fit([image1, image2, laser_power, velocity], labels, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.contrastive_loss_laser_power = ContrastiveLossLaserPower()\n",
    "        self.contrastive_loss_velocity = ContrastiveLossVelocity()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, laser_power2, velocity1, velocity2):\n",
    "        loss_laser_power = self.contrastive_loss_laser_power(y_true, y_pred, laser_power1, laser_power2)\n",
    "        loss_velocity = self.contrastive_loss_velocity(y_true, y_pred, velocity1, velocity2)\n",
    "        return self.alpha * loss_laser_power + (1 - self.alpha) * loss_velocity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m         margin_square_velocity \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msquare(tf\u001b[38;5;241m.\u001b[39mmaximum(margin_velocity \u001b[38;5;241m-\u001b[39m y_pred, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(y_true \u001b[38;5;241m*\u001b[39m square_pred \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y_true) \u001b[38;5;241m*\u001b[39m margin_square_velocity)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m[ContrastiveLossLaserPower(), ContrastiveLossVelocity()])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "class ContrastiveLossLaserPower(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, laser_power2):\n",
    "        # Calculate the margin as a function of laser power\n",
    "        margin_laser_power = tf.abs(laser_power1 - laser_power2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_laser_power = tf.square(tf.maximum(margin_laser_power - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square_laser_power)\n",
    "\n",
    "class ContrastiveLossVelocity(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, velocity1, velocity2):\n",
    "        # Calculate the margin as a function of velocity\n",
    "        margin_velocity = tf.abs(velocity1 - velocity2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_velocity = tf.square(tf.maximum(margin_velocity - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square_velocity)\n",
    "    \n",
    "model.compile(optimizer='adam', loss=[ContrastiveLossLaserPower(), ContrastiveLossVelocity()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
