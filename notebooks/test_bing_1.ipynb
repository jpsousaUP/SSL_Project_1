{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manta shape:  (9587, 320, 320)\n",
      "xiris shape:  (9587, 320, 320)\n",
      "y shape:  (9587, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "manta_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_manta.npy\"\n",
    "xiris_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_xiris.npy\"\n",
    "y_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_y.npy\"\n",
    "feats_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_feats.npy\"\n",
    "\n",
    "# load numpy arrays and display shapes\n",
    "manta = np.load(manta_path)\n",
    "xiris = np.load(xiris_path)\n",
    "y = np.load(y_path)\n",
    "print(\"manta shape: \", manta.shape)\n",
    "print(\"xiris shape: \", xiris.shape)\n",
    "print(\"y shape: \", y.shape) # laser power and velocity\n",
    "\n",
    "#feats = np.load(feats_path)\n",
    "#print(\"feats shape: \", feats.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  (9587,)\n"
     ]
    }
   ],
   "source": [
    "y = y[:, 0] # only use laser power\n",
    "print(\"y shape: \", y.shape)\n",
    "\n",
    "# normalize y\n",
    "y = y / np.max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values in y:  [0.18181818 0.45454545 0.72727273 1.        ]\n",
      "indices:  [array([   0,    1,    2, ..., 2413, 2414, 2415]), array([2416, 2417, 2418, ..., 4835, 4836, 4837]), array([4838, 4839, 4840, ..., 7205, 7206, 7207]), array([7208, 7209, 7210, ..., 9584, 9585, 9586])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.18181818, 0.18181818, 0.18181818, ..., 1.        , 1.        ,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # get indices of each unique value\n",
    "indices = []\n",
    "for i in range(len(y_unique)):\n",
    "    indices.append(np.where(y == y_unique[i])[0])\n",
    "print(\"indices: \", indices)\n",
    "y \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values in y:  [0.18181818 0.45454545 0.72727273 1.        ]\n",
      "y encoded:  [0. 0. 0. ... 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "# unique values in y\n",
    "y_unique = np.unique(y)\n",
    "print(\"unique values in y: \", y_unique)\n",
    "\n",
    "# encode y as integers based on unique values\n",
    "y_encoded = np.zeros(y.shape)\n",
    "for i in range(len(y_unique)):\n",
    "    y_encoded[y == y_unique[i]] = i\n",
    "print(\"y encoded: \", y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 320, 320, 1)]     0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 369664)            55744     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               47317120  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47372864 (180.71 MB)\n",
      "Trainable params: 47372864 (180.71 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 19:15:41.378299: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 19:15:41.439969: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 19:15:41.440126: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 19:15:41.442250: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 19:15:41.442429: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 19:15:41.442519: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 19:15:41.515031: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 19:15:41.515171: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 19:15:41.515275: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 19:15:41.515352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input, Model\n",
    "\n",
    "def create_encoder():\n",
    "    inputs = Input(shape=(320, 320, 1))\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# add projection head\n",
    "def create_projection_head():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    return model\n",
    "\n",
    "input_shape = (320, 320, 1)\n",
    "\n",
    "def add_projection_head(encoder):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    outputs = layers.Dense(128, activation='relu')(features)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "encoder = create_encoder()\n",
    "encoder_with_projection_head = add_projection_head(encoder)\n",
    "encoder_with_projection_head.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complile model\n",
    "encoder_with_projection_head.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create two instances of the base network\n",
    "base_network = create_base_network()\n",
    "image1_network = models.Model(inputs=base_network.input, outputs=base_network.output)\n",
    "image2_network = models.Model(inputs=base_network.input, outputs=base_network.output)\n",
    "\n",
    "# Define the contrastive loss function\n",
    "class ContrastiveLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, velocity1, laser_power2, velocity2):\n",
    "        # Calculate the margins as functions of laser power and velocity\n",
    "        margin_laser_power = tf.abs(laser_power1 - laser_power2)\n",
    "        margin_velocity = tf.abs(velocity1 - velocity2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_laser_power = tf.square(tf.maximum(margin_laser_power - y_pred, 0))\n",
    "        margin_square_velocity = tf.square(tf.maximum(margin_velocity - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * (margin_square_laser_power + margin_square_velocity))\n",
    "    \n",
    "# Create input layers for laser power and velocity\n",
    "laser_power_input1 = layers.Input(shape=(1,))\n",
    "velocity_input1 = layers.Input(shape=(1,))\n",
    "laser_power_input2 = layers.Input(shape=(1,))\n",
    "velocity_input2 = layers.Input(shape=(1,))\n",
    "\n",
    "# Connect input layers to base networks\n",
    "image1_output = image1_network(base_network.output)\n",
    "image2_output = image2_network(base_network.output)\n",
    "\n",
    "# Concatenate image and feature outputs\n",
    "merged_output = layers.concatenate([image1_output, image2_output, laser_power_input1, velocity_input1, laser_power_input2, velocity_input2])\n",
    "\n",
    "\n",
    "# Compile the model with the contrastive loss function\n",
    "model = models.Model(inputs=[image1_network.input, image2_network.input, laser_power1, velocity1, laser_power2, velocity2], outputs=distance)\n",
    "model.compile(optimizer='adam', loss=ContrastiveLoss())\n",
    "\n",
    "\n",
    "def calculate_similarity_indicator(laser_power1, velocity1, laser_power2, velocity2):\n",
    "    # Calculate the difference in laser power and velocity\n",
    "    difference_laser_power = abs(laser_power1 - laser_power2)\n",
    "    difference_velocity = abs(velocity1 - velocity2)\n",
    "\n",
    "    # Define a threshold for considering laser power and velocity as 'the same'\n",
    "    threshold = 0.01\n",
    "\n",
    "    # If the differences are below the threshold, return 1, else return 0\n",
    "    if difference_laser_power < threshold and difference_velocity < threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Assuming you have a binary indicator representing whether the laser power and velocity are the same for each pair of images\n",
    "similarity_indicator = calculate_similarity_indicator(laser_power1, velocity1, laser_power2, velocity2)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit([image1, image2, laser_power1, velocity1, laser_power2, velocity2], similarity_indicator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 18:02:17.636605: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-28 18:02:17.720150: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-28 18:02:17.720203: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-28 18:02:17.723229: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-28 18:02:17.738875: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-28 18:02:18.376590: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 18:02:39.564482: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.667648: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.667897: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.669297: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.669512: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.669658: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.767911: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.768127: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.768292: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.768440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'distance_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 76\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(y_true \u001b[38;5;241m*\u001b[39m square_pred \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y_true) \u001b[38;5;241m*\u001b[39m (margin_square_laser_power \u001b[38;5;241m+\u001b[39m margin_square_velocity))\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Create the distance layer\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m distance \u001b[38;5;241m=\u001b[39m \u001b[43mdistance_layer\u001b[49m(image1_network\u001b[38;5;241m.\u001b[39moutput, image2_network\u001b[38;5;241m.\u001b[39moutput, laser_power1, velocity1, laser_power2, velocity2)\n\u001b[1;32m     77\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m[image1_network\u001b[38;5;241m.\u001b[39minput, image2_network\u001b[38;5;241m.\u001b[39minput, laser_power1, velocity1, laser_power2, velocity2], outputs\u001b[38;5;241m=\u001b[39mdistance)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'distance_layer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming you have your images and features preprocessed and stored in numpy arrays\n",
    "# image1, image2, laser_power, velocity\n",
    "\n",
    "# Define the base network architecture\n",
    "def create_base_network():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(32))\n",
    "    return model\n",
    "\n",
    "# Create two instances of the base network\n",
    "base_network = create_base_network()\n",
    "image1_network = models.Model(inputs=base_network.input, outputs=base_network.output)\n",
    "image2_network = models.Model(inputs=base_network.input, outputs=base_network.output)\n",
    "\n",
    "# Define the distance layer\n",
    "class DistanceLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, image1, image2, laser_power1, velocity1, laser_power2, velocity2):\n",
    "        image_distance = tf.reduce_sum(tf.square(image1 - image2), axis=-1)\n",
    "        laser_power_distance = tf.square(laser_power1 - laser_power2)\n",
    "        velocity_distance = tf.square(velocity1 - velocity2)\n",
    "        return image_distance + laser_power_distance + velocity_distance\n",
    "    \n",
    "\n",
    "class ContrastiveLossLaserPower(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, laser_power2):\n",
    "        # Calculate the margin as a function of laser power\n",
    "        margin_laser_power = tf.abs(laser_power1 - laser_power2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_laser_power = tf.square(tf.maximum(margin_laser_power - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square_laser_power)\n",
    "\n",
    "class ContrastiveLossVelocity(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, velocity1, velocity2):\n",
    "        # Calculate the margin as a function of velocity\n",
    "        margin_velocity = tf.abs(velocity1 - velocity2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_velocity = tf.square(tf.maximum(margin_velocity - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square_velocity)\n",
    "    \n",
    "class ContrastiveLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, velocity1, laser_power2, velocity2):\n",
    "        # Calculate the margins as functions of laser power and velocity\n",
    "        margin_laser_power = tf.abs(laser_power1 - laser_power2)\n",
    "        margin_velocity = tf.abs(velocity1 - velocity2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_laser_power = tf.square(tf.maximum(margin_laser_power - y_pred, 0))\n",
    "        margin_square_velocity = tf.square(tf.maximum(margin_velocity - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * (margin_square_laser_power + margin_square_velocity))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the distance layer\n",
    "distance = distance_layer(image1_network.output, image2_network.output, laser_power1, velocity1, laser_power2, velocity2)\n",
    "model = models.Model(inputs=[image1_network.input, image2_network.input, laser_power1, velocity1, laser_power2, velocity2], outputs=distance)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='contrastive_loss')  # You need to define 'contrastive_loss'\n",
    "\n",
    "# Train the model\n",
    "# model.fit([image1, image2, laser_power, velocity], labels, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.contrastive_loss_laser_power = ContrastiveLossLaserPower()\n",
    "        self.contrastive_loss_velocity = ContrastiveLossVelocity()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, laser_power2, velocity1, velocity2):\n",
    "        loss_laser_power = self.contrastive_loss_laser_power(y_true, y_pred, laser_power1, laser_power2)\n",
    "        loss_velocity = self.contrastive_loss_velocity(y_true, y_pred, velocity1, velocity2)\n",
    "        return self.alpha * loss_laser_power + (1 - self.alpha) * loss_velocity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m         margin_square_velocity \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msquare(tf\u001b[38;5;241m.\u001b[39mmaximum(margin_velocity \u001b[38;5;241m-\u001b[39m y_pred, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(y_true \u001b[38;5;241m*\u001b[39m square_pred \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y_true) \u001b[38;5;241m*\u001b[39m margin_square_velocity)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m[ContrastiveLossLaserPower(), ContrastiveLossVelocity()])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "class ContrastiveLossLaserPower(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, laser_power2):\n",
    "        # Calculate the margin as a function of laser power\n",
    "        margin_laser_power = tf.abs(laser_power1 - laser_power2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_laser_power = tf.square(tf.maximum(margin_laser_power - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square_laser_power)\n",
    "\n",
    "class ContrastiveLossVelocity(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, velocity1, velocity2):\n",
    "        # Calculate the margin as a function of velocity\n",
    "        margin_velocity = tf.abs(velocity1 - velocity2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_velocity = tf.square(tf.maximum(margin_velocity - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square_velocity)\n",
    "    \n",
    "model.compile(optimizer='adam', loss=[ContrastiveLossLaserPower(), ContrastiveLossVelocity()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
