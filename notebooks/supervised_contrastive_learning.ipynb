{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37FWnl0quVyz"
      },
      "source": [
        "# Supervised Contrastive Learning\n",
        "\n",
        "**Author:** [Khalid Salama](https://www.linkedin.com/in/khalid-salama-24403144/)<br>\n",
        "**Date created:** 2020/11/30<br>\n",
        "**Last modified:** 2020/11/30<br>\n",
        "**Description:** Using supervised contrastive learning for image classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrHgINe8uVy0"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "[Supervised Contrastive Learning](https://arxiv.org/abs/2004.11362)\n",
        "(Prannay Khosla et al.) is a training methodology that outperforms\n",
        "supervised training with crossentropy on classification tasks.\n",
        "\n",
        "Essentially, training an image classification model with Supervised Contrastive\n",
        "Learning is performed in two phases:\n",
        "\n",
        "1. Training an encoder to learn to produce vector representations of input images such\n",
        "that representations of images in the same class will be more similar compared to\n",
        "representations of images in different classes.\n",
        "2. Training a classifier on top of the frozen encoder.\n",
        "\n",
        "Note that this example requires [TensorFlow Addons](https://www.tensorflow.org/addons), which you can install using the following command:\n",
        "\n",
        "```python\n",
        "pip install tensorflow-addons\n",
        "```\n",
        "\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install tensorflow-addons\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZW2fsStquVy0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-28 18:57:30.793416: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-12-28 18:57:31.218093: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-28 18:57:31.218335: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-28 18:57:31.284235: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-28 18:57:31.441223: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-28 18:57:32.902692: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/home/vm/laser/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-28 18:57:34.992384: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-28 18:57:35.153037: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-28 18:57:35.153236: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
          ]
        }
      ],
      "source": [
        "# allow memory growth for GPU\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Dec 28 18:57:35 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA RTX A6000               Off | 00000000:07:00.0 Off |                  Off |\n",
            "| 30%   31C    P0              65W / 300W |      5MiB / 49140MiB |      3%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65mWVZ6quVy1"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8a3Lpkk-uVy1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "# Load the train and test data splits\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Display shapes of train and test datasets\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYgWZZKLuVy1"
      },
      "source": [
        "## Using image data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EFauXakguVy1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-28 18:57:36.696010: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-28 18:57:36.696204: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-28 18:57:36.696290: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-28 18:57:36.778841: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-28 18:57:36.778987: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-28 18:57:36.779090: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-28 18:57:36.779171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
            "2023-12-28 18:57:37.902665: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.02),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Setting the state of the normalization layer.\n",
        "data_augmentation.layers[0].adapt(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULasSxITuVy2"
      },
      "source": [
        "## Build the encoder model\n",
        "\n",
        "The encoder model takes the image as input and turns it into a 2048-dimensional\n",
        "feature vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "StlHOWINuVy2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"cifar10-encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 32, 32, 3)         7         \n",
            "                                                                 \n",
            " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23564807 (89.89 MB)\n",
            "Trainable params: 23519360 (89.72 MB)\n",
            "Non-trainable params: 45447 (177.53 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def create_encoder():\n",
        "    resnet = keras.applications.ResNet50V2(\n",
        "        include_top=False, weights=None, input_shape=input_shape, pooling=\"avg\"\n",
        "    )\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    augmented = data_augmentation(inputs)\n",
        "    outputs = resnet(augmented)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder\")\n",
        "    return model\n",
        "\n",
        "\n",
        "encoder = create_encoder()\n",
        "encoder.summary()\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 265\n",
        "hidden_units = 512\n",
        "projection_units = 128\n",
        "num_epochs = 10\n",
        "dropout_rate = 0.5\n",
        "temperature = 0.05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8BNQGdOuVy2"
      },
      "source": [
        "## Build the classification model\n",
        "\n",
        "The classification model adds a fully-connected layer on top of the encoder,\n",
        "plus a softmax layer with the target classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "H2vYXSONuVy2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_classifier(encoder, trainable=True):\n",
        "\n",
        "    for layer in encoder.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    features = encoder(inputs)\n",
        "    features = layers.Dropout(dropout_rate)(features)\n",
        "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
        "    features = layers.Dropout(dropout_rate)(features)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q531KK7duVy2"
      },
      "source": [
        "## Experiment 1: Train the baseline classification model\n",
        "\n",
        "In this experiment, a baseline classifier is trained as usual, i.e., the\n",
        "encoder and the classifier parts are trained together as a single model\n",
        "to minimize the crossentropy loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JLlTEp3quVy2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"cifar10-classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " cifar10-encoder (Functiona  (None, 2048)              23564807  \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24619025 (93.91 MB)\n",
            "Trainable params: 24573578 (93.74 MB)\n",
            "Non-trainable params: 45447 (177.53 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-28 18:58:01.262320: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
            "2023-12-28 18:58:01.787252: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
            "2023-12-28 18:58:04.462073: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f7abdc3bfb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-12-28 18:58:04.462101: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
            "2023-12-28 18:58:04.475432: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1703789884.663972    1496 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "189/189 [==============================] - 51s 106ms/step - loss: 1.8870 - sparse_categorical_accuracy: 0.3131\n",
            "Epoch 2/10\n",
            "189/189 [==============================] - 16s 86ms/step - loss: 1.4453 - sparse_categorical_accuracy: 0.4839\n",
            "Epoch 3/10\n",
            "189/189 [==============================] - 17s 88ms/step - loss: 1.2757 - sparse_categorical_accuracy: 0.5503\n",
            "Epoch 4/10\n",
            "189/189 [==============================] - 17s 88ms/step - loss: 1.1367 - sparse_categorical_accuracy: 0.6030\n",
            "Epoch 5/10\n",
            "189/189 [==============================] - 17s 90ms/step - loss: 1.0105 - sparse_categorical_accuracy: 0.6528\n",
            "Epoch 6/10\n",
            "189/189 [==============================] - 17s 90ms/step - loss: 0.9197 - sparse_categorical_accuracy: 0.6845\n",
            "Epoch 7/10\n",
            "189/189 [==============================] - 16s 84ms/step - loss: 0.8568 - sparse_categorical_accuracy: 0.7085\n",
            "Epoch 8/10\n",
            "189/189 [==============================] - 16s 86ms/step - loss: 0.8138 - sparse_categorical_accuracy: 0.7233\n",
            "Epoch 9/10\n",
            "189/189 [==============================] - 16s 85ms/step - loss: 0.7662 - sparse_categorical_accuracy: 0.7386\n",
            "Epoch 10/10\n",
            "189/189 [==============================] - 16s 86ms/step - loss: 0.7061 - sparse_categorical_accuracy: 0.7605\n",
            "313/313 [==============================] - 8s 20ms/step - loss: 0.8918 - sparse_categorical_accuracy: 0.7013\n",
            "Test accuracy: 70.13%\n"
          ]
        }
      ],
      "source": [
        "encoder = create_encoder()\n",
        "classifier = create_classifier(encoder)\n",
        "classifier.summary()\n",
        "\n",
        "history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs)\n",
        "\n",
        "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcSZltckuVy2"
      },
      "source": [
        "## Experiment 2: Use supervised contrastive learning\n",
        "\n",
        "In this experiment, the model is trained in two phases. In the first phase,\n",
        "the encoder is pretrained to optimize the supervised contrastive loss,\n",
        "described in [Prannay Khosla et al.](https://arxiv.org/abs/2004.11362).\n",
        "\n",
        "In the second phase, the classifier is trained using the trained encoder with\n",
        "its weights freezed; only the weights of fully-connected layers with the\n",
        "softmax are optimized.\n",
        "\n",
        "### 1. Supervised contrastive learning loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Q9FTBrMruVy3"
      },
      "outputs": [],
      "source": [
        "\n",
        "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
        "    def __init__(self, temperature=1, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
        "        # Normalize feature vectors\n",
        "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
        "        # Compute logits\n",
        "        logits = tf.divide(\n",
        "            tf.matmul(\n",
        "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
        "            ),\n",
        "            self.temperature,\n",
        "        )\n",
        "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
        "\n",
        "\n",
        "def add_projection_head(encoder):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    features = encoder(inputs)\n",
        "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
        "    model = keras.Model(\n",
        "        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcbC1it9uVy3"
      },
      "source": [
        "### 2. Pretrain the encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Xb8eiM2IuVy3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"cifar-encoder_with_projection-head\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " cifar10-encoder (Functiona  (None, 2048)              23564807  \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               262272    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23827079 (90.89 MB)\n",
            "Trainable params: 23781632 (90.72 MB)\n",
            "Non-trainable params: 45447 (177.53 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "189/189 [==============================] - 38s 91ms/step - loss: 5.3340\n",
            "Epoch 2/10\n",
            "189/189 [==============================] - 17s 89ms/step - loss: 5.0857\n",
            "Epoch 3/10\n",
            "189/189 [==============================] - 17s 88ms/step - loss: 4.9516\n",
            "Epoch 4/10\n",
            "189/189 [==============================] - 16s 86ms/step - loss: 4.8277\n",
            "Epoch 5/10\n",
            "189/189 [==============================] - 16s 87ms/step - loss: 4.7162\n",
            "Epoch 6/10\n",
            "189/189 [==============================] - 17s 89ms/step - loss: 4.6245\n",
            "Epoch 7/10\n",
            "189/189 [==============================] - 16s 86ms/step - loss: 4.5469\n",
            "Epoch 8/10\n",
            "189/189 [==============================] - 17s 88ms/step - loss: 4.4672\n",
            "Epoch 9/10\n",
            "189/189 [==============================] - 17s 90ms/step - loss: 4.4097\n",
            "Epoch 10/10\n",
            "189/189 [==============================] - 17s 90ms/step - loss: 4.3399\n"
          ]
        }
      ],
      "source": [
        "encoder = create_encoder()\n",
        "\n",
        "encoder_with_projection_head = add_projection_head(encoder)\n",
        "encoder_with_projection_head.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate),\n",
        "    loss=SupervisedContrastiveLoss(temperature),\n",
        ")\n",
        "\n",
        "encoder_with_projection_head.summary()\n",
        "\n",
        "history = encoder_with_projection_head.fit(\n",
        "    x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Oeei8o8uVy3"
      },
      "source": [
        "### 3. Train the classifier with the frozen encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0Z7J60dcuVy3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "189/189 [==============================] - 8s 25ms/step - loss: 0.7344 - sparse_categorical_accuracy: 0.7770\n",
            "Epoch 2/10\n",
            "189/189 [==============================] - 4s 23ms/step - loss: 0.6575 - sparse_categorical_accuracy: 0.7860\n",
            "Epoch 3/10\n",
            "189/189 [==============================] - 4s 23ms/step - loss: 0.6477 - sparse_categorical_accuracy: 0.7898\n",
            "Epoch 4/10\n",
            "189/189 [==============================] - 4s 23ms/step - loss: 0.6466 - sparse_categorical_accuracy: 0.7901\n",
            "Epoch 5/10\n",
            "189/189 [==============================] - 4s 23ms/step - loss: 0.6388 - sparse_categorical_accuracy: 0.7903\n",
            "Epoch 6/10\n",
            "189/189 [==============================] - 4s 23ms/step - loss: 0.6367 - sparse_categorical_accuracy: 0.7929\n",
            "Epoch 7/10\n",
            "189/189 [==============================] - 4s 23ms/step - loss: 0.6306 - sparse_categorical_accuracy: 0.7921\n",
            "Epoch 8/10\n",
            "189/189 [==============================] - 4s 23ms/step - loss: 0.6339 - sparse_categorical_accuracy: 0.7916\n",
            "Epoch 9/10\n",
            "189/189 [==============================] - 4s 23ms/step - loss: 0.6368 - sparse_categorical_accuracy: 0.7912\n",
            "Epoch 10/10\n",
            "189/189 [==============================] - 4s 23ms/step - loss: 0.6381 - sparse_categorical_accuracy: 0.7889\n",
            "313/313 [==============================] - 7s 19ms/step - loss: 0.8028 - sparse_categorical_accuracy: 0.7349\n",
            "Test accuracy: 73.49%\n"
          ]
        }
      ],
      "source": [
        "classifier = create_classifier(encoder, trainable=False)\n",
        "\n",
        "history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs)\n",
        "\n",
        "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZo0v9vauVy4"
      },
      "source": [
        "We get to an improved test accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMT-RjDvuVy4"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "As shown in the experiments, using the supervised contrastive learning technique\n",
        "outperformed the conventional technique in terms of the test accuracy. Note that\n",
        "the same training budget (i.e., number of epochs) was given to each technique.\n",
        "Supervised contrastive learning pays off when the encoder involves a complex\n",
        "architecture, like ResNet, and multi-class problems with many labels.\n",
        "In addition, large batch sizes and multi-layer projection heads\n",
        "improve its effectiveness. See the [Supervised Contrastive Learning](https://arxiv.org/abs/2004.11362)\n",
        "paper for more details.\n",
        "\n",
        "You can use the trained model hosted on [Hugging Face Hub](https://huggingface.co/keras-io/supervised-contrastive-learning-cifar10)\n",
        "and try the demo on [Hugging Face Spaces](https://huggingface.co/spaces/keras-io/supervised-contrastive-learning)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "supervised-contrastive-learning",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
