{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 12:20:02.248725: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-29 12:20:02.333601: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-29 12:20:02.333648: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-29 12:20:02.336104: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-29 12:20:02.351989: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-29 12:20:03.145291: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_6884/40465397.py:6: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n",
      "Setting memory growth to True for GPU:  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 12:20:04.599947: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-29 12:20:04.669536: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-29 12:20:04.669716: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-29 12:20:04.746031: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-29 12:20:04.746159: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-29 12:20:04.746253: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-29 12:20:04.746347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "2023-12-29 12:20:04.748136: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-29 12:20:04.748278: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-29 12:20:04.748361: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input, Model\n",
    "import numpy as np\n",
    "\n",
    "# verify if GPU is available\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "# set memory growth to true\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Setting memory growth to True for GPU: \", physical_devices[0])\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# dont display much info of tensorflow\n",
    "tf.get_logger().setLevel('ERROR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manta shape:  (9587, 320, 320)\n",
      "xiris shape:  (9587, 320, 320)\n",
      "y shape:  (9587, 2)\n",
      "y shape:  (9587,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "manta_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_manta.npy\"\n",
    "xiris_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_xiris.npy\"\n",
    "y_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_y.npy\"\n",
    "feats_path = \"/home/vm/SSL_Project_1/data/processed/bag_2023-07-04_15-23-48/_feats.npy\"\n",
    "\n",
    "# load numpy arrays and display shapes\n",
    "manta = np.load(manta_path)\n",
    "xiris = np.load(xiris_path)\n",
    "y = np.load(y_path)\n",
    "print(\"manta shape: \", manta.shape)\n",
    "print(\"xiris shape: \", xiris.shape)\n",
    "print(\"y shape: \", y.shape) # laser power and velocity\n",
    "\n",
    "#feats = np.load(feats_path)\n",
    "#print(\"feats shape: \", feats.shape)\n",
    "y = y[:, 0] # only use laser power\n",
    "print(\"y shape: \", y.shape)\n",
    "\n",
    "# normalize y\n",
    "y = y / np.max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values in y:  [0.18181818 0.45454545 0.72727273 1.        ]\n",
      "y encoded:  [0. 0. 0. ... 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "# unique values in y\n",
    "y_unique = np.unique(y)\n",
    "print(\"unique values in y: \", y_unique)\n",
    "\n",
    "# encode y as integers based on unique values\n",
    "y_encoded = np.zeros(y.shape)\n",
    "for i in range(len(y_unique)):\n",
    "    y_encoded[y == y_unique[i]] = i\n",
    "print(\"y encoded: \", y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (7669, 320, 320)\n",
      "y_train shape:  (7669,)\n",
      "x_test shape:  (1918, 320, 320)\n",
      "y_test shape:  (1918,)\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test (manta as input and y as output) with shuffle as true\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(manta, y_encoded, test_size=0.2, shuffle=True)\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 320, 320, 1)]     0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 369664)            55744     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               47317120  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47372864 (180.71 MB)\n",
      "Trainable params: 47372864 (180.71 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 12:20:14.098408: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-29 12:20:14.098658: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-29 12:20:14.098748: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-29 12:20:14.098877: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-29 12:20:14.098963: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-29 12:20:14.099032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def create_encoder():\n",
    "    inputs = Input(shape=(320, 320, 1))\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# add projection head\n",
    "def create_projection_head():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    return model\n",
    "\n",
    "input_shape = (320, 320, 1)\n",
    "\n",
    "def add_projection_head(encoder):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    outputs = layers.Dense(128, activation='relu')(features)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "encoder = create_encoder()\n",
    "encoder_with_projection_head = add_projection_head(encoder)\n",
    "encoder_with_projection_head.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vm/laser/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "\n",
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        # Compute logits\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        # Compute logits\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "\n",
    "        # Assuming labels is already one-dimensional\n",
    "        labels = tf.cast(labels, dtype=tf.int32)\n",
    "        labels = tf.reshape(labels, shape=(-1,))\n",
    "\n",
    "        # Use native TensorFlow implementation of npairs_loss\n",
    "        return tf.nn.sparse_softmax_cross_entropy_with_logits(labels, logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complile model with SupervisedContrastiveLoss\n",
    "encoder_with_projection_head.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=SupervisedContrastiveLoss(temperature=0.1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manta shape:  (9587, 320, 320)\n",
      "y_encoded shape:  (9587,)\n"
     ]
    }
   ],
   "source": [
    "# print manta and y_encoded shapes\n",
    "print(\"manta shape: \", manta.shape)\n",
    "print(\"y_encoded shape: \", y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 12:20:23.040848: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2023-12-29 12:20:23.143806: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-29 12:20:23.557712: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-29 12:20:25.264734: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f72debcc7e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-29 12:20:25.264763: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-12-29 12:20:25.269504: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1703852425.428414    6938 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 14s 37ms/step - loss: 3.4707\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 3.4657\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 3.4656\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 3.4654\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 3.4650\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 3.4650\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 3.4650\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 3.4650\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 3.4650\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 8s 33ms/step - loss: 3.4650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f853014a7d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model with manta an y_encoded\n",
    "encoder_with_projection_head.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float16, numpy=array([8.06 , 2.   , 4.473], dtype=float16)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1, 2], [3, 4],[5, 6]], dtype=tf.float16)\n",
    "b = tf.constant([[5, 9], [3, 6],[1, 8]], dtype=tf.float16)\n",
    "y_pred = tf.linalg.norm(a - b, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create two instances of the base network\n",
    "base_network = create_base_network()\n",
    "image1_network = models.Model(inputs=base_network.input, outputs=base_network.output)\n",
    "image2_network = models.Model(inputs=base_network.input, outputs=base_network.output)\n",
    "\n",
    "# Define the contrastive loss function\n",
    "class ContrastiveLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, velocity1, laser_power2, velocity2):\n",
    "        # Calculate the margins as functions of laser power and velocity\n",
    "        margin_laser_power = tf.abs(laser_power1 - laser_power2)\n",
    "        margin_velocity = tf.abs(velocity1 - velocity2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_laser_power = tf.square(tf.maximum(margin_laser_power - y_pred, 0))\n",
    "        margin_square_velocity = tf.square(tf.maximum(margin_velocity - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * (margin_square_laser_power + margin_square_velocity))\n",
    "    \n",
    "# Create input layers for laser power and velocity\n",
    "laser_power_input1 = layers.Input(shape=(1,))\n",
    "velocity_input1 = layers.Input(shape=(1,))\n",
    "laser_power_input2 = layers.Input(shape=(1,))\n",
    "velocity_input2 = layers.Input(shape=(1,))\n",
    "\n",
    "# Connect input layers to base networks\n",
    "image1_output = image1_network(base_network.output)\n",
    "image2_output = image2_network(base_network.output)\n",
    "\n",
    "# Concatenate image and feature outputs\n",
    "merged_output = layers.concatenate([image1_output, image2_output, laser_power_input1, velocity_input1, laser_power_input2, velocity_input2])\n",
    "\n",
    "\n",
    "# Compile the model with the contrastive loss function\n",
    "model = models.Model(inputs=[image1_network.input, image2_network.input, laser_power1, velocity1, laser_power2, velocity2], outputs=distance)\n",
    "model.compile(optimizer='adam', loss=ContrastiveLoss())\n",
    "\n",
    "\n",
    "def calculate_similarity_indicator(laser_power1, velocity1, laser_power2, velocity2):\n",
    "    # Calculate the difference in laser power and velocity\n",
    "    difference_laser_power = abs(laser_power1 - laser_power2)\n",
    "    difference_velocity = abs(velocity1 - velocity2)\n",
    "\n",
    "    # Define a threshold for considering laser power and velocity as 'the same'\n",
    "    threshold = 0.01\n",
    "\n",
    "    # If the differences are below the threshold, return 1, else return 0\n",
    "    if difference_laser_power < threshold and difference_velocity < threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Assuming you have a binary indicator representing whether the laser power and velocity are the same for each pair of images\n",
    "similarity_indicator = calculate_similarity_indicator(laser_power1, velocity1, laser_power2, velocity2)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit([image1, image2, laser_power1, velocity1, laser_power2, velocity2], similarity_indicator, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 18:02:17.636605: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-28 18:02:17.720150: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-28 18:02:17.720203: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-28 18:02:17.723229: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-28 18:02:17.738875: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-28 18:02:18.376590: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 18:02:39.564482: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.667648: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.667897: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.669297: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.669512: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.669658: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.767911: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.768127: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.768292: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-28 18:02:39.768440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46872 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'distance_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 76\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(y_true \u001b[38;5;241m*\u001b[39m square_pred \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y_true) \u001b[38;5;241m*\u001b[39m (margin_square_laser_power \u001b[38;5;241m+\u001b[39m margin_square_velocity))\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Create the distance layer\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m distance \u001b[38;5;241m=\u001b[39m \u001b[43mdistance_layer\u001b[49m(image1_network\u001b[38;5;241m.\u001b[39moutput, image2_network\u001b[38;5;241m.\u001b[39moutput, laser_power1, velocity1, laser_power2, velocity2)\n\u001b[1;32m     77\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m[image1_network\u001b[38;5;241m.\u001b[39minput, image2_network\u001b[38;5;241m.\u001b[39minput, laser_power1, velocity1, laser_power2, velocity2], outputs\u001b[38;5;241m=\u001b[39mdistance)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'distance_layer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming you have your images and features preprocessed and stored in numpy arrays\n",
    "# image1, image2, laser_power, velocity\n",
    "\n",
    "# Define the base network architecture\n",
    "def create_base_network():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(32))\n",
    "    return model\n",
    "\n",
    "# Create two instances of the base network\n",
    "base_network = create_base_network()\n",
    "image1_network = models.Model(inputs=base_network.input, outputs=base_network.output)\n",
    "image2_network = models.Model(inputs=base_network.input, outputs=base_network.output)\n",
    "\n",
    "# Define the distance layer\n",
    "class DistanceLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, image1, image2, laser_power1, velocity1, laser_power2, velocity2):\n",
    "        image_distance = tf.reduce_sum(tf.square(image1 - image2), axis=-1)\n",
    "        laser_power_distance = tf.square(laser_power1 - laser_power2)\n",
    "        velocity_distance = tf.square(velocity1 - velocity2)\n",
    "        return image_distance + laser_power_distance + velocity_distance\n",
    "    \n",
    "\n",
    "class ContrastiveLossLaserPower(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, laser_power2):\n",
    "        # Calculate the margin as a function of laser power\n",
    "        margin_laser_power = tf.abs(laser_power1 - laser_power2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_laser_power = tf.square(tf.maximum(margin_laser_power - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square_laser_power)\n",
    "\n",
    "class ContrastiveLossVelocity(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, velocity1, velocity2):\n",
    "        # Calculate the margin as a function of velocity\n",
    "        margin_velocity = tf.abs(velocity1 - velocity2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_velocity = tf.square(tf.maximum(margin_velocity - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square_velocity)\n",
    "    \n",
    "class ContrastiveLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, velocity1, laser_power2, velocity2):\n",
    "        # Calculate the margins as functions of laser power and velocity\n",
    "        margin_laser_power = tf.abs(laser_power1 - laser_power2)\n",
    "        margin_velocity = tf.abs(velocity1 - velocity2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_laser_power = tf.square(tf.maximum(margin_laser_power - y_pred, 0))\n",
    "        margin_square_velocity = tf.square(tf.maximum(margin_velocity - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * (margin_square_laser_power + margin_square_velocity))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the distance layer\n",
    "distance = distance_layer(image1_network.output, image2_network.output, laser_power1, velocity1, laser_power2, velocity2)\n",
    "model = models.Model(inputs=[image1_network.input, image2_network.input, laser_power1, velocity1, laser_power2, velocity2], outputs=distance)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='contrastive_loss')  # You need to define 'contrastive_loss'\n",
    "\n",
    "# Train the model\n",
    "# model.fit([image1, image2, laser_power, velocity], labels, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.contrastive_loss_laser_power = ContrastiveLossLaserPower()\n",
    "        self.contrastive_loss_velocity = ContrastiveLossVelocity()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, laser_power2, velocity1, velocity2):\n",
    "        loss_laser_power = self.contrastive_loss_laser_power(y_true, y_pred, laser_power1, laser_power2)\n",
    "        loss_velocity = self.contrastive_loss_velocity(y_true, y_pred, velocity1, velocity2)\n",
    "        return self.alpha * loss_laser_power + (1 - self.alpha) * loss_velocity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m         margin_square_velocity \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msquare(tf\u001b[38;5;241m.\u001b[39mmaximum(margin_velocity \u001b[38;5;241m-\u001b[39m y_pred, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_mean(y_true \u001b[38;5;241m*\u001b[39m square_pred \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y_true) \u001b[38;5;241m*\u001b[39m margin_square_velocity)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m[ContrastiveLossLaserPower(), ContrastiveLossVelocity()])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "class ContrastiveLossLaserPower(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, laser_power1, laser_power2):\n",
    "        # Calculate the margin as a function of laser power\n",
    "        margin_laser_power = tf.abs(laser_power1 - laser_power2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_laser_power = tf.square(tf.maximum(margin_laser_power - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square_laser_power)\n",
    "\n",
    "class ContrastiveLossVelocity(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_true, y_pred, velocity1, velocity2):\n",
    "        # Calculate the margin as a function of velocity\n",
    "        margin_velocity = tf.abs(velocity1 - velocity2)\n",
    "\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square_velocity = tf.square(tf.maximum(margin_velocity - y_pred, 0))\n",
    "        return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square_velocity)\n",
    "    \n",
    "model.compile(optimizer='adam', loss=[ContrastiveLossLaserPower(), ContrastiveLossVelocity()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
